{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### States\n",
    "path_LUH2 = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/states.nc'\n",
    "luh2_states = xarray.open_dataset(path_LUH2, engine=\"netcdf4\", decode_times=False)\n",
    "luh2_states_worldwide = luh2_states.isel(time=slice(1000, 1173))\n",
    "luh2_states_worldwide['time'] = pd.date_range(start=\"1850-01-01\", end=\"2022-01-01\", freq='YS')\n",
    "\n",
    "# ### Transition\n",
    "transition_LUH2 = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/transitions.nc'\n",
    "luh2_trans = xarray.open_dataset(transition_LUH2, engine=\"netcdf4\", decode_times=False)\n",
    "luh2_trans_worldwide = luh2_trans.isel(time=slice(1000, 1173))\n",
    "luh2_trans_worldwide['time'] = pd.date_range(start='1850-01-01', end='2021-01-01', freq='YS')\n",
    "luh2_trans_worldwide = luh2_trans_worldwide.drop(['primf_to_urban','secdf_to_urban', 'secdn_to_urban', 'primf_bioh', 'primn_bioh','secmf_bioh','secyf_bioh','secnf_bioh', \"urban_to_secdf\", \"urban_to_secdn\",\"urban_to_c3ann\",\"urban_to_c4ann\", \"urban_to_c3per\",\n",
    "    \"urban_to_c4per\", \"urban_to_c3nfx\", \"urban_to_pastr\", \"c3ann_to_urban\", \"c4ann_to_urban\", \"c3per_to_urban\", \"c4per_to_urban\", \"c3nfx_to_urban\", \"pastr_to_urban\", \"range_to_urban\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_class = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/FAO/Crop Classification_latest.xlsx\", engine=\"openpyxl\", skiprows=1)\n",
    "crop_class = crop_class.drop('Unnamed: 0', axis=1)\n",
    "crop_class.rename(columns={'FAO Crops': 'Item'}, inplace=True)\n",
    "\n",
    "fao_stat = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/FAO/fao_all_data.xlsx\", engine=\"openpyxl\")\n",
    "fao_stat.dropna(axis=0, inplace=True)\n",
    "fao_stat_area_harv = fao_stat[fao_stat['Element']==\"Area harvested\"]\n",
    "fao_stat_area_harv.insert(9, 'True Value', fao_stat_area_harv['Value']/100, True)\n",
    "faostat_area_harvested = fao_stat_area_harv.merge(crop_class, on='Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARBON_EMISSION_C3C4_5tahun = xarray.load_dataset(\"D:/kerja/asisten riset/vol/milkunarc/cadlan/Analysis3_LUC/CARBON_EMISSION_C3C4_5tahun_run7.nc\", engine=\"netcdf4\")\n",
    "# CARBON_EMISSION_C3C4_5tahun.isel(time=1).sel(lat=-7.125, lon=109.375).to_pandas()\n",
    "CARBON_EMISSION_C3C4_5tahun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfrac_interp = xarray.open_dataset(\"D:/kerja/asisten riset/vol/milkunarc/cadlan/GFRAC_GRAPC_Interpolation/GFRAC-INTERPOLATION-WORLDWIDE-1970_1975.nc\", engine=\"netcdf4\")\n",
    "gfrac_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gfrac = xarray.open_dataset(\"D:/kerja/asisten riset/vol/milkunarc/cadlan/GFRAC_GRAPC_Interpolation/GFRAC-RESAMPLE-NEW-1970-2100.nc\", engine='netcdf4')\n",
    "gfrac_ngfbfc = gfrac.coords['NGFBFC'].data.tolist()\n",
    "\n",
    "static = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/staticData_quarterdeg.nc'\n",
    "luh2_static = xarray.open_dataset(static, engine=\"netcdf4\")\n",
    "\n",
    "country_code = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/ISO-3166-Country-Code.xlsx\", engine=\"openpyxl\")\n",
    "ccode_iso = list(country_code['country-code'])\n",
    "cname_iso = list(country_code['name'])\n",
    "\n",
    "ccode_dict = {}\n",
    "for i, ccode in enumerate(ccode_iso):\n",
    "    ccode_dict[ccode] = cname_iso[i]\n",
    "    \n",
    "ccode_worldwide_int = luh2_static['ccode'].to_numpy().astype('int64')\n",
    "ccode_convert = np.zeros((720, 1440), dtype=\"<U64\")\n",
    "\n",
    "for i in range(720):\n",
    "    for j in range(1440):\n",
    "        if ccode_worldwide_int[i][j] in ccode_dict.keys():\n",
    "            ccode_convert[i][j] = ccode_dict[ccode_worldwide_int[i][j]]\n",
    "        else:\n",
    "            ccode_convert[i][j] = \"ocean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_check_process(grid_luh, grid_gfrac, year, country):\n",
    "\n",
    "    # kondisi A \n",
    "    if len(grid_luh) == 1 and len(grid_gfrac) == 1:\n",
    "        print(\"masuk A\")\n",
    "        if (faostat_area_harvested['LUH2Class'] == grid_luh[0]).any():\n",
    "            # nilai dari fao corps ini belum dipakai\n",
    "            corps = np.array([(faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                                    (faostat_area_harvested['IMAGE Classification'] == grid_gfrac[0]) &\n",
    "                                                    (faostat_area_harvested['LUH2Class'] == grid_luh[0])]['Item']), \n",
    "\n",
    "                            (faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                                    (faostat_area_harvested['IMAGE Classification'] == grid_gfrac[0]) &\n",
    "                                                    (faostat_area_harvested['LUH2Class'] == grid_luh[0])]['True Value'])])\n",
    "            \n",
    "            emission_intensity = (CARBON_EMISSION_C3C4_5tahun[f'all_to_{grid_luh[0]}_var'].isel(time=1).sel(lat=-7.125, lon=109.375).values \\\n",
    "                                  / (gfrac_interp['gfrac_interp'].isel(time=1).sel(lat=-7.125, lon=109.375).sel(NGFBFC=f'RF {grid_gfrac[0]}').values *\\\n",
    "                                      luh2_static['carea'].sel(lat=-7.125, lon=109.375).values))\n",
    "            \n",
    "            return corps, (f\"{emission_intensity} ton CO2/ ha\")\n",
    "\n",
    "    # Kondisi B \n",
    "    elif len(grid_luh) == 1 and len(grid_gfrac) > 1:\n",
    "        print(\"masuk B\")\n",
    "        result = list()\n",
    "        for idx, ngfbfc in enumerate(grid_gfrac):\n",
    "            luh2_item = (faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                            (faostat_area_harvested['Year'] == year) &\n",
    "                                                            (faostat_area_harvested['Area'] == country)]['LUH2Class']).values\n",
    "            if (grid_luh[0] == luh2_item).any():\n",
    "\n",
    "                corps = np.array([(faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                            (faostat_area_harvested['Year'] == year) &\n",
    "                                                            (faostat_area_harvested['Area'] == country) &\n",
    "                                                            (faostat_area_harvested['LUH2Class'] == grid_luh[0])]['Item']),\n",
    "\n",
    "                                    (faostat_area_harvested[(faostat_area_harvested['Year'] == year) & \n",
    "                                                            (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                            (faostat_area_harvested['Area'] == country) &\n",
    "                                                            (faostat_area_harvested['LUH2Class'] == grid_luh[0])]['IMAGE Classification']),\n",
    "\n",
    "                                    (faostat_area_harvested[(faostat_area_harvested['Year'] == year) & \n",
    "                                                            (faostat_area_harvested['Area'] == country) &\n",
    "                                                            (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                            (faostat_area_harvested['LUH2Class'] == grid_luh[0])]['True Value'])])\n",
    "                \n",
    "                crops_sum =  faostat_area_harvested[(faostat_area_harvested['Year'] == year) & \n",
    "                                                            (faostat_area_harvested['Area'] == country) &\n",
    "                                                            (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                            (faostat_area_harvested['LUH2Class'] == grid_luh[0])]['True Value'].sum()\n",
    "                \n",
    "                crops_carea = (gfrac_interp['gfrac_interp'].isel(time=1).sel(lat=-7.125, lon=109.375).sel(NGFBFC=f'RF {ngfbfc}').values *\\\n",
    "                                    luh2_static['carea'].sel(lat=-7.125, lon=109.375).values)\n",
    "                if crops_carea != 0:\n",
    "                    emission_intensity = (CARBON_EMISSION_C3C4_5tahun[f'all_to_{grid_luh[0]}_var'].isel(time=1).sel(lat=-7.125, lon=109.375).values \\\n",
    "                                    / crops_carea)\n",
    "                else:\n",
    "                    emission_intensity = 0\n",
    "                    \n",
    "                result.append(emission_intensity)\n",
    "\n",
    "            for x in range(len(corps[0])):\n",
    "                tabel2 = np.array([corps[0][x], corps[1][x], corps[2][x], (corps[2][x]/crops_sum)*100])\n",
    "                print(tabel2)\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for i, emission in enumerate(result):\n",
    "            print(f\"{emission} ton CO2/ ha\")\n",
    "\n",
    "    #Kondisi C\n",
    "    elif len(grid_luh) > 1 and len(grid_gfrac) == 1:\n",
    "        print(\"masuk C\")\n",
    "        sum_proporsi = list()\n",
    "        tabel2 = list()\n",
    "        for items in grid_luh:\n",
    "            corps = np.array([(faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == grid_gfrac[0]) &\n",
    "                                (faostat_area_harvested['Year'] == year) &\n",
    "                                (faostat_area_harvested['Area'] == country) &\n",
    "                                (faostat_area_harvested['LUH2Class'] == items)]['Item']),\n",
    "                                \n",
    "                                (faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == grid_gfrac[0]) &\n",
    "                                (faostat_area_harvested['Year'] == year) &\n",
    "                                (faostat_area_harvested['Area'] == country) &\n",
    "                                (faostat_area_harvested['LUH2Class'] == items)]['True Value'])])\n",
    "\n",
    "            corps_sum = np.array(faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == grid_gfrac[0]) &\n",
    "                                (faostat_area_harvested['Year'] == year) &\n",
    "                                (faostat_area_harvested['Area'] == country) &\n",
    "                                (faostat_area_harvested['LUH2Class'] == items)]['True Value'].sum())\n",
    "            \n",
    "            if len(corps[0]) > 1:\n",
    "                for x in range(0, len(corps)):\n",
    "                    tabel2.append([corps[0][x], corps[1][x], ((corps[1][x]/corps_sum)*100)])\n",
    "            else:\n",
    "                if corps.size == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    sum_proporsi.append(corps_sum)\n",
    "                    tabel2.append([corps[0][0], corps[1][0], corps_sum, ((corps[1][0]/corps_sum) * 100)])\n",
    "        \n",
    "        crarea_hektar = []\n",
    "        for idx, i in enumerate(tabel2):\n",
    "            corps_proportion = np.array([tabel2[idx][0], tabel2[idx][1], tabel2[idx][2], tabel2[idx][3], tabel2[idx][2]/sum(sum_proporsi), tabel2[idx][2]/sum(sum_proporsi) * tabel2[idx][3]])\n",
    "            print(corps_proportion)\n",
    "            crops_crarea = float(corps_proportion[5]) * (0.4 * 100) / 100\n",
    "            crarea_hektar.append(crops_crarea)\n",
    "\n",
    "        return f\"{round(sum(crarea_hektar))} hektar\"\n",
    "        \n",
    "    #kondisi D1 D2\n",
    "    elif len(grid_luh) > 1 and len(grid_gfrac) > 1:\n",
    "        print(\"masuk D\")\n",
    "        list_mayor_grid = np.array(['Oil, palm fruit', 'Wheat', 'Soybeans', 'Maize', 'Rice'])\n",
    "        sum_proporsi = list()\n",
    "        crarea_hektar = list()\n",
    "        tabel2 = list()\n",
    "        grid_mayor = list()\n",
    "        for items in grid_luh:\n",
    "            for grid in grid_gfrac:\n",
    "                if grid in list_mayor_grid: #Oil, palm fruit\n",
    "                    grid_gfrac = gfrac['GFRAC_res'].isel(time=1).sel(lat=-7.125, lon=109.375).sel(NGFBFC=\"Oil, palm fruit\").values\n",
    "                    grid_corps = grid_gfrac * luh2_static['carea'].sel(lat=-7.125, lon=109.375).values\n",
    "                    return grid_mayor.append(grid_corps)\n",
    "                    # continue #diambil nilai major nya 0.4 * 100 carea \n",
    "                \n",
    "                else:\n",
    "                    corps = np.array([(faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == grid) &\n",
    "                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                    (faostat_area_harvested['Area'] == country) &\n",
    "                                    (faostat_area_harvested['LUH2Class'] == items)]['IMAGE Classification']),\n",
    "\n",
    "                                    (faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == grid) &\n",
    "                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                    (faostat_area_harvested['Area'] == country) &\n",
    "                                    (faostat_area_harvested['LUH2Class'] == items)]['Item']),\n",
    "                                    \n",
    "                                    (faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == grid) &\n",
    "                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                    (faostat_area_harvested['Area'] == country) &\n",
    "                                    (faostat_area_harvested['LUH2Class'] == items)]['True Value'])])\n",
    "                    \n",
    "                    corps_sum = np.array(faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == grid) &\n",
    "                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                    (faostat_area_harvested['Area'] == country) &\n",
    "                                    (faostat_area_harvested['LUH2Class'] == items)]['True Value'].sum())\n",
    "                \n",
    "                    if len(corps[0]) > 1:\n",
    "                        sum_proporsi.append(corps_sum)\n",
    "                        for x in range(0, len(corps[0])):\n",
    "                            tabel2.append([items[9:], corps[0][x], corps[1][x], corps[2][x], corps_sum, ((corps[2][x]/corps_sum)*100)])\n",
    "                    else:\n",
    "                        if corps.size == 0:\n",
    "                            continue\n",
    "                        else:\n",
    "                            sum_proporsi.append(corps_sum)\n",
    "                            tabel2.append([items[9:], corps[0][0], corps[1][0], corps[2][0], corps_sum, ((corps[2][0]/corps_sum)*100)])\n",
    "\n",
    "        for idx, grid_corps in enumerate(tabel2):\n",
    "            corps_proportion = np.array([grid_corps[0], grid_corps[1], grid_corps[2], grid_corps[3], grid_corps[4], grid_corps[5], grid_corps[4]/sum(sum_proporsi), grid_corps[4]/sum(sum_proporsi) * grid_corps[5]])\n",
    "            print(corps_proportion)\n",
    "            crops_crarea = float(corps_proportion[5]) * (0.4 * 100) / 100\n",
    "            crarea_hektar.append(crops_crarea)\n",
    "        return f\"{round(sum(crarea_hektar))} hektar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid jawa tengah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_check_process(grid_luh=[\"c3per\"], grid_gfrac=[\"Tropical oil crops\", \"Oil & palm fruit\"], year=2017, country='Ghana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_gfrac = gfrac_interp['GFRAC_interp'].isel(time=1).sel(lat=-7.125, lon=109.375)\n",
    "# atribut = []\n",
    "\n",
    "att_ngfbfc = gfrac_interp.coords['NGFBFC'].where(grid_gfrac > 0.0, gfrac_interp['GFRAC_interp'], 0).data\n",
    "att_ngfbfc\n",
    "\n",
    "# for idx, value in enumerate(grid_gfrac):\n",
    "    # print(value.values)\n",
    "    # if value.any() > 0.0:\n",
    "        # print(gfrac_interp.coords['NGFBFC'].data.tolist()[idx])\n",
    "# atribut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ates_worldwide.drop([\"primf\", \"primn\", \"secdf\", \"secdn\", \"urban\", \"pastr\", \"range\", \"secmb\", \"secma\"])\n",
    "\n",
    "crops_list = [\"c3ann\", \"c4ann\", \"c3per\", \"c4per\", \"c3nfx\"]\n",
    "atribut_luh = list()\n",
    "for idx, value in enumerate(luh2_states_worldwide.isel(time=2).sel(lat=-7.125, lon=109.375).to_pandas().values):\n",
    "    if value.any() > 0.0:\n",
    "        attribut = crops_list[idx]\n",
    "        atribut_luh.append(attribut)\n",
    "atribut_luh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(52):\n",
    "    if float(luh2_trans_worldwide['secdf_to_c3ann'].isel(time=i).sel(lat=-7.125, lon=109.375).values) > 0.0:\n",
    "        print(i, luh2_trans_worldwide['secdf_to_c3ann'].isel(time=i).sel(lat=-7.125, lon=109.375).values)\n",
    "\n",
    "\n",
    "for i in range(52):\n",
    "    if gfrac['GFRAC_res'].isel(time=i).sel(lat=-7.125, lon=109.375).values.any() > 0.0:\n",
    "        for idx, value in enumerate(gfrac['GFRAC_res'].isel(time=i).sel(lat=-7.125, lon=109.375).values):\n",
    "            if value > 0.0:\n",
    "                ngfbfc_dfrac = [gfrac.coords['NGFBFC'].data.tolist()[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # kondisi A \n",
    "    if len(luh2_cat) == 1 and len(ngfbfc_att) == 1:\n",
    "        jenis_kacang_kacangan += faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                                (faostat_area_harvested['Year'] == year) &\n",
    "                                                (faostat_area_harvested['IMAGE Classification'] == ngfbfc_att) &\n",
    "                                                (faostat_area_harvested['LUH2Class'] == luh2_cat)]['Item'].tolist()\n",
    "        \n",
    "        crops += faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                                (faostat_area_harvested['Year'] == year) &\n",
    "                                                (faostat_area_harvested['IMAGE Classification'] == ngfbfc_att) &\n",
    "                                                (faostat_area_harvested['LUH2Class'] == luh2_cat)]['True Value'].tolist()\n",
    "\n",
    "    # Kondisi B \n",
    "    elif len(luh2_cat) == 1 and len(ngfbfc_att) > 1:\n",
    "\n",
    "        for ngfbfc in ngfbfc_att:\n",
    "            jenis_kacang_kacangan += faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                        (faostat_area_harvested['Year'] == year) &\n",
    "                                        (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                        (faostat_area_harvested['LUH2Class'] == luh2_cat)]['Item'].tolist()\n",
    "                    \n",
    "            crops += faostat_area_harvested[(faostat_area_harvested['Year'] == year) & \n",
    "                                                        (faostat_area_harvested['Area'] == country) &\n",
    "                                                        (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                        (faostat_area_harvested['LUH2Class'] == luh2_cat)]['True Value'].tolist()\n",
    "            \n",
    "            crops_sum += faostat_area_harvested[(faostat_area_harvested['Year'] == year) & \n",
    "                                                 (faostat_area_harvested['Area'] == country) &\n",
    "                                                 (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                 (faostat_area_harvested['LUH2Class'] == luh2_cat)]['True Value'].sum()\n",
    "        \n",
    "    #Kondisi C\n",
    "    elif len(luh2_cat) > 1 and len(ngfbfc_att) == 1:\n",
    "\n",
    "        for items in luh2_cat:\n",
    "            jenis_kacang_kacangan += faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                        (faostat_area_harvested['Year'] == year) &\n",
    "                                        (faostat_area_harvested['IMAGE Classification'] == ngfbfc_att) &\n",
    "                                        (faostat_area_harvested['LUH2Class'] == items)]['Item'].tolist()\n",
    "            \n",
    "            crops += faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == ngfbfc_att) &\n",
    "                                (faostat_area_harvested['Year'] == year) &\n",
    "                                (faostat_area_harvested['Area'] == country) &\n",
    "                                (faostat_area_harvested['LUH2Class'] == items)]['True Value'].tolist()\n",
    "\n",
    "            crops_sum += faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == ngfbfc_att) &\n",
    "                                (faostat_area_harvested['Year'] == year) &\n",
    "                                (faostat_area_harvested['Area'] == country) &\n",
    "                                (faostat_area_harvested['LUH2Class'] == items)]['True Value'].sum()\n",
    "        \n",
    "    #kondisi D1 D2\n",
    "    elif len(luh2_cat) > 1 and len(ngfbfc_att) > 1:\n",
    "        list_mayor_grid = np.array(['Oil, palm fruit', 'Wheat', 'Soybeans', 'Maize', 'Rice'])\n",
    "\n",
    "        for items in luh2_cat:\n",
    "            for ngfbfc in ngfbfc_att:\n",
    "\n",
    "                if ngfbfc in list_mayor_grid:\n",
    "                    jenis_kacang_kacangan += faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                        (faostat_area_harvested['Year'] == year) &\n",
    "                                        (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                        (faostat_area_harvested['LUH2Class'] == items)]['Item'].tolist()\n",
    "                    \n",
    "                    crops += [gfrac_interp['GFRAC_interp'].isel(time=time, lat=lat, lon=lon).sel(NGFBFC=ngfbfc).values * luh2_static['carea'].isel(lat=lat, lon=lon).values]\n",
    "\n",
    "                if ngfbfc is not list_mayor_grid:\n",
    "                    jenis_kacang_kacangan += faostat_area_harvested[(faostat_area_harvested['Area'] == country) &\n",
    "                                        (faostat_area_harvested['Year'] == year) &\n",
    "                                        (faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                        (faostat_area_harvested['LUH2Class'] == items)]['Item'].tolist()\n",
    "                    \n",
    "                    crops += faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                                    (faostat_area_harvested['Area'] == country) &\n",
    "                                                    (faostat_area_harvested['LUH2Class'] == items)]['True Value'].tolist()\n",
    "                \n",
    "                    crops_sum += faostat_area_harvested[(faostat_area_harvested['IMAGE Classification'] == ngfbfc) &\n",
    "                                    (faostat_area_harvested['Year'] == year) &\n",
    "                                    (faostat_area_harvested['Area'] == country) &\n",
    "                                    (faostat_area_harvested['LUH2Class'] == items)]['True Value'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
