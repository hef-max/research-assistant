{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HEFRY ANESTI\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\coding\\times.py:167: SerializationWarning: Ambiguous reference date string: 850-01-01 0:0:0. The first value is assumed to be the year hence will be padded with zeros to remove the ambiguity (the padded reference date string is: 0850-01-01 0:0:0). To remove this message, remove the ambiguity by padding your reference date strings with zeros.\n",
      "  warnings.warn(warning_msg, SerializationWarning)\n"
     ]
    }
   ],
   "source": [
    "# ### States\n",
    "path_LUH2 = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/states.nc'\n",
    "luh2_states = xarray.open_dataset(path_LUH2, engine=\"netcdf4\", decode_times=False)\n",
    "luh2_states_worldwide = luh2_states.isel(time=slice(1000, 1173))\n",
    "luh2_states_worldwide['time'] = pd.date_range(start=\"1850-01-01\", end=\"2022-01-01\", freq='YS')\n",
    "\n",
    "# ### Transition\n",
    "transition_LUH2 = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/transitions.nc'\n",
    "luh2_trans = xarray.open_dataset(transition_LUH2, engine=\"netcdf4\", decode_times=False)\n",
    "luh2_trans_worldwide = luh2_trans.isel(time=slice(1000, 1173))\n",
    "luh2_trans_worldwide['time'] = pd.date_range(start='1850-01-01', end='2021-01-01', freq='YS')\n",
    "luh2_trans_worldwide = luh2_trans_worldwide.drop(['primf_to_urban','secdf_to_urban', 'secdn_to_urban', 'primf_bioh', 'primn_bioh','secmf_bioh','secyf_bioh','secnf_bioh', \"urban_to_secdf\", \"urban_to_secdn\",\"urban_to_c3ann\",\"urban_to_c4ann\", \"urban_to_c3per\",\n",
    "    \"urban_to_c4per\", \"urban_to_c3nfx\", \"urban_to_pastr\", \"c3ann_to_urban\", \"c4ann_to_urban\", \"c3per_to_urban\", \"c4per_to_urban\", \"c3nfx_to_urban\", \"pastr_to_urban\", \"range_to_urban\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_emission_1971 = xarray.load_dataset(\"D:/kerja/asisten riset/vol/milkunarc/cadlan/Analysis3_LUC/CARBON_EMISSION-1970-1976_corps.nc\", engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crop_class = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/FAO/Crop Classification_latest.xlsx\", engine=\"openpyxl\", skiprows=1)\n",
    "crop_class = crop_class.drop('Unnamed: 0', axis=1)\n",
    "crop_class.rename(columns={'FAO Crops': 'Item'}, inplace=True)\n",
    "\n",
    "\n",
    "fao_stat = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/FAO/fao_all_data.xlsx\", engine=\"openpyxl\")\n",
    "fao_stat.dropna(axis=0, inplace=True)\n",
    "fao_stat_yield = fao_stat[fao_stat['Element']=='Yield']\n",
    "fao_stat_yield.insert(9, 'True Value', fao_stat_yield['Value']*100, True)\n",
    "faostat_yield = fao_stat_yield.merge(crop_class, on='Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapc = xarray.open_dataset(\"D:/kerja/asisten riset/vol/milkunarc/cadlan/GFRAC_GRAPC_Interpolation/GRAPC-RESAMPLE-1970-2100.nc\", engine='netcdf4')\n",
    "grapc_nfbfc = grapc.coords['NFBFC'].data.tolist()\n",
    "\n",
    "static = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/staticData_quarterdeg.nc'\n",
    "luh2_static = xarray.open_dataset(static, engine=\"netcdf4\")\n",
    "\n",
    "country_code = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/ISO-3166-Country-Code.xlsx\", engine=\"openpyxl\")\n",
    "ccode_iso = list(country_code['country-code'])\n",
    "cname_iso = list(country_code['name'])\n",
    "\n",
    "ccode_dict = {}\n",
    "for i, ccode in enumerate(ccode_iso):\n",
    "    ccode_dict[ccode] = cname_iso[i]\n",
    "    \n",
    "ccode_worldwide_int = luh2_static['ccode'].to_numpy().astype('int64')\n",
    "ccode_convert = np.zeros((720, 1440), dtype=\"<U64\")\n",
    "\n",
    "for i in range(720):\n",
    "    for j in range(1440):\n",
    "        if ccode_worldwide_int[i][j] in ccode_dict.keys():\n",
    "            ccode_convert[i][j] = ccode_dict[ccode_worldwide_int[i][j]]\n",
    "        else:\n",
    "            ccode_convert[i][j] = \"Unknown\"\n",
    "\n",
    "ccode_convert_v1 = np.unique(ccode_convert).astype(str)\n",
    "\n",
    "luh2_trans_worldwide_list = []\n",
    "for luh2_trans in luh2_trans_worldwide.data_vars:\n",
    "        luh2_trans_worldwide_list.append(luh2_trans[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worldwide_intensity = np.zeros((131, 27, 7, 720, 1440), dtype)\n",
    "grid_intensity = np.zeros((27, 720, 1440), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_check_process(grid_luh, grid_grapc, year, country):\n",
    "\n",
    "    # kondisi A if: grid 1,1 LUH2 exist = 1 variable & grid 1,1 Grapc exist=1 variable\n",
    "    if len(grid_luh) == 1 and len(grid_grapc) == 1:\n",
    "        for grid_grapc in grid_grapc:\n",
    "            if faostat_yield['IMAGE Classification'] == grid_grapc:\n",
    "                grid_emisi = carbon_emission_1971[f'to_{faostat_yield['LUH2Class']}'].isel(time=1).sel(lat=-7.125, lon=109.375).values/(grid_grapc * luh2_static['carea'].sel(lat=-7.125, lon=109.375).values)\n",
    "                grid_intensity = np.array(grid_emisi) \n",
    "        return grid_intensity\n",
    "\n",
    "    # Kondisi B - if: grid 1,1 LUH2 exist = 1 variable & grid 1,1 Grapc exist>1 variable (minimal 2)\n",
    "    elif len(grid_luh) == 1 and len(grid_grapc) > 1:\n",
    "        corps =  np.array([(faostat_yield[(faostat_yield['Year'] == year) & \n",
    "                                                   (faostat_yield['Area'] == country) &\n",
    "                                                   (faostat_yield['LUH2Class'] == grid_luh[0][9:])]['IMAGE Classification']),\n",
    "                            (faostat_yield[(faostat_yield['Year'] == year) & \n",
    "                                                    (faostat_yield['Area'] == country) &\n",
    "                                                    (faostat_yield['LUH2Class'] == grid_luh[0][9:])]['True Value'])])\n",
    "        \n",
    "        corps_sum =  np.array([(faostat_yield[(faostat_yield['Year'] == year) & \n",
    "                                                    (faostat_yield['Area'] == country) &\n",
    "                                                    (faostat_yield['LUH2Class'] == grid_luh[0][9:])]['True Value'].sum())])\n",
    "        for x in range(0, len(corps[0])):\n",
    "            luas_aktual_grid_grapc = np.array([corps[0][x], corps[1][x], (corps[1][x] * luh2_static['carea'].sel(lat=-7.125, lon=109.375).values), ((corps[1][x] / corps_sum) * 100)]) \n",
    "            emisi_intensity = (luas_aktual_grid_grapc[3][0] * carbon_emission_1971['to_c3ann'].isel(time=1).sel(lat=-7.125, lon=109.375).values) / luas_aktual_grid_grapc[1]\n",
    "            \n",
    "            print((luas_aktual_grid_grapc[3][0], carbon_emission_1971['to_c3ann'].isel(time=1).sel(lat=-7.125, lon=109.375).values), luas_aktual_grid_grapc[1])\n",
    "            print(luas_aktual_grid_grapc)\n",
    "\n",
    "    #Kondisi C\n",
    "    elif len(grid_luh) > 1 and len(grid_grapc) == 1:\n",
    "        for items in grid_luh:\n",
    "            corps = np.array([(faostat_yield[(faostat_yield['IMAGE Classification'] == grid_grapc[0]) &\n",
    "                                (faostat_yield['Year'] == year) &\n",
    "                                (faostat_yield['Area'] == country) &\n",
    "                                (faostat_yield['LUH2Class'] == items[9:])]['Item']),\n",
    "                                \n",
    "                                (faostat_yield[(faostat_yield['IMAGE Classification'] == grid_grapc[0]) &\n",
    "                                (faostat_yield['Year'] == year) &\n",
    "                                (faostat_yield['Area'] == country) &\n",
    "                                (faostat_yield['LUH2Class'] == items[9:])]['True Value'])])\n",
    "\n",
    "            corps_sum = np.array(faostat_yield[(faostat_yield['IMAGE Classification'] == grid_grapc[0]) &\n",
    "                                (faostat_yield['Year'] == year) &\n",
    "                                (faostat_yield['Area'] == country) &\n",
    "                                (faostat_yield['LUH2Class'] == items[9:])]['True Value'].sum())\n",
    "            \n",
    "            intensity_corps = []\n",
    "            if corps.any() > 0:\n",
    "                for x in range(0, len(corps)): \n",
    "                    corps_proportion = np.array([corps[0][x], corps[1][x], ((corps[1][x]/corps_sum)*100)])   \n",
    "\n",
    "                    intensity_corps.append(carbon_emission_1971['to_c3ann'].isel(time=1).sel(lat=-7.125, lon=109.375).values * corps_proportion[2])\n",
    "            return intensity_corps\n",
    "        \n",
    "    #kondisi D1 D2\n",
    "    elif len(grid_grapc) > 1 and len(grid_luh) > 1:\n",
    "        proporsi = list()\n",
    "        list_mayor_grid = ['Oil, palm fruit', 'Wheat', 'Soybeans', 'Maize', 'Rice']\n",
    "        for mayor_grid in list_mayor_grid:\n",
    "                crops = np.array([(faostat_yield[(faostat_yield['IMAGE Classification'] != mayor_grid) &\n",
    "                                (faostat_yield['Year'] == year) &\n",
    "                                (faostat_yield['Area'] == country) &\n",
    "                                (faostat_yield['LUH2Class'] == items[9:])]['IMAGE Classification']),\n",
    "\n",
    "                                (faostat_yield[(faostat_yield['IMAGE Classification'] != mayor_grid) &\n",
    "                                (faostat_yield['Year'] == year) &\n",
    "                                (faostat_yield['Area'] == country) &\n",
    "                                (faostat_yield['LUH2Class'] == items[9:])]['Item']),\n",
    "                                \n",
    "                                (faostat_yield[(faostat_yield['IMAGE Classification'] != mayor_grid) &\n",
    "                                (faostat_yield['Year'] == year) &\n",
    "                                (faostat_yield['Area'] == country) &\n",
    "                                (faostat_yield['LUH2Class'] == items[9:])]['True Value'])])\n",
    "\n",
    "                crops_sum = np.array(faostat_yield[(faostat_yield['IMAGE Classification'] != mayor_grid) &\n",
    "                                (faostat_yield['Year'] == year) &\n",
    "                                (faostat_yield['Area'] == country) &\n",
    "                                (faostat_yield['LUH2Class'] == items[9:])]['True Value'].sum())\n",
    "\n",
    "                for x in range(0, len(crops[0])):\n",
    "                        corps_proportion = np.array([crops[0][x], crops[1][x], crops[2][x], ((crops[2][x]/crops_sum)*100)])\n",
    "                        proporsi.append(float(corps_proportion[3]))\n",
    "        return proporsi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid jawa tengah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1154804419436513, array(24013.00427246)) 12.0\n",
      "['Vegetables & fruits' 12.0 9201.6181640625 array([0.11548044])]\n",
      "(14.723756347815542, array(24013.00427246)) 1530.0\n",
      "['Pulses' 1530.0 1173206.3159179688 array([14.72375635])]\n",
      "(5.292853589084019, array(24013.00427246)) 550.0\n",
      "['Rice' 550.0 421740.83251953125 array([5.29285359])]\n",
      "(0.08603292924802022, array(24013.00427246)) 8.94\n",
      "['Plant-based fibers' 8.94 6855.205532226562 array([0.08603293])]\n",
      "(2.684920275189893, array(24013.00427246)) 279.0\n",
      "['Other non-food, luxury, spices' 279.0 213937.62231445312\n",
      " array([2.68492028])]\n",
      "(0.3849348064788377, array(24013.00427246)) 40.0\n",
      "['Vegetables & fruits' 40.0 30672.060546875 array([0.38493481])]\n",
      "(2.694543645351864, array(24013.00427246)) 280.0\n",
      "['Vegetables & fruits' 280.0 214704.423828125 array([2.69454365])]\n",
      "(1.7899468501265954, array(24013.00427246)) 186.0\n",
      "['Vegetables & fruits' 186.0 142625.08154296875 array([1.78994685])]\n",
      "(0.15686093364012638, array(24013.00427246)) 16.3\n",
      "['Other non-food, luxury, spices' 16.3 12498.864672851563\n",
      " array([0.15686093])]\n",
      "(0.8564799444154139, array(24013.00427246)) 89.0\n",
      "['Other non-food, luxury, spices' 89.0 68245.33471679688\n",
      " array([0.85647994])]\n",
      "(9.43215379685258, array(24013.00427246)) 980.13\n",
      "['Temperate oil crops' 980.13 751565.1675952148 array([9.4321538])]\n",
      "(20.20907734013898, array(24013.00427246)) 2100.0\n",
      "['Tropical roots and tubers' 2100.0 1610283.1787109375\n",
      " array([20.20907734])]\n",
      "(25.02076242112445, array(24013.00427246)) 2600.0\n",
      "['Tropical roots and tubers' 2600.0 1993683.935546875 array([25.02076242])]\n",
      "(16.55219667859002, array(24013.00427246)) 1720.0\n",
      "['Tropical roots and tubers' 1720.0 1318898.603515625 array([16.55219668])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HEFRYA~1\\AppData\\Local\\Temp/ipykernel_10028/190737735.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  luas_aktual_grid_gfrac = np.array([corps[0][x], corps[1][x], (corps[1][x] * luh2_static['carea'].sel(lat=-7.125, lon=109.375).values), ((corps[1][x] / corps_sum) * 100)])\n"
     ]
    }
   ],
   "source": [
    "luh2_trans_worldwide['primf_to_c3ann'].isel(time=1).sel(lat=-7.125, lon=109.375).values\n",
    "\n",
    "grid_gfrac = grapc['GFRAC_res'].isel(time=1).sel(lat=-7.125, lon=109.375).values\n",
    "atribut = []\n",
    "for idx, value in enumerate(grid_gfrac):\n",
    "    if value > 0.0:\n",
    "        atribut.append(grapc.coords['NGFBFC'].data.tolist()[idx])\n",
    "        \n",
    "grid_check_process(grid_luh=['primf_to_c3ann'], grid_gfrac=atribut, year=1970, country='Ghana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(27):\n",
    "    if float(luh2_trans_worldwide['secdf_to_c3ann'].isel(time=i).sel(lat=-7.125, lon=109.375).values) > 0.0:\n",
    "        print(i, luh2_trans_worldwide['secdf_to_c3ann'].isel(time=i).sel(lat=-7.125, lon=109.375).values)\n",
    "\n",
    "\n",
    "for i in range(27):\n",
    "    if grapc['GRAPC_res'].isel(time=i).sel(lat=-7.125, lon=109.375).values.any() > 0.0:\n",
    "        for idx, value in enumerate(grapc['GRAPC_res'].isel(time=i).sel(lat=-7.125, lon=109.375).values):\n",
    "            if value > 0.0:\n",
    "                ngfbfc_dfrac = [grapc.coords['NGFBFC'].data.tolist()[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "worldwide_intensity_arr = np.array()\n",
    "\n",
    "\n",
    "# output\n",
    "grid_intensity_netcdf = xarray.Dataset({\n",
    "        \"grid_interp\":([\"country\", 'items', \"time\", \"lat\", \"lon\"], worldwide_intensity_arr)\n",
    "    },\n",
    "    coords={\n",
    "        \"country\": list(np.unique(ccode_convert)),\n",
    "        'Items': luh2_trans_worldwide_list,\n",
    "        \"time\":pd.date_range(\"1970-01-01\", \"2100-01-01\", freq='YS'),\n",
    "        \"lon\":luh2_states_worldwide.coords[\"lon\"].to_numpy(),\n",
    "        \"lat\":luh2_states_worldwide.coords[\"lat\"].to_numpy()\n",
    "    })\n",
    "\n",
    "\n",
    "grid_intensity_netcdf.to_netcdf(\"D:/kerja/asisten riset/vol/milkunarc/cadlan/grid_intensity_netcdf-1970_2100.nc\", mode='w', format=\"NETCDF4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
