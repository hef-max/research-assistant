{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HEFRY ANESTI\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xarray\\coding\\times.py:167: SerializationWarning: Ambiguous reference date string: 850-01-01 0:0:0. The first value is assumed to be the year hence will be padded with zeros to remove the ambiguity (the padded reference date string is: 0850-01-01 0:0:0). To remove this message, remove the ambiguity by padding your reference date strings with zeros.\n",
      "  warnings.warn(warning_msg, SerializationWarning)\n"
     ]
    }
   ],
   "source": [
    "# ### States\n",
    "path_LUH2 = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/states.nc'\n",
    "luh2_states = xarray.open_dataset(path_LUH2, engine=\"netcdf4\", decode_times=False)\n",
    "luh2_states_worldwide = luh2_states.isel(time=slice(1000, 1173))\n",
    "luh2_states_worldwide['time'] = pd.date_range(start=\"1850-01-01\", end=\"2022-01-01\", freq='YS')\n",
    "\n",
    "luh2_added_states_worldwide = xarray.open_dataset(\"D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/multiple-states_input4MIPs_landState_ScenarioMIP_UofMD-IMAGE-ssp119-2-1-f_gn_2015-2100.nc\",\\\n",
    "                                        engine=\"netcdf4\", decode_times=False)\n",
    "luh2_added_trans = luh2_added_states_worldwide.drop_vars(['lat_bounds', 'lon_bounds', 'time_bnds'])\n",
    "luh2_added_trans.coords['time'] = pd.date_range(start='2015-01-01', end='2100-01-01', freq='YS')\n",
    "\n",
    "# ### Static\n",
    "static = 'D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/staticData_quarterdeg.nc'\n",
    "luh2_static = xarray.open_dataset(static, engine=\"netcdf4\")\n",
    "\n",
    "country_code = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/LUH2 2022/ISO-3166-Country-Code.xlsx\", engine=\"openpyxl\")\n",
    "ccode_iso = list(country_code['country-code'])\n",
    "cname_iso = list(country_code['name'])\n",
    "\n",
    "ccode_convert = np.zeros((720, 1440), dtype=\"<U64\")\n",
    "\n",
    "ccode_dict = {}\n",
    "for i, ccode in enumerate(ccode_iso):\n",
    "    ccode_dict[ccode] = cname_iso[i]\n",
    "\n",
    "ccode_worldwide_int = luh2_static['ccode'].to_numpy().astype('int64')\n",
    "\n",
    "for i in range(720):\n",
    "    for j in range(1440):\n",
    "        if ccode_worldwide_int[i][j] in ccode_dict.keys():\n",
    "            ccode_convert[i][j] = ccode_dict[ccode_worldwide_int[i][j]]\n",
    "        else:\n",
    "            ccode_convert[i][j] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_class = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/FAO/Crop Classification_latest.xlsx\", engine=\"openpyxl\", skiprows=1)\n",
    "crop_class = crop_class.drop('Unnamed: 0', axis=1)\n",
    "crop_class.rename(columns={'FAO Crops': 'Item'}, inplace=True)\n",
    "\n",
    "fao_stat = pd.read_excel(\"D:/kerja/asisten riset/vol/milkunC/achaidir/FAO/fao_all_data.xlsx\", engine=\"openpyxl\")\n",
    "fao_stat.dropna(axis=0, inplace=True)\n",
    "\n",
    "fao_stat_yield = fao_stat[fao_stat['Element']=='Yield']\n",
    "fao_stat_yield.insert(9, 'True Value', fao_stat_yield['Value']*100, True)\n",
    "faostat_yield = fao_stat_yield.merge(crop_class, on='Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapc = xarray.open_dataset(\"D:/kerja/asisten riset/vol/milkunarc/cadlan/GFRAC_GRAPC_Interpolation/GRAPC-RESAMPLE-1970-2100.nc\", engine='netcdf4')\n",
    "grapc_nfbfc = grapc.coords['NFBFC'].data.tolist()\n",
    "\n",
    "grapc_nfbfc_ir_rf = []\n",
    "for grapc_cls in grapc_nfbfc:\n",
    "    if grapc_cls[0:2] == 'RF' or grapc_cls[0:2] == 'IR':\n",
    "        grapc_nfbfc_ir_rf.append(grapc_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi interpolasi\n",
    "def grid_level(kolom_sebelumnya, percent):\n",
    "    return np.divide(np.multiply(kolom_sebelumnya, percent), 100)\n",
    "\n",
    "def percent_change(grapc, kolom_sekarang, kolom_sebelumnya):\n",
    "    if kolom_sebelumnya != 0:\n",
    "        result = np.multiply(np.nan_to_num(np.divide(kolom_sekarang, kolom_sebelumnya)), 100)\n",
    "    else:\n",
    "        result = np.nan\n",
    "    return grid_level(grapc, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grapc_interp(grapc_class, grapc_cls_idx, country):\n",
    "\n",
    "    arr = np.zeros((56, 32, 720, 1440), dtype=\"float64\")\n",
    "\n",
    "    arr[0][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=0).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[5][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=1).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[10][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=2).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[15][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=3).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[20][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=4).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[25][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=5).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[30][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=6).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[35][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=7).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[40][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=8).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[45][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=9).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[50][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=10).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    arr[55][grapc_cls_idx] = np.where(country in ccode_convert, grapc['GRAPC_res'].isel(time=11).sel(NGFBFC=grapc_class).to_numpy(), 0)\n",
    "    \n",
    "    years = list(np.linspace(1970, 2025, 56, dtype=\"int64\"))\n",
    "\n",
    "    for column_idx, column in enumerate(years[1:]):\n",
    "        if grapc_class[0:2] == 'RF':\n",
    "            current_year_fao = (faostat_yield[(faostat_yield['Year'] == column)&(faostat_yield['Area'] == country)&\n",
    "                                    (faostat_yield['IMAGE Classification']==grapc_class.replace('RF ',''))]['True Value'].sum())\n",
    "            \n",
    "            previous_year_fao = (faostat_yield[(faostat_yield['Year'] == column - 1)&(faostat_yield['Area'] == country)&\n",
    "                                            (faostat_yield['IMAGE Classification'] == grapc_class.replace('RF ',''))]['True Value'].sum())\n",
    "\n",
    "            current_year_grapc = arr[column_idx + 1]\n",
    "            previous_year_grapc = arr[column_idx]\n",
    "            \n",
    "            if current_year_grapc.any() == 0.0: \n",
    "                arr[column_idx + 1] = percent_change(previous_year_grapc, current_year_fao, previous_year_fao)\n",
    "        \n",
    "        elif grapc_class[0:2] == 'IR':\n",
    "            current_year_fao = (faostat_yield[(faostat_yield['Year'] == column)&(faostat_yield['Area'] == country)&\n",
    "                                    (faostat_yield['IMAGE Classification']==grapc_class.replace('IR ',''))]['True Value'].sum())\n",
    "            \n",
    "            previous_year_fao = (faostat_yield[(faostat_yield['Year'] == column - 1)&(faostat_yield['Area'] == country)&\n",
    "                                            (faostat_yield['IMAGE Classification'] == grapc_class.replace('IR ',''))]['True Value'].sum())\n",
    "            \n",
    "            current_year_grapc = arr[column_idx + 1]\n",
    "            previous_year_grapc = arr[column_idx]\n",
    "            \n",
    "            if current_year_grapc.any() == 0.0: \n",
    "                arr[column_idx + 1] = percent_change(previous_year_grapc, current_year_fao, previous_year_fao)\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldwide_gfrac_interp = []\n",
    "for cty_idx, country in enumerate(list(np.unique(ccode_convert))):\n",
    "    worldwide_gfrac_interp.append([])\n",
    "    for grapc_class_idx, grapc_class in enumerate(grapc_nfbfc_ir_rf):\n",
    "        crops_interp_all_expand = np.expand_dims(grapc_interp(grapc_class, grapc_class_idx, country), axis=-1)\n",
    "        worldwide_gfrac_interp[cty_idx].append(crops_interp_all_expand)\n",
    "\n",
    "worldwide_gfrac_interp_arr = np.concatenate(worldwide_gfrac_interp, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapc_interp_netcdf = xarray.Dataset({\n",
    "        \"grapc_interp\":([\"country\", \"time\", \"lat\", \"lon\", \"nfbfc\"], worldwide_grapc_interp_arr)\n",
    "    },\n",
    "    coords={\n",
    "        \"NFBFC\": np.array(grapc_nfbfc_ir_rf, dtype='<U35'),\n",
    "        \"country\": list(np.unique(ccode_convert)),\n",
    "        \"time\":pd.date_range(\"1970-01-01\", \"2022-01-01\", freq='YS'),\n",
    "        \"lon\":luh2_states_worldwide.coords[\"lon\"].to_numpy(),\n",
    "        \"lat\":luh2_states_worldwide.coords[\"lat\"].to_numpy()\n",
    "    })\n",
    "\n",
    "grapc_interp_netcdf.to_netcdf(\"c:/Users/HEFRY ANESTI/Downloads/GRAPC-INTERPOLATION-WORLDWIDE-1970_2022.nc\", mode='w', format=\"NETCDF4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
