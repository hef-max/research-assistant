{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.colors import BoundaryNorm, LinearSegmentedColormap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patheffects as path_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define varaible\n",
    "interval = 5\n",
    "list_year_default = list(range(1970, 2101, interval))\n",
    "\n",
    "start_time_year = 1970\n",
    "end_time_year = 1980\n",
    "\n",
    "start_year_ori = list_year_default.index(start_time_year)\n",
    "end_year_ori = list_year_default.index(end_time_year)\n",
    "\n",
    "start_time = f\"{start_time_year}-01-01\"\n",
    "end_time = f\"{end_time_year}-01-01\"\n",
    "frequensi = f\"{interval}YS\"\n",
    "\n",
    "start_year_analysis = start_year_ori + 1 # 1975\n",
    "end_year_analysis = end_year_ori + 1 # 2020\n",
    "\n",
    "coord_time = pd.date_range(start=start_time, end=end_time, freq=frequensi)\n",
    "label_start_time_ori = coord_time[start_year_ori]\n",
    "\n",
    "label_start_time_analysis = coord_time[start_year_analysis]\n",
    "label_end_time_analysis = coord_time[end_year_ori]\n",
    "\n",
    "dims = [\"time\", \"latitude\", \"longitude\"]\n",
    "dims_ngfbfc = [\"time\", \"NGFBFC\", \"latitude\", \"longitude\"]\n",
    "lat = 2160\n",
    "lon = 4320\n",
    "ocean_label = \"ocean\"\n",
    "\n",
    "account_period = len(coord_time) - start_year_ori\n",
    "analysis_period = account_period - 1\n",
    "\n",
    "Mg_to_kg = 1e3\n",
    "Mg_to_tonne = 1\n",
    "Kg_to_tonne = 1e-3\n",
    "km2_to_ha = 1e2\n",
    "ton_to_gigaton = 1e-9\n",
    "C_to_CO2 = 44/12\n",
    "N_to_N2O = 44/28\n",
    "CH4_to_CH4 = 1\n",
    "CO2_to_CO2eq = 1\n",
    "tonne_to_tonne = 1\n",
    "N2O_to_CO2eq = 265\n",
    "CH4_to_CO2eq = 28\n",
    "CVKGDMKGC = 0.48 \n",
    "RCH4CAGW = 5.63 #unit g CH4/ kg C\n",
    "ratioCH4toC = 0.00563 #(tonne CH4 /tonne C)\n",
    "CCH4toCH4 = 1\n",
    "RN2OCAGW = 0.09 #unit g N/ kg C\n",
    "ratioN2OtoC = 0.00009 #(tonne/tonne)\n",
    "CNtoN2O = 44/28\n",
    "\n",
    "std_dtype_str = \"<U64\"\n",
    "std_dtype_float = \"float32\"\n",
    "\n",
    "columns = ['IMAGE Region Name', 'time', 'NGFBFC']\n",
    "\n",
    "colors = {'plant based fibres': '#4D869C',\n",
    "          'non food, luxury, spices': '#7AB2B2',\n",
    "          'vegetables & fruits': '#CDE8E5',\n",
    "          'palm oil': '#FC4100',\n",
    "          'sugar crops': '#FFC55A',\n",
    "          'tropical roots & tubers': '#8E3E63',\n",
    "          'temperate roots & tubers': '#D2649A',\n",
    "          'tropical oil crops': '#03AED2',\n",
    "          'temperate oil crops': '#68D2E8',\n",
    "          'soybeans': '#5F6F52',\n",
    "          'pulses': '#A9B388',\n",
    "          'temperate cereals': '#FC819E',\n",
    "          'tropical cereals': '#F7418F',\n",
    "          'maize': '#FFF455',\n",
    "          'rice': '#FFEFEF',\n",
    "          'wheat': '#F7C566',\n",
    "          \"pasture\": '#ACE1AF'}\n",
    "\n",
    "palettes = {'Oceania': '#B3C8CF','Japan':'#E5E483','Korea region':'#D2D180','China region':'#B2B377','Rest of South Asia':'#EF9595',\n",
    "                'India':'#EFB495','Indonesia region':'#FF8A08','Southeast Asia':'#FFC100','Middle East':'#1B1A55','Central Asia':'#535C91',\n",
    "                'Russia region':'#9290C3','Rest of Southern Africa':'#C75B7A','South Africa':'#710019','Eastern Africa':'#D43790',\n",
    "                'Western Africa':'#EC8FD0','Northern Africa':'#F2C5E0', 'Turkey':'#6F4E37','Ukraine region':'#A67B5B','Central Europe':'#ECB176',\n",
    "                'Western Europe':'#FED8B1', 'Rest of South America':'#254336','Brazil':'#00b2b2','Central America':'#B3E2A7','Mexico':'#003285',\n",
    "                'USA':'#40A2E3','Canada':'#BBE2EC'}\n",
    "\n",
    "\n",
    "palette = {\n",
    "    'maize - Brazil': \"#00b2b2\", 'soybeans - Brazil': \"#00b2b2\", 'pulses - Brazil': \"#00b2b2\",\n",
    "    'wheat - China region': \"#B2B377\", 'rice - China region': \"#B2B377\", 'vegetables & fruits - China region': \"#B2B377\",\n",
    "    'non food, luxury, spices - Indonesia region': \"#FF8A08\", 'palm oil - Indonesia region': \"#FF8A08\", 'tropical oil crops - Indonesia region': \"#FF8A08\",\n",
    "    'tropical roots & tubers - Indonesia region':\"#FF8A08\", 'pulses - Indonesia region':\"#FF8A08\", 'sugar crops - Indonesia region':\"#FF8A08\",\n",
    "    'soybeans - Rest of South America': \"#254336\", 'rice - Rest of South Asia': \"#EF9595\",'wheat - Rest of South Asia': \"#EF9595\",\n",
    "    'rice - India': \"#EFB495\",'rice - Southeast Asia': \"#FFC100\", 'tropical oil crops - Southeast Asia': \"#FFC100\", 'non food, luxury, spices - Southeast Asia': \"#FFC100\",\n",
    "    'sugar crops - Southeast Asia': \"#FFC100\",  'tropical cereals - Western Africa': \"#EC8FD0\", 'tropical roots & tubers - Western Africa': \"#EC8FD0\",\n",
    "    'sugar crops - Western Europe': \"#FED8B1\"\n",
    "}\n",
    "\n",
    "\n",
    "markers = {\n",
    "    'rice - China region': \"P\", 'rice - Rest of South Asia': \"P\",\n",
    "    'rice - India': \"P\",'rice - Southeast Asia': \"P\", 'palm oil - Indonesia region': 's', \n",
    "    'maize - Brazil': 'o', 'pulses - Brazil': \"P\", 'soybeans - Brazil': 's',\n",
    "    'vegetables & fruits - China region': \"P\", 'wheat - China region': 's', 'wheat - Rest of South Asia': 's',\n",
    "    'non food, luxury, spices - Indonesia region': 'X', 'non food, luxury, spices - Southeast Asia': 'o', \n",
    "    'soybeans - Rest of South America': 'o', 'tropical oil crops - Southeast Asia': 's','tropical oil crops - Indonesia region': \"*\",\n",
    "    'tropical cereals - Western Africa': 'X', 'tropical roots & tubers - Western Africa': \"P\", 'tropical roots & tubers - Indonesia region': \"D\",\n",
    "    'sugar crops - Western Europe': 'o', 'sugar crops - Southeast Asia': 'o', 'sugar crops - Indonesia region' : 'o',\n",
    "    'pulses - Indonesia region':\"d\"\n",
    "}\n",
    "\n",
    "legend_order = [\n",
    "    'wheat - China region',\n",
    "    'rice - Southeast Asia','rice - Rest of South Asia','rice - China region',\n",
    "    'maize - Brazil', 'palm oil - Indonesia region', 'soybeans - Brazil', \n",
    "    'tropical oil crops - Indonesia region', \n",
    "    'sugar crops - Western Europe','sugar crops - Southeast Asia','sugar crops - Indonesia region', \n",
    "    'tropical roots & tubers - Indonesia region',\n",
    "    'non food, luxury, spices - Indonesia region',\n",
    "    'tropical cereals - Western Africa',\n",
    "    'pulses - Indonesia region',]\n",
    "\n",
    "columns1 = ['Agricultural Transition Emission','Natural Vegetation to Agriculture Emission', 'N2O Land Clearing',\n",
    "'CO2 Drained Peatland', 'CH4 Drained Peatland','N2O Drained Peatland', \n",
    "'N2O Synthetic Fertilizer','N2O Manure Fertilizer',\n",
    "'CH4 Agriculture Waste Burning', 'N2O Agriculture Waste Burning','N2O Agriculture Residues',\n",
    "'CH4 Wetland Rice']\n",
    "\n",
    "colors1 = [\n",
    "          '#47663B', #Agri Trans\n",
    "          '#72BF78', #LUC Agri\n",
    "          '#C2FFC7', #N2O Land clearing\n",
    "          '#4A628A', #CO2 peat\n",
    "          '#7AB2D3', #CH4 peat\n",
    "          '#B9E5E8', #NO2 peat\n",
    "          '#FA812F', #manure\n",
    "          '#FAB12F', #synthetic\n",
    "          '#FFE31A', #burning CH4\n",
    "          '#FFF100', #burning N2O\n",
    "          '#FA4032', #agri residue\n",
    "          '#A04747', #rice\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = pd.read_excel(\"/INPUT_DATA/ISO-3166-Country-Code_REV.xlsx\", engine=\"openpyxl\")\n",
    "filtred_Ccode = country_code[[\"ISO Country\", \"IMAGE Region Name\"]]\n",
    "\n",
    "def matrixMultiply(data1, data2):\n",
    "    return np.nan_to_num(np.multiply(data1, data2))\n",
    "\n",
    "def fractionDivision(data1, data2):\n",
    "    return np.nan_to_num(np.divide(data1, data2))\n",
    "\n",
    "def save_netcdf(out_file_name, variabel, dims, input_data, coord, time):\n",
    "    netcdf = xr.Dataset({\n",
    "        variabel:(dims, input_data)\n",
    "    }, coords={\n",
    "        \"time\": time,\n",
    "        \"latitude\": coord.coords[\"latitude\"].to_numpy(),\n",
    "        \"longitude\": coord.coords[\"longitude\"].to_numpy()\n",
    "    })\n",
    "\n",
    "    netcdf.to_netcdf(f\"/OUTPUT_DATA/{out_file_name}.NC\", mode='w', format=\"NETCDF4\")\n",
    "    return netcdf\n",
    "\n",
    "def save_netcdf_variabel(out_file_name, variabel, input_data, coord, time):\n",
    "    netcdf = xr.Dataset(\n",
    "    coords={\n",
    "        \"time\": time,\n",
    "        \"latitude\": coord.coords[\"latitude\"].to_numpy(),\n",
    "        \"longitude\": coord.coords[\"longitude\"].to_numpy(),\n",
    "    })\n",
    "    coords = (\"time\", \"latitude\", \"longitude\")\n",
    "    data_vars = {\n",
    "        label: (coords, input_data[i]) for i, label in enumerate(variabel)\n",
    "    }\n",
    "    netcdf = netcdf.assign(data_vars)\n",
    "\n",
    "    netcdf.to_netcdf(f\"/OUTPUT_DATA/{out_file_name}.NC\", mode='w', format=\"NETCDF4\")\n",
    "    return netcdf\n",
    "\n",
    "def save_netcdf_ngfbfc(out_file_name, variabel, dims, input_data, input_ngfbfc, coord, time):\n",
    "    netcdf = xr.Dataset({\n",
    "        variabel:(dims, input_data)\n",
    "    },coords={\n",
    "        \"time\": time,\n",
    "        \"NGFBFC\" : input_ngfbfc,\n",
    "        \"latitude\": coord.coords[\"latitude\"].to_numpy(),\n",
    "        \"longitude\": coord.coords[\"longitude\"].to_numpy()\n",
    "    })\n",
    "\n",
    "    netcdf.to_netcdf(f\"/OUTPUT_DATA/{out_file_name}.NC\", mode='w', format=\"NETCDF4\")\n",
    "    return netcdf\n",
    "\n",
    "def Gprocess(file_name, length, year, input_data1, input_data2, ton):\n",
    "    Gdata = xr.open_dataset(f\"/INPUT_DATA/{file_name}.NC\", engine=\"h5netcdf\")\n",
    "    Gdata = Gdata.isel(time=slice(start_year_analysis, end_year_analysis))\n",
    "\n",
    "    emission_Gdata_ton_ha = Gdata[f'{file_name}'] * ton / km2_to_ha\n",
    "\n",
    "    if file_name == \"GFERTILIZER\":\n",
    "        GFERTILIZER_manure = Gdata.sel(NFERTSMT=b'manure stable on cropland                         ')\n",
    "        emission_GFERTILIZER_ton_ha = GFERTILIZER_manure[f\"{file_name}\"] * Mg_to_tonne / km2_to_ha\n",
    "        emission_ton = emission_GFERTILIZER_ton_ha * input_data1\n",
    "        emission_GtTon = emission_ton * (N_to_N2O) * ton_to_gigaton * 5\n",
    "\n",
    "    else:\n",
    "        emission_ton = matrixMultiply(emission_Gdata_ton_ha, input_data1)\n",
    "        emission_GtTon = emission_ton * (N_to_N2O) * ton_to_gigaton * 5\n",
    "\n",
    "        if file_name == \"GECH4RI\":\n",
    "            data_zeros = np.zeros((year, 2160, 4320), dtype=\"float32\")\n",
    "            for i in range(length):\n",
    "                for n in range(year):\n",
    "                    data_zeros[n] = matrixMultiply(emission_GtTon[n], input_data2[i][n])\n",
    "\n",
    "            return data_zeros\n",
    "\n",
    "    data_zeros = np.zeros((length, year, 2160, 4320), dtype=\"float32\")\n",
    "    for i in range(length):\n",
    "        for n in range(year):\n",
    "            data_zeros[i][n] = matrixMultiply(emission_GtTon[n], input_data2[i][n])\n",
    "\n",
    "    return data_zeros\n",
    "\n",
    "def netcdf_to_excel(out_file_name, input_data, label, columns_name, index_data, column_data, agg):\n",
    "    df = input_data.isel(time=0).to_dataframe()\n",
    "    df_pivot = pd.pivot_table(df, values=label, index=index_data, columns=column_data, aggfunc=agg, fill_value=0)\n",
    "    df_pivot = df_pivot.stack(level=0, future_stack=True)\n",
    "    df_pivot.columns = pd.to_datetime(df_pivot.columns, format='%d/%m/%Y %H.%M.%S').year\n",
    "\n",
    "    df_result = df_pivot.reset_index()\n",
    "    df_result.rename(columns={'level_1': columns_name}, inplace=True)\n",
    "    region_merge = pd.merge(left=df_result, right=filtred_Ccode, left_on=\"country_name\", right_on=\"ISO Country\")\n",
    "    region_merge.to_excel(f\"/OUTPUT_DATA/{out_file_name}.xlsx\", index=False)\n",
    "    return region_merge\n",
    "\n",
    "def netcdf_to_excel_peryear(out_file_name, input_data, year, columns_name, input_label, index_data, column_data, agg):\n",
    "    frames = []\n",
    "    n = 0\n",
    "    while n < year:\n",
    "        df = input_data.isel(time=n).to_dataframe()\n",
    "        df_table = pd.pivot_table(df, values=input_label, index=index_data, columns=column_data, aggfunc=agg, fill_value=0)\n",
    "        df_table = df_table.stack(level=0, future_stack=True)\n",
    "\n",
    "        df_table.columns = pd.to_datetime(df_table.columns, format='%d/%m/%Y %H.%M.%S').year\n",
    "        df_index = df_table.reset_index()\n",
    "        df_index.rename(columns={'level_1': columns_name}, inplace=True)\n",
    "        frames.append(df_index)\n",
    "        n += 1\n",
    "\n",
    "    df_result = reduce(lambda left, right: pd.merge(left, right, on=[index_data[0], columns_name]), frames)\n",
    "    df_result = df_result.replace([np.inf, -np.inf], np.nan)\n",
    "    df_result = df_result.fillna(0)\n",
    "    region_merge = pd.merge(left=df_result, right=filtred_Ccode, left_on=\"country_name\", right_on=\"ISO Country\")\n",
    "\n",
    "    region_merge.to_excel(f\"/OUTPUT_DATA/{out_file_name}.xlsx\", index=False)\n",
    "    return region_merge\n",
    "\n",
    "def gfrac_to_excel(out_file_name, input_data, year, columns_name, input_label, index_data, column_data, agg):\n",
    "    dataframes = []\n",
    "    for i, ngfbfc in enumerate(input_label):\n",
    "        frames = []\n",
    "        n = 0\n",
    "        df_ngfbfc = input_data[ngfbfc]\n",
    "        while n < year:\n",
    "            df = df_ngfbfc.isel(time=n).to_dataframe()\n",
    "            df_table = pd.pivot_table(df, index=index_data, columns=column_data, aggfunc=agg, fill_value=0)\n",
    "            df_table = df_table.stack(level=0, future_stack=True)\n",
    "\n",
    "            df_table.columns = pd.to_datetime(df_table.columns, format='%d/%m/%Y %H.%M.%S').year\n",
    "            df_index = df_table.reset_index()\n",
    "            df_index.rename(columns={'level_1': columns_name}, inplace=True)\n",
    "            frames.append(df_index)\n",
    "            n += 1\n",
    "            \n",
    "        df_result = reduce(lambda left, right: pd.merge(left, right, on=[index_data[0], columns_name]), frames)\n",
    "        df_result = df_result.replace([np.inf, -np.inf], np.nan)\n",
    "        df_result = df_result.fillna(0)\n",
    "        dataframes.append(df_result)\n",
    "\n",
    "    merged_df = pd.concat(dataframes, axis=0, ignore_index=True).fillna(0)\n",
    "    region_merge = pd.merge(left=merged_df, right=filtred_Ccode, left_on=\"country_name\", right_on=\"ISO Country\")\n",
    "    region_merge.to_excel(f\"/OUTPUT_DATA/{out_file_name}.xlsx\", index=False)\n",
    "\n",
    "    return region_merge\n",
    "\n",
    "def ngfbfc_processing(df):\n",
    "    try:\n",
    "        if \"type\" in df.columns.to_list():\n",
    "            df = df.rename(columns={\"type\": \"NGFBFC\"}) \n",
    "\n",
    "        if \"NGFBFC\" in df.columns:\n",
    "            df['NGFBFC'] = df['NGFBFC'].str.lower()\n",
    "            if 'grass' in df['NGFBFC'].unique():\n",
    "                df['NGFBFC'] = df['NGFBFC'].replace('grass', 'pasture')\n",
    "            df['NGFBFC'] = df['NGFBFC'].replace(\"oil & palm fruit\", \"palm oil\")\n",
    "            df['NGFBFC'] = df['NGFBFC'].replace(\"other non-food & luxury & spices\", \"non food, luxury, spices\")\n",
    "            df['NGFBFC'] = df['NGFBFC'].replace('other temperate cereals', 'temperate cereals')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"error: {e}\")\n",
    "        return df\n",
    "\n",
    "def region_processing(df):\n",
    "    try:\n",
    "        df['IMAGE Region Name'] = df['IMAGE Region Name'].replace('Kazakhstan region', 'Central Asia').replace('C. Europe', 'Central Europe').replace('E. Africa', 'Eastern Africa').replace('N. Africa', 'Northern Africa')\n",
    "        df['IMAGE Region Name'] = df['IMAGE Region Name'].replace('Rest C. America', 'Central America').replace('Rest S. Africa', 'Rest of Southern Africa').replace('Rest S. America', 'Rest of South America')\n",
    "        df['IMAGE Region Name'] = df['IMAGE Region Name'].replace('Rest S. Asia', 'Rest of South Asia').replace('SE. Asia', 'Southeast Asia').replace('Rest S. America', 'Rest of South America')\n",
    "        df['IMAGE Region Name'] = df['IMAGE Region Name'].replace('W. Africa', 'Western Africa').replace('W. Europe', 'Western Europe').replace('Russia', 'Russia region')\n",
    "        df['IMAGE Region Name'] = df['IMAGE Region Name'].replace('Indonesia', 'Indonesia region').replace('China', 'China region').replace('Korea', 'Korea region')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"error: {e}\")\n",
    "        return df\n",
    "\n",
    "def custom_mean(x):\n",
    "  \"\"\"Calculates the mean of non-zero values.\"\"\"\n",
    "  non_zero_values = x[x > 0]\n",
    "  return non_zero_values.sum() / len(non_zero_values) if len(non_zero_values) > 0 else 0\n",
    "\n",
    "def get_top_n(df, category_col, value_col, n):\n",
    "    return df.groupby(category_col).apply(lambda x: x.nlargest(n, value_col)).reset_index(drop=True)\n",
    "\n",
    "def get_angular_position(NGFBFC_name, NGFBFCs_list):\n",
    "    \"\"\"Calculate the angular position of a NGFBFC in the chart\"\"\"\n",
    "    idx = NGFBFCs_list.index(NGFBFC_name)\n",
    "    return (idx * 360.0 / len(NGFBFCs_list) + 90) % 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "glct = xr.open_dataset(\"/INPUT_DATA/GLCT.NC\")\n",
    "glctdf = pd.read_excel(\"/INPUT_DATA/GLCT.xlsx\", engine=\"openpyxl\", sheet_name=\"Sheet5\", index_col=False)\n",
    "\n",
    "## Step 1\n",
    "# S1.AM1.A\n",
    "label_map = {\n",
    "    1: 'agri', 2: 'grass', 3: 'carb', 4: 'rfab', 5: 'rftm',\n",
    "    6: 'biof', 7: 'ice', 8: 'tund', 9: 'tuwd', 10: 'bore',\n",
    "    11: 'ccfo', 12: 'tmfo', 13: 'tdfo', 14: 'wmfo', 15: 'stepp',\n",
    "    16: 'dsrt', 17: 'scrb', 18: 'svna', 19: 'trow', 20: 'trof'\n",
    "}\n",
    "\n",
    "glct_labels = glct['GLCT'].isel(time=slice(start_year_ori, end_year_analysis)).fillna(0).values.astype(int)\n",
    "glct_class = np.array([label_map.get(label_id, ocean_label) for label_id in glct_labels.ravel()]).reshape(glct_labels.shape)\n",
    "\n",
    "glct_NICK_AM1_netcdf = save_netcdf(out_file_name=\"GLCT_trans\", variabel=\"GLCT_trans\", dims=dims, input_data=glct_class, coord=glct, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "glct5mins_trans_AM1 = np.zeros((analysis_period, lat, lon), dtype=std_dtype_str)\n",
    "for n in range(start_year_ori, analysis_period):\n",
    "    prev_nicknames_with_to = np.char.add(glct_class[n], '_to_')\n",
    "    glct5mins_trans_AM1[n] = np.char.add(prev_nicknames_with_to, glct_class[n+1])\n",
    "\n",
    "glct_trans_AM1_netcdf = save_netcdf(out_file_name=\"GLCT_trans\", variabel=\"GLCT_trans\", dims=dims, input_data=glct5mins_trans_AM1, coord=glct, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "land_use_transitions_postif = dict(glctdf[['Classification_1st', 'Classification_2nd_postif']].values)\n",
    "land_use_transitions_negatif = dict(glctdf[['Classification_1st', 'Classification_2nd_negatif']].values)\n",
    "land_use_transitions = dict(glctdf[['trans_name', 'Classification_1st']].values)\n",
    "glct_class1st_AM1 = np.array([land_use_transitions.get(label_id, 'ocean_to_ocean') for label_id in glct5mins_trans_AM1.ravel()]).reshape(glct5mins_trans_AM1.shape)\n",
    "\n",
    "trans_glct1st_AM1_netcdf = save_netcdf(out_file_name=\"GLCT_1st\", variabel=\"GLCT_1st\", dims=dims, input_data=glct_class1st_AM1, coord=glct, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "# S1.AM23.A\n",
    "glct5mins_trans_AM23 = np.zeros((1, lat, lon), dtype=std_dtype_str)\n",
    "prev_nicknames_with_to = np.char.add(glct_class[start_year_ori], '_to_')\n",
    "glct5mins_trans_AM23[0] = np.char.add(prev_nicknames_with_to, glct_class[(account_period - start_year_analysis)])\n",
    "\n",
    "glct_trans_AM23_netcdf = save_netcdf(out_file_name=\"GLCT_trans\", variabel=\"GLCT_trans\", dims=dims, input_data=glct5mins_trans_AM23, coord=glct, time=pd.to_datetime([label_end_time_analysis]))\n",
    "\n",
    "glct_class1st_AM23 = np.array([land_use_transitions.get(label_id, 'ocean_to_ocean') for label_id in glct5mins_trans_AM23.ravel()]).reshape(glct5mins_trans_AM23.shape)\n",
    "\n",
    "trans_glct1st_AM23_netcdf = save_netcdf(out_file_name=\"GLCT_1st\", variabel=\"GLCT_1st\", dims=dims, input_data=glct_class1st_AM23, coord=glct, time=pd.to_datetime([label_end_time_analysis]))\n",
    "\n",
    "# S1.AM1.B\n",
    "# Country\n",
    "luh_static = xr.open_dataset(\"/INPUT_DATA/CCODE_RASTER.nc\")\n",
    "country_code = pd.read_excel(\"/INPUT_DATA/ISO-3166-Country-Code_REV.xlsx\", engine=\"openpyxl\")\n",
    "gbiomass_5min = xr.open_dataset(\"/INPUT_DATA/GBIOMASS.NC\")\n",
    "\n",
    "ccode_iso = list(country_code['country-code'])\n",
    "cname_iso = list(country_code['ISO Country'])\n",
    "\n",
    "ccode_worldwide_int = luh_static['ccode'].to_numpy().astype('int64')\n",
    "ccode_convert = np.zeros((lat, lon), dtype=std_dtype_str)\n",
    "cname_dict = {}\n",
    "\n",
    "for idx, ccode in enumerate(ccode_iso):\n",
    "    cname_dict[ccode] = cname_iso[idx]\n",
    "\n",
    "for x in range(lat):\n",
    "    for y in range(lon):\n",
    "        if (ccode_worldwide_int[x][y] in cname_dict.keys()):\n",
    "            ccode_convert[x][y] = cname_dict[ccode_worldwide_int[x][y]]\n",
    "        else:\n",
    "            ccode_convert[x][y] = ocean_label\n",
    "\n",
    "country_coords = xr.Dataset({\"country\": ([\"latitude\", \"longitude\"], ccode_convert)},\n",
    "                         coords={ \"longitude\": gbiomass_5min.coords[\"longitude\"].to_numpy(),\n",
    "                                  \"latitude\": gbiomass_5min.coords[\"latitude\"].to_numpy()})\n",
    "\n",
    "gbiomass_nbpsum = np.zeros((account_period, lat, lon), dtype=std_dtype_float)\n",
    "gbiomass_5min = gbiomass_5min.drop_sel(NBP=b'long lifetime timber                              ')\n",
    "gbiomass_5min = gbiomass_5min.drop_sel(NBP=b'short lifetime timber                             ')\n",
    "gbiomass_5min = gbiomass_5min.drop_sel(NBP=b'charcoal                                          ')\n",
    "gbiomass_5min = gbiomass_5min.drop_sel(NBP=b'humus                                             ')\n",
    "gbiomass_5min = gbiomass_5min.drop_sel(NBP=b'litter                                            ')\n",
    "gbiomass_5min = gbiomass_5min.drop_sel(NBP=b'roots                                             ')\n",
    "\n",
    "for n in range(account_period):\n",
    "    gbiomass_nbpsum[n] = gbiomass_5min['GBIOMASS'].isel(time=n).sum(dim='NBP')\n",
    "\n",
    "gbiomass_biomass_sumdim_netcdf = save_netcdf(out_file_name=\"gbiomass_biomass_sumdim\", variabel=\"gbiomass_biomass_sumdim\", dims=dims, input_data=gbiomass_nbpsum, coord=gbiomass_5min, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "valid_transitions = ['agri_to_biof', 'agri_to_natveg', 'biof_to_natveg', 'grass_to_biof', 'grass_to_natveg', 'natveg_to_agri', 'natveg_to_biof', 'natveg_to_grass']\n",
    "gbiomass_biomass_sumdim_manip = np.zeros((account_period, lat, lon), dtype=std_dtype_float)\n",
    "for n in range(account_period): \n",
    "    if n <= account_period - 3:\n",
    "        current_glct = trans_glct1st_AM1_netcdf['GLCT_1st'].isel(time=n).values\n",
    "\n",
    "        gbiomass_biomass_sumdim_manip[n + 1] = np.where(\n",
    "            np.isin(current_glct, list(valid_transitions)),\n",
    "            gbiomass_biomass_sumdim_netcdf['gbiomass_biomass_sumdim'].isel(time=n + 2),\n",
    "            gbiomass_biomass_sumdim_netcdf['gbiomass_biomass_sumdim'].isel(time=n + 1)\n",
    "        )\n",
    "\n",
    "gbiomass_biomass_sumdim_manip_netcdf = save_netcdf(out_file_name=\"gbiomass_biomass_sumdim_manip\", variabel=\"gbiomass_biomass_sumdim_manip\", dims=dims, input_data=gbiomass_biomass_sumdim_manip, coord=gbiomass_biomass_sumdim_netcdf, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "gbiomass_selisih = np.zeros((analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "for n in range(analysis_period):\n",
    "    gbiomass_selisih[n] = gbiomass_biomass_sumdim_manip_netcdf['gbiomass_biomass_sumdim_manip'].isel(time=n).to_numpy() - gbiomass_biomass_sumdim_manip_netcdf['gbiomass_biomass_sumdim_manip'].isel(time=n+1).to_numpy()\n",
    "\n",
    "gbiomass_selisih_AM1_netcdf = save_netcdf(out_file_name=\"gbiomass_manip_selisih\", variabel=\"gbiomass_manip_selisih\", dims=dims, input_data=gbiomass_selisih, coord=gbiomass_5min, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "gbiomass_selisih_AM1_netcdf = gbiomass_selisih_AM1_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "\n",
    "# S1.AM23.B\n",
    "gbiomass_selisih = np.zeros((1, lat, lon), dtype=std_dtype_float)\n",
    "gbiomass_selisih[0] = gbiomass_biomass_sumdim_manip_netcdf['gbiomass_biomass_sumdim_manip'].isel(time=start_year_ori).to_numpy() - gbiomass_biomass_sumdim_manip_netcdf['gbiomass_biomass_sumdim_manip'].isel(time=end_year_ori).to_numpy()\n",
    "\n",
    "gbiomass_selisih_AM23_netcdf = save_netcdf(out_file_name=\"gbiomass_manip_selisih\", variabel=\"gbiomass_manip_selisih\", dims=dims, input_data=gbiomass_selisih, coord=gbiomass_5min, time=pd.to_datetime([label_end_time_analysis]))\n",
    "\n",
    "## Step 2\n",
    "# S2.AM1.A\n",
    "garea = xr.open_dataset(\"/INPUT_DATA/GAREA.NC\")\n",
    "\n",
    "LUC_category = [\"Agricultural Transition Emission\", \"Agricultural Transition Sequestration\", \"LUC Crops Emission\", \"LUC Crops Sequestration\", \"Forest Harvest\",\"Forest Growth\",\n",
    "            \"Land Abandonment Emission\", \"Land Abandonment Sequestration\", \"LUC Rangeland Emission\", \"LUC Rangeland Sequestration\", \"LUC Biofuel Emission\", \"LUC Biofuel Sequestration\"]\n",
    "\n",
    "len_category = len(LUC_category)\n",
    "\n",
    "garea_ha_7020 = matrixMultiply(garea['GAREA'].to_numpy(), km2_to_ha)\n",
    "garea_ha_7520 = matrixMultiply(garea['GAREA'].isel(time=slice(start_year_analysis, end_year_analysis)).to_numpy(), km2_to_ha)\n",
    "\n",
    "gbiomass_tonCha = gbiomass_selisih_AM1_netcdf['gbiomass_manip_selisih'] * Mg_to_tonne / km2_to_ha\n",
    "emission_C_ton = matrixMultiply(gbiomass_tonCha, garea_ha_7520)\n",
    "emission_GtTon_CO2 = emission_C_ton * (C_to_CO2) * ton_to_gigaton\n",
    "\n",
    "emission_CO2_AM1_netcdf = save_netcdf(out_file_name=\"emission_CO2\", variabel=\"emission_CO2\", dims=dims, input_data=emission_GtTon_CO2, coord=garea, time=pd.date_range(start=label_start_time_analysis, end=end_time, freq=frequensi))\n",
    "ds = xr.merge([trans_glct1st_AM1_netcdf, emission_CO2_AM1_netcdf], compat='no_conflicts', join='outer', fill_value=0)\n",
    "\n",
    "emission_or_sequestration = ds['emission_CO2'].values > 0\n",
    "glct_labels = ds['GLCT_1st'].values.astype(str)\n",
    "glct_class_2nd = np.where(emission_or_sequestration, np.array([land_use_transitions_postif.get(label_id, '') for label_id in glct_labels.ravel()]).reshape(glct_labels.shape),\\\n",
    "                          np.array([land_use_transitions_negatif.get(label_id, '') for label_id in glct_labels.ravel()]).reshape(glct_labels.shape))\n",
    "\n",
    "trans_glct_2nd_netcdf = save_netcdf(out_file_name=\"trans_glct\", variabel=\"trans_glct\", dims=dims, input_data=glct_class_2nd, coord=garea, time=pd.date_range(start=label_start_time_analysis, end=end_time, freq=frequensi))\n",
    "ds2 = xr.merge([trans_glct_2nd_netcdf, emission_CO2_AM1_netcdf], compat='no_conflicts', join='outer', fill_value=0)\n",
    "\n",
    "emission_CO2_occur = np.zeros((len_category, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "for i, luc in enumerate(LUC_category):\n",
    "    for n in range(analysis_period):\n",
    "        emission_CO2_occur[i][n] = np.where(ds2['trans_glct'].isel(time=n) == luc, ds2['emission_CO2'].isel(time=n), 0)\n",
    "\n",
    "emission_CO2_LUC_Category_AM1_netcdf = save_netcdf_variabel(out_file_name=\"emission_CO2_AM1\", variabel=LUC_category, input_data=emission_CO2_occur, coord=garea, time=pd.date_range(start=label_start_time_analysis, end=end_time, freq=frequensi))\n",
    "emission_CO2_LUC_Category_AM1_netcdf = emission_CO2_LUC_Category_AM1_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "emission_CO2_LUC_Category_AM1_excel = netcdf_to_excel_peryear(out_file_name=\"emission_CO2_AM1\", year=analysis_period, input_data=emission_CO2_LUC_Category_AM1_netcdf, input_label=LUC_category, columns_name=\"LUC_Category\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "# S2.AM23.A\n",
    "garea_ha_1975 = matrixMultiply(garea['GAREA'].isel(time=1).to_numpy(), km2_to_ha)\n",
    "gbiomass_tonCha = gbiomass_selisih_AM23_netcdf['gbiomass_manip_selisih'] * Mg_to_tonne / km2_to_ha\n",
    "\n",
    "emission_C_ton = matrixMultiply(gbiomass_tonCha, garea_ha_1975)\n",
    "emission_GtTon_CO2 = emission_C_ton * (C_to_CO2) * ton_to_gigaton\n",
    "\n",
    "emission_CO2_AM23_netcdf = save_netcdf(out_file_name=\"emission_CO2\", variabel=\"emission_CO2\", dims=dims, input_data=emission_GtTon_CO2, coord=garea, time=pd.to_datetime([label_end_time_analysis]))\n",
    "ds = xr.merge([trans_glct1st_AM23_netcdf, emission_CO2_AM23_netcdf], compat='no_conflicts', join='outer', fill_value=0)\n",
    "\n",
    "emission_or_sequestration = ds['emission_CO2'].values > 0\n",
    "glct_labels = ds['GLCT_1st'].values.astype(str)\n",
    "glct_class_2nd = np.where(emission_or_sequestration, np.array([land_use_transitions_postif.get(label_id, '') for label_id in glct_labels.ravel()]).reshape(glct_labels.shape),\\\n",
    "                          np.array([land_use_transitions_negatif.get(label_id, '') for label_id in glct_labels.ravel()]).reshape(glct_labels.shape))\n",
    "\n",
    "trans_glct_2nd_netcdf = save_netcdf(out_file_name=\"trans_glct\", variabel=\"trans_glct\", dims=dims, input_data=glct_class_2nd, coord=garea, time=pd.to_datetime([label_end_time_analysis]))\n",
    "ds2 = xr.merge([trans_glct_2nd_netcdf, emission_CO2_AM23_netcdf], compat='no_conflicts', join='outer', fill_value=0)\n",
    "\n",
    "emission_CO2_occur = np.zeros((len_category, 1, lat, lon), dtype=std_dtype_float)\n",
    "for i, luc in enumerate(LUC_category):\n",
    "    emission_CO2_occur[i][0] = np.where(ds2['trans_glct'].isel(time=0) == luc, ds2['emission_CO2'].isel(time=0), 0)\n",
    "\n",
    "emission_CO2_AM2_AM3_netcdf = save_netcdf_variabel(out_file_name=\"emission_CO2_AM2_AM3\", variabel=LUC_category, input_data=emission_CO2_occur, coord=garea, time=pd.to_datetime([label_end_time_analysis]))\n",
    "emission_CO2_AM2_AM3_netcdf = emission_CO2_AM2_AM3_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "emission_CO2_AM2_AM3_excel = netcdf_to_excel(out_file_name=\"emission_CO2_AM2_AM3\", input_data=emission_CO2_AM2_AM3_netcdf, label=LUC_category, columns_name=\"LUC_Category\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "## Step 3\n",
    "gfrac5min = xr.open_dataset(\"/INPUT_DATA/GFRAC.NC\")\n",
    "gfrac_32i = gfrac5min.drop_sel(NGFBFC=b'grass                                             ')\n",
    "gfrac_32i = gfrac5min.drop_sel(NGFBFC=b'Grains (biofuel)                                  ')\n",
    "gfrac_32i = gfrac5min.drop_sel(NGFBFC=b'Oil crops (biofuel)                               ')\n",
    "gfrac_32i = gfrac5min.drop_sel(NGFBFC=b'Sugar cane (biofuel)                              ')\n",
    "gfrac_32i = gfrac5min.drop_sel(NGFBFC=b'Woody biofuel                                     ')\n",
    "gfrac_32i = gfrac5min.drop_sel(NGFBFC=b'Non-woody biofuel                                 ')\n",
    "gfrac_ngfbfc32i = [element.strip() for element in gfrac_32i.coords['NGFBFC'].data.astype('str').tolist()]\n",
    "gfrac_32i = gfrac_32i.assign_coords(NGFBFC=gfrac_ngfbfc32i)\n",
    "\n",
    "gfracarea32 = np.zeros((len(gfrac_ngfbfc32i), account_period, lat, lon), dtype=\"float32\")\n",
    "for i, ngfbfc in enumerate(gfrac_ngfbfc32i):\n",
    "    for n in range(account_period):\n",
    "        gfracarea32[i][n] = matrixMultiply(gfrac_32i.isel(time=n).sel(NGFBFC=ngfbfc), garea_ha_7020[n])\n",
    "\n",
    "gfrac32_netcdf = save_netcdf_variabel(out_file_name=\"GFRACarea_32_concat\", variabel=gfrac_ngfbfc32i, input_data=gfracarea32, coord=garea, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "gfrac32_netcdf = gfrac32_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "gfrac32_excel = gfrac_to_excel(out_file_name=\"GFRACarea_32_concat\", year=account_period, input_data=gfrac32_netcdf, input_label=gfrac_ngfbfc32i, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "gfrac_ngfbfc_ori = gfrac5min.coords['NGFBFC'].data.tolist()\n",
    "gfrac_ngfbfc_ir_rf = []\n",
    "gfrac_ngfbfc_rf = []\n",
    "gfrac_ngfbfc_ir = []\n",
    "\n",
    "for i, gfrac_cls in enumerate(gfrac_ngfbfc_ori):\n",
    "    gfrac_cls_str = gfrac_cls.decode('utf-8') \n",
    "    if np.char.replace(gfrac_cls_str, ' ', '') == \"grass\":\n",
    "        gfrac_ngfbfc_ir.append(gfrac_cls)\n",
    "        gfrac_ngfbfc_rf.append(gfrac_cls)\n",
    "        gfrac_ngfbfc_ir_rf.append(gfrac_cls)\n",
    "    elif gfrac_cls[0:2] == b'RF':\n",
    "        gfrac_ngfbfc_rf.append(gfrac_cls)\n",
    "        gfrac_ngfbfc_ir_rf.append(gfrac_cls[3:])\n",
    "    elif gfrac_cls[0:2] == b'IR':\n",
    "        gfrac_ngfbfc_ir.append(gfrac_cls)\n",
    "        gfrac_ngfbfc_ir_rf.append(gfrac_cls[3:])\n",
    "\n",
    "gfrac_ngfbfc_ir_rf_list = gfrac_ngfbfc_ir_rf[:17]\n",
    "\n",
    "gfrac5mins_new = np.zeros((account_period, len(gfrac_ngfbfc_ir_rf_list), lat, lon), dtype=std_dtype_float) #30 mins an\n",
    "for n in range(account_period):\n",
    "    gfrac5mins_new[n][0] = gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=0)\n",
    "    gfrac5mins_new[n][1] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=1) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=22))\n",
    "    gfrac5mins_new[n][2] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=2) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=23))\n",
    "    gfrac5mins_new[n][3] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=3) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=24))\n",
    "    gfrac5mins_new[n][4] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=4) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=25))\n",
    "    gfrac5mins_new[n][5] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=5) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=26))\n",
    "    gfrac5mins_new[n][6] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=6) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=27))\n",
    "    gfrac5mins_new[n][7] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=7) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=28))\n",
    "    gfrac5mins_new[n][8] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=8) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=29))\n",
    "    gfrac5mins_new[n][9] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=9) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=30))\n",
    "    gfrac5mins_new[n][10] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=10) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=31))\n",
    "    gfrac5mins_new[n][11] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=11) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=32))\n",
    "    gfrac5mins_new[n][12] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=12) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=33))\n",
    "    gfrac5mins_new[n][13] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=13) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=34))\n",
    "    gfrac5mins_new[n][14] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=14) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=35))\n",
    "    gfrac5mins_new[n][15] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=15) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=36))\n",
    "    gfrac5mins_new[n][16] = (gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=16) + gfrac5min[\"GFRAC\"].isel(time=n, NGFBFC=37))\n",
    "\n",
    "gfrac_combined_netcdf = save_netcdf_ngfbfc(out_file_name=\"GFRAC_5_mins_combined_run2\", variabel=\"GFRAC_combined\", dims=dims_ngfbfc, input_data=gfrac5mins_new, input_ngfbfc=gfrac_ngfbfc_ir_rf_list, coord=gfrac5min, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "# S3.AM1.A\n",
    "columns_year_analysis = range(start_time_year+5, end_time_year, interval)\n",
    "\n",
    "gfrac_ngfbfc = [element.strip() for element in gfrac_combined_netcdf.coords['NGFBFC'].data.astype('str').tolist()]\n",
    "gfrac_combined_netcdf = gfrac_combined_netcdf.assign_coords(NGFBFC=gfrac_ngfbfc)\n",
    "len_ngfbfc = len(gfrac_ngfbfc)\n",
    "\n",
    "gfrac_area_7020 = np.zeros((account_period, len_ngfbfc, lat, lon), dtype=std_dtype_float)\n",
    "for n in range(account_period):\n",
    "    for i, crop in enumerate(gfrac_ngfbfc):\n",
    "        gfrac_area_7020[n][i] = matrixMultiply(gfrac_combined_netcdf['GFRAC_combined'].isel(time=n).sel(NGFBFC=crop).to_numpy(), garea_ha_7020[n])\n",
    "\n",
    "gfrac_area_7020_netcdf = save_netcdf_ngfbfc(out_file_name=\"GFRAC_combined\", variabel=\"GFRAC_combined\", dims=dims_ngfbfc, input_data=gfrac_area_7020, input_ngfbfc=gfrac_ngfbfc, coord=garea, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "gfrac_area_7020_netcdf = gfrac_area_7020_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "gfrac_area_7020_excel = gfrac_to_excel(out_file_name=\"GFRAC_combined\", year=account_period, input_data=gfrac_area_7020_netcdf, input_label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "gfrac_area_7520_netcdf = gfrac_area_7020_netcdf.isel(time=slice(start_year_analysis, end_year_analysis))\n",
    "\n",
    "prop_crops_GFRAC_AM1 = np.zeros((len_ngfbfc, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    for n in range(analysis_period):\n",
    "        prop_crops_GFRAC_AM1[i][n] = fractionDivision(gfrac_area_7520_netcdf['GFRAC_combined'].isel(time=n).sel(NGFBFC=crop).to_numpy(),\n",
    "                                                            gfrac_area_7520_netcdf['GFRAC_combined'].isel(time=n).sum(dim='NGFBFC').to_numpy())\n",
    "\n",
    "prop_crops_GFRAC_AM1_netcdf = save_netcdf_variabel(out_file_name=\"prop_crops_GFRAC_AM1\", variabel=gfrac_ngfbfc, input_data=prop_crops_GFRAC_AM1, coord=garea, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "luc_crops_prop_crop = np.zeros((len_ngfbfc, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "LUCrops_trans = emission_CO2_LUC_Category_AM1_netcdf['LUC Crops Emission'].isel(time=slice(start_year_ori, analysis_period)).to_numpy()\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    for n in range(analysis_period):\n",
    "        luc_crops_prop_crop[i][n] = matrixMultiply(LUCrops_trans[n], prop_crops_GFRAC_AM1[i][n])\n",
    "\n",
    "luc_crops_prop_crop_AM1_netcdf = save_netcdf_variabel(out_file_name=\"luc_prop_crops_AM1\", variabel=gfrac_ngfbfc, input_data=luc_crops_prop_crop, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "luc_crops_prop_crop_AM1_netcdf = luc_crops_prop_crop_AM1_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "luc_crops_prop_crop_AM1_excel = netcdf_to_excel_peryear(out_file_name=\"luc_prop_crops_AM1\", year=analysis_period, input_data=luc_crops_prop_crop_AM1_netcdf, input_label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "luc_crops_prop_crop_AM1_excel.insert(3, \"emissions\", \"LUC_AGRI\")\n",
    "luc_crops_prop_crop_AM1_excel.to_excel(f\"/OUTPUT_DATA/luc_prop_crops_AM1.xlsx\", index=False)\n",
    "\n",
    "selisih_gfrac = np.zeros((analysis_period, len_ngfbfc, lat, lon), dtype=std_dtype_float)\n",
    "for n in range(analysis_period):\n",
    "    for i, crop in enumerate(gfrac_ngfbfc):\n",
    "        selisih_gfrac[n][i] = np.where((trans_glct1st_AM1_netcdf['GLCT_1st'].isel(time=n).values == 'agri_to_agri') &\n",
    "                            (gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=n+1).sel(NGFBFC=crop).values > gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=n).sel(NGFBFC=crop).values),\n",
    "                            gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=n+1).sel(NGFBFC=crop).values - gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=n).sel(NGFBFC=crop).values, 0)\n",
    "\n",
    "selisih_gfrac_area_AM1_netcdf = save_netcdf_ngfbfc(out_file_name=\"selisih_gfrac\", variabel=\"selisih_gfrac\", dims=dims_ngfbfc, input_data=selisih_gfrac, input_ngfbfc=gfrac_ngfbfc, coord=garea, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "proporsi_delta = np.zeros((analysis_period, len_ngfbfc, lat, lon), dtype=std_dtype_float)\n",
    "for n in range(analysis_period):\n",
    "    for i, crop in enumerate(gfrac_ngfbfc):\n",
    "        proporsi_delta[n][i] = fractionDivision(selisih_gfrac_area_AM1_netcdf['selisih_gfrac'].isel(time=n).sel(NGFBFC=crop).to_numpy(),\n",
    "                                                    selisih_gfrac_area_AM1_netcdf['selisih_gfrac'].isel(time=n).sum(dim='NGFBFC').to_numpy())\n",
    "\n",
    "proporsi_delta_netcdf = save_netcdf_ngfbfc(out_file_name=\"selisih_gfrac\", variabel=\"selisih_gfrac\", dims=dims_ngfbfc, input_data=proporsi_delta, input_ngfbfc=gfrac_ngfbfc, coord=garea, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "agri_to_agri_prop_crop = np.zeros((len_ngfbfc, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "agri_trans = emission_CO2_LUC_Category_AM1_netcdf['Agricultural Transition Emission'].isel(time=slice(start_year_ori, analysis_period)).to_numpy()\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    for n in range(analysis_period):\n",
    "        agri_to_agri_prop_crop[i][n] = matrixMultiply(agri_trans[n], proporsi_delta[n][i])\n",
    "\n",
    "agri_to_agri_prop_crop_AM1_netcdf = save_netcdf_variabel(out_file_name=\"agri_to_agri_prop_crop_AM1\", variabel=gfrac_ngfbfc, input_data=agri_to_agri_prop_crop, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "agri_to_agri_prop_crop_AM1_netcdf = agri_to_agri_prop_crop_AM1_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "agri_to_agri_prop_crop_AM1_excel = netcdf_to_excel_peryear(out_file_name=\"agri_to_agri_prop_crop_AM1\", year=analysis_period, input_data=agri_to_agri_prop_crop_AM1_netcdf, input_label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "agri_to_agri_prop_crop_AM1_excel.insert(3, \"emissions\", \"AGRI_to_AGRI\")\n",
    "agri_to_agri_prop_crop_AM1_excel.to_excel(f\"/OUTPUT_DATA/agri_to_agri_prop_crop_AM1.xlsx\", index=False)\n",
    "\n",
    "emission_total_AM1 = np.zeros((len_ngfbfc, analysis_period, lat, lon))\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    for n in range(analysis_period):\n",
    "        condition = agri_to_agri_prop_crop[i][n] + luc_crops_prop_crop[i][n]\n",
    "        emission_total_AM1[i][n] = np.where(np.isfinite(condition), condition, 0)\n",
    "\n",
    "emission_total_prop_crop_AM1_netcdf = save_netcdf_variabel(out_file_name=\"emission_total_prop_crop_AM1\", variabel=gfrac_ngfbfc, input_data=emission_total_AM1, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "emission_total_prop_crop_AM1_netcdf = emission_total_prop_crop_AM1_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "emission_total_prop_crop_AM1_excel = netcdf_to_excel_peryear(out_file_name=\"emission_total_prop_crop_AM1\", year=analysis_period, input_data=emission_total_prop_crop_AM1_netcdf, input_label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "emission_total_prop_crop_AM1_excel.insert(3, \"emissions\", \"emissions_total\")\n",
    "emission_total_prop_crop_AM1_excel.columns[:, columns_year_analysis] = emission_total_prop_crop_AM1_excel.columns[columns_year_analysis].values / interval\n",
    "emission_total_prop_crop_AM1_excel.to_excel(f\"/OUTPUT_DATA/emission_total_prop_crop_AM1.xlsx\", index=False)\n",
    "\n",
    "# S3.AM2.A\n",
    "prop_crops_GFRAC_AM2 = np.zeros((len_ngfbfc, 1, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    prop_crops_GFRAC_AM2[i][0] = fractionDivision(gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=end_year_ori).sel(NGFBFC=crop).to_numpy(),\n",
    "                                                            gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=end_year_ori).sum(dim='NGFBFC').to_numpy())\n",
    "\n",
    "luc_crops_prop_crop = np.zeros((len_ngfbfc, 1, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    luc_crops_prop_crop[i][0] = matrixMultiply(emission_CO2_AM2_AM3_netcdf['LUC Crops Emission'].isel(time=0).to_numpy(), prop_crops_GFRAC_AM2[i][0])\n",
    "\n",
    "luc_crops_prop_crop_AM2_netcdf = save_netcdf_variabel(out_file_name=\"luc_crops_prop_crop_AM2\", variabel=gfrac_ngfbfc, input_data=luc_crops_prop_crop, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "luc_crops_prop_crop_AM2_netcdf = luc_crops_prop_crop_AM2_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "luc_crops_prop_crop_AM2_excel = netcdf_to_excel(out_file_name=\"luc_crops_prop_crop_AM2\", input_data=luc_crops_prop_crop_AM2_netcdf, label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "selisih_gfrac = np.zeros((1, len_ngfbfc, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    selisih_gfrac[0][i] = np.where(trans_glct1st_AM23_netcdf['GLCT_1st'].isel(time=0).values == 'agri_to_agri',\n",
    "                                                np.where(gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=end_year_ori).sel(NGFBFC=crop).values > gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=start_year_ori).sel(NGFBFC=crop).values,\n",
    "                                                      gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=end_year_ori).sel(NGFBFC=crop).values - gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=start_year_ori).sel(NGFBFC=crop).values, 0), 0)\n",
    "\n",
    "selisih_gfrac_area_7020_netcdf = save_netcdf_ngfbfc(out_file_name=\"selisih_gfrac\", variabel=\"selisih_gfrac\", dims=dims_ngfbfc, input_data=selisih_gfrac, input_ngfbfc=gfrac_ngfbfc, coord=garea, time=pd.to_datetime([label_end_time_analysis]))\n",
    "\n",
    "proporsi_delta = np.zeros((1, len_ngfbfc, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "        proporsi_delta[0][i] = fractionDivision(selisih_gfrac_area_7020_netcdf['selisih_gfrac'].isel(time=0).sel(NGFBFC=crop).to_numpy(),\n",
    "                                                    selisih_gfrac_area_7020_netcdf['selisih_gfrac'].isel(time=0).sum(dim='NGFBFC').to_numpy())\n",
    "\n",
    "agri_to_agri_prop_crop = np.zeros((len_ngfbfc, 1, lat, lon), dtype=std_dtype_float)\n",
    "agri_trans = emission_CO2_AM2_AM3_netcdf['Agricultural Transition Emission'].to_numpy()\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "        agri_to_agri_prop_crop[i][0] = matrixMultiply(agri_trans[0], proporsi_delta[0][i])\n",
    "\n",
    "agri_to_agri_prop_crop_AM2_netcdf = save_netcdf_variabel(out_file_name=\"agri_to_agri_prop_crop_AM2\", variabel=gfrac_ngfbfc, input_data=agri_to_agri_prop_crop, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "agri_to_agri_prop_crop_AM2_netcdf = agri_to_agri_prop_crop_AM2_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "agri_to_agri_prop_crop_AM2_excel = netcdf_to_excel(out_file_name=\"agri_to_agri_prop_crop_AM2\", input_data=agri_to_agri_prop_crop_AM2_netcdf, label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "emission_total_AM2 = np.zeros((len_ngfbfc, 1, lat, lon))\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    condition = agri_to_agri_prop_crop[i][0] + luc_crops_prop_crop[i][0]\n",
    "    emission_total_AM2[i][0] = np.where(np.isfinite(condition), condition, 0)\n",
    "\n",
    "emission_total_prop_crop_AM2_netcdf = save_netcdf_variabel(out_file_name=\"emission_total_prop_crop_AM2\", variabel=gfrac_ngfbfc, input_data=emission_total_AM2, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "emission_total_prop_crop_AM2_netcdf = emission_total_prop_crop_AM2_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "emission_total_prop_crop_AM2_excel = netcdf_to_excel(out_file_name=\"emission_total_prop_crop_AM2\", input_data=emission_total_prop_crop_AM2_netcdf, label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "# S3.AM3.A\n",
    "akumulasi = np.zeros((1, len_ngfbfc, lat, lon))\n",
    "for n in range(account_period):\n",
    "    for i, crop in enumerate(gfrac_ngfbfc):\n",
    "        condition = np.where(gfrac_combined_netcdf['GFRAC_combined'].isel(time=n).sel(NGFBFC=crop).to_numpy() > 0, gfrac_combined_netcdf['GFRAC_combined'].isel(time=n).sel(NGFBFC=crop).to_numpy(), 0)\n",
    "        akumulasi[0][i] += np.nan_to_num(condition)\n",
    "        akumulasi[0][i] = np.nan_to_num(akumulasi[0][i])\n",
    "\n",
    "akumulasi_netcdf = save_netcdf_ngfbfc(out_file_name=\"akumulasi\", variabel=\"akumulasi\", dims=dims_ngfbfc, input_data=akumulasi, input_ngfbfc=gfrac_ngfbfc, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "\n",
    "glct_array = np.where(glct_NICK_AM1_netcdf['GLCT_trans'].to_numpy() == \"agri\", 1, 0)\n",
    "glct_numpy = np.zeros((1, lat, lon))\n",
    "for n in range(analysis_period):\n",
    "    glct_numpy[0] += np.nan_to_num(glct_array[n])\n",
    "\n",
    "proporsi_OY = np.zeros((1, len_ngfbfc, lat, lon))\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    condition = fractionDivision(akumulasi[0][i], glct_numpy[0])\n",
    "    proporsi_OY[0][i] = np.nan_to_num(condition)\n",
    "\n",
    "proporsi_AM3_netcdf = save_netcdf_ngfbfc(out_file_name=\"proporsi_AM3_OY_coord\", variabel=\"proporsi_OY\", dims=dims_ngfbfc, input_data=proporsi_OY, input_ngfbfc=gfrac_ngfbfc, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "proporsi_AM3_netcdf = proporsi_AM3_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "\n",
    "proporsi_OY = proporsi_OY.reshape((len_ngfbfc, 1, lat, lon))\n",
    "proporsi2_AM3_netcdf = save_netcdf_variabel(out_file_name=\"proporsi_AM3_OY_variabel\", variabel=gfrac_ngfbfc, input_data=proporsi_OY, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "\n",
    "luc_prop_crop = np.zeros((len_ngfbfc, 1, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    luc_prop_crop[i][0] = matrixMultiply(emission_CO2_AM2_AM3_netcdf['LUC Crops Emission'].isel(time=0).to_numpy(), proporsi_OY[i][0])\n",
    "\n",
    "luc_crops_prop_crop_AM3_netcdf = save_netcdf_variabel(out_file_name=\"luc_crops_prop_crop_AM3\", variabel=gfrac_ngfbfc, input_data=luc_prop_crop, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "luc_crops_prop_crop_AM3_netcdf = luc_crops_prop_crop_AM3_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "luc_crops_prop_crop_AM3_excel = netcdf_to_excel(out_file_name=\"luc_crops_prop_crop_AM3\", input_data=luc_crops_prop_crop_AM3_netcdf, label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "agri_to_agri_prop_crop = np.zeros((len_ngfbfc, 1, lat, lon))\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    agri_to_agri_prop_crop[i][0] = matrixMultiply(emission_CO2_AM2_AM3_netcdf['Agricultural Transition Emission'].isel(time=0).to_numpy(), proporsi_OY[i][0])\n",
    "\n",
    "agri_to_agri_prop_crop_AM3_netcdf = save_netcdf_variabel(out_file_name=\"agri_to_agri_prop_crop_AM3\", variabel=gfrac_ngfbfc, input_data=agri_to_agri_prop_crop, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "agri_to_agri_prop_crop_AM3_netcdf = agri_to_agri_prop_crop_AM3_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "agri_to_agri_prop_crop_AM3_excel = netcdf_to_excel(out_file_name=\"agri_to_agri_prop_crop_AM3\", input_data=agri_to_agri_prop_crop_AM3_netcdf, label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n",
    "\n",
    "emission_total_AM3 = np.zeros((len_ngfbfc, 1, lat, lon))\n",
    "for i, crop in enumerate(gfrac_ngfbfc):\n",
    "    condition = agri_to_agri_prop_crop[i][0] + luc_prop_crop[i][0]\n",
    "    emission_total_AM3[i][0] = np.where(np.isfinite(condition), condition, 0)\n",
    "\n",
    "emission_total_prop_crop_AM3_netcdf = save_netcdf_variabel(out_file_name=\"emission_total_prop_crop_AM3\", variabel=gfrac_ngfbfc, input_data=emission_total_AM3, coord=gfrac_combined_netcdf, time=pd.to_datetime([label_end_time_analysis]))\n",
    "emission_total_prop_crop_AM3_netcdf = emission_total_prop_crop_AM3_netcdf.assign_coords(country_name=country_coords['country'])\n",
    "emission_total_prop_crop_AM3_excel = netcdf_to_excel(out_file_name=\"emission_total_prop_crop_AM3\", input_data=emission_total_prop_crop_AM3_netcdf, label=gfrac_ngfbfc, columns_name=\"NGFBFC\", index_data=['country_name'], column_data=['time'], agg='sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4\n",
    "# S4.1A\n",
    "ngfbfc_wt_grass = [element for element in gfrac_ngfbfc if element != 'grass']\n",
    "len_wt_grass = len(ngfbfc_wt_grass)\n",
    "list_gdata = {\"GEN2OLC_N20\": [len_ngfbfc, Kg_to_tonne], \"GFERTILIZER_N20\": [len_wt_grass, Mg_to_tonne], \"GECH4RI_CH4\": [1, Kg_to_tonne]}\n",
    "\n",
    "for key, value in list_gdata.items():\n",
    "    filename = key.split('_')[0]\n",
    "    gas_type = key.split('_')[1]\n",
    "\n",
    "    if filename == \"GFERTILIZER\":\n",
    "        gdata = Gprocess(file_name=filename, length=value[0], year=analysis_period, input_data1=garea_ha_7520, input_data2=prop_crops_GFRAC_AM1, ton=value[1])\n",
    "        Gdata_crop_netcdf = save_netcdf_variabel(out_file_name=f\"{filename}_crop_{gas_type}\", variabel=ngfbfc_wt_grass, input_data=gdata, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "        Gdata_crop_netcdf = Gdata_crop_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "        Gdata_crop_excel = netcdf_to_excel_peryear(out_file_name=f\"{filename}_crop_{gas_type}\", input_data=Gdata_crop_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=ngfbfc_wt_grass, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "\n",
    "        Gdata_crop_excel.insert(3, \"emissions\", f\"{filename}_crop_{gas_type}\")\n",
    "        Gdata_crop_excel.columns[:, columns_year_analysis] = (Gdata_crop_excel.columns[columns_year_analysis].values * N2O_to_CO2eq * 0.002) / interval\n",
    "        Gdata_crop_excel.to_excel(f\"/OUTPUT_DATA/{filename}_crop_{gas_type}.xlsx\", index=False)\n",
    "    \n",
    "    elif filename == \"GECH4RI\":\n",
    "        gdata = Gprocess(file_name=filename, length=value[0], year=analysis_period, input_data1=garea_ha_7520, input_data2=prop_crops_GFRAC_AM1, ton=value[1])\n",
    "        Gdata_crop_netcdf = save_netcdf(out_file_name=f\"{filename}_crop_{gas_type}\", variabel=\"rice\", dims=dims, input_data=gdata, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "        Gdata_crop_netcdf = Gdata_crop_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "        Gdata_crop_excel = netcdf_to_excel_peryear(out_file_name=f\"{filename}_crop_{gas_type}\", input_data=Gdata_crop_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=\"rice\", index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "\n",
    "        Gdata_crop_excel.insert(3, \"emissions\", f\"{filename}_crop_{gas_type}\")\n",
    "        Gdata_crop_excel.columns[:, columns_year_analysis] = (Gdata_crop_excel.columns[columns_year_analysis].values * CH4_to_CO2eq) / interval        \n",
    "        Gdata_crop_excel.to_excel(f\"/OUTPUT_DATA/{filename}_crop_{gas_type}.xlsx\", index=False)\n",
    "\n",
    "    else:\n",
    "        gdata = Gprocess(file_name=filename, length=value[0], year=analysis_period, input_data1=garea_ha_7520, input_data2=prop_crops_GFRAC_AM1, ton=value[1])\n",
    "        Gdata_crop_netcdf = save_netcdf_variabel(out_file_name=f\"{filename}_crop_{gas_type}\",  variabel=gfrac_ngfbfc, input_data=gdata, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "        Gdata_crop_netcdf = Gdata_crop_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "        Gdata_crop_excel = netcdf_to_excel_peryear(out_file_name=f\"{filename}_crop_{gas_type}\", input_data=Gdata_crop_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=gfrac_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "\n",
    "        Gdata_crop_excel.insert(3, \"emissions\", f\"{filename}_crop_{gas_type}\")\n",
    "        Gdata_crop_excel.columns[:, columns_year_analysis] = (Gdata_crop_excel.columns[columns_year_analysis].values * N2O_to_CO2eq) / interval\n",
    "        Gdata_crop_excel.to_excel(f\"/OUTPUT_DATA/{filename}_crop_{gas_type}.xlsx\", index=False)\n",
    "\n",
    "GFERTILIZERSYN = xr.open_dataset(\"/INPUT_DATA/GFERTILIZERSYN.NC\")\n",
    "GFERTILIZERSYN = GFERTILIZERSYN.drop_sel(NFBCT=b'Grains (biofuel)                                  ')\n",
    "GFERTILIZERSYN = GFERTILIZERSYN.drop_sel(NFBCT=b'Oil crops (biofuel)                               ')\n",
    "GFERTILIZERSYN = GFERTILIZERSYN.drop_sel(NFBCT=b'Sugar cane (biofuel)                              ')\n",
    "GFERTILIZERSYN = GFERTILIZERSYN.drop_sel(NFBCT=b'Woody biofuel                                     ')\n",
    "GFERTILIZERSYN = GFERTILIZERSYN.drop_sel(NFBCT=b'Non-woody biofuel                                 ')\n",
    "GFERTILIZERSYN = GFERTILIZERSYN.drop_sel(NFBCT=b'total                                             ')\n",
    "GFERTILIZERSYN = GFERTILIZERSYN.isel(time=slice(start_year_analysis, end_year_analysis))\n",
    "GFERTILIZERSYN_ton_ha = GFERTILIZERSYN['GFERTILIZERSYN'] * Mg_to_tonne / km2_to_ha\n",
    "\n",
    "GFERTILIZERSYN_gfrac_area = np.zeros((len(ngfbfc_wt_grass), analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(ngfbfc_wt_grass):\n",
    "    for n in range(analysis_period):\n",
    "        GFERTILIZERSYN_gfrac_area[i][n] = matrixMultiply(GFERTILIZERSYN_ton_ha.isel(time=n, NFBCT=i).to_numpy(), gfrac_area_7520_netcdf['GFRAC_combined'].isel(time=n, NGFBFC=i).to_numpy())\n",
    "        \n",
    "emission_GFERTILIZERSYN_GtTon = GFERTILIZERSYN_gfrac_area * (N_to_N2O) * ton_to_gigaton * interval\n",
    "\n",
    "emission_GFERTILIZERSYN_GtTon_netcdf = save_netcdf_variabel(out_file_name=\"GFERTILIZER_SYNTHETIC_crop_N20\", variabel=ngfbfc_wt_grass, input_data=emission_GFERTILIZERSYN_GtTon, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "emission_GFERTILIZERSYN_GtTon_netcdf = emission_GFERTILIZERSYN_GtTon_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "emission_GFERTILIZERSYN_GtTon_excel = netcdf_to_excel_peryear(out_file_name=\"GFERTILIZER_SYNTHETIC_crop_N20\", input_data=emission_GFERTILIZERSYN_GtTon_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=ngfbfc_wt_grass, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "\n",
    "emission_GFERTILIZERSYN_GtTon_excel.insert(3, \"emissions\", \"GFERTILIZER_SYNTHETIC\")\n",
    "emission_GFERTILIZERSYN_GtTon_excel.columns[:, columns_year_analysis] = (emission_GFERTILIZERSYN_GtTon_excel.columns[columns_year_analysis].values * N2O_to_CO2eq * 0.01) / interval\n",
    "emission_GFERTILIZERSYN_GtTon_excel.to_excel(f\"/OUTPUT_DATA/GFERTILIZER_SYNTHETIC_crop_N20.xlsx\", index=False)\n",
    "\n",
    "# S4.2A\n",
    "GABOVERES = xr.open_dataset(\"/INPUT_DATA/GABOVERES.NC\", engine='netcdf4')\n",
    "AGWBUR = pd.read_excel(\"/INPUT_DATA/AGWBUR.xlsm\")\n",
    "GREG = xr.open_dataset(\"/INPUT_DATA/GREG.nc\", engine='netcdf4')\n",
    "GEN2ORE = xr.open_dataset(\"/INPUT_DATA/GEN2ORE.NC\", engine=\"netcdf4\")\n",
    "\n",
    "GABOVERES_ngfbfc_ori = GABOVERES.coords['NGFBFC'].data.tolist()\n",
    "\n",
    "GABOVERES_ngfbfc_ir_rf = []\n",
    "for i, GABOVERES_cls in enumerate(GABOVERES_ngfbfc_ori):\n",
    "    GABOVERES_cls_str = GABOVERES_cls.decode('utf-8')\n",
    "    if np.char.replace(GABOVERES_cls_str, ' ', '') == \"grass\":\n",
    "        GABOVERES_ngfbfc_ir_rf.append(GABOVERES_cls)\n",
    "    elif GABOVERES_cls_str.startswith('RF'):\n",
    "        GABOVERES_ngfbfc_ir_rf.append(GABOVERES_cls[3:])\n",
    "    elif GABOVERES_cls_str.startswith('IR'):\n",
    "        GABOVERES_ngfbfc_ir_rf.append(GABOVERES_cls[3:])\n",
    "\n",
    "GABOVERES_ngfbfc_ir_rf_list = GABOVERES_ngfbfc_ir_rf[:17]\n",
    "\n",
    "GABOVERES_new = np.zeros((account_period, len(GABOVERES_ngfbfc_ir_rf_list), lat, lon), dtype=std_dtype_float)\n",
    "for n in range(account_period):\n",
    "    GABOVERES_new[n][0] = GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=0)\n",
    "    GABOVERES_new[n][1] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=1) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=22))\n",
    "    GABOVERES_new[n][2] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=2) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=23))\n",
    "    GABOVERES_new[n][3] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=3) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=24))\n",
    "    GABOVERES_new[n][4] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=4) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=25))\n",
    "    GABOVERES_new[n][5] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=5) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=26))\n",
    "    GABOVERES_new[n][6] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=6) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=27))\n",
    "    GABOVERES_new[n][7] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=7) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=28))\n",
    "    GABOVERES_new[n][8] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=8) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=29))\n",
    "    GABOVERES_new[n][9] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=9) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=30))\n",
    "    GABOVERES_new[n][10] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=10) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=31))\n",
    "    GABOVERES_new[n][11] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=11) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=32))\n",
    "    GABOVERES_new[n][12] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=12) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=33))\n",
    "    GABOVERES_new[n][13] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=13) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=34))\n",
    "    GABOVERES_new[n][14] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=14) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=35))\n",
    "    GABOVERES_new[n][15] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=15) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=36))\n",
    "    GABOVERES_new[n][16] = (GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=16) + GABOVERES[\"GABOVERES\"].isel(time=n, NGFBFC=37))\n",
    "\n",
    "GABOVERES_combined_netcdf = save_netcdf_ngfbfc(out_file_name=\"GABOVERES_combined\", variabel=\"GABOVERES_combined\", dims=dims_ngfbfc, input_data=GABOVERES_new, input_ngfbfc=GABOVERES_ngfbfc_ir_rf_list, coord=GABOVERES, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "burnresLocc = np.zeros((account_period, len(GABOVERES_ngfbfc_ir_rf_list), lat, lon), dtype=std_dtype_float)\n",
    "for n, year in enumerate(range(start_time_year, end_time_year, interval)):\n",
    "    for i, crops in enumerate(gfrac_ngfbfc_ir_rf_list):\n",
    "        for j in range(1, 27):\n",
    "            mask = np.where(GREG['GREG'].isel(time=0).to_numpy() == j)\n",
    "            burnresLocc[n][i][mask] = matrixMultiply(GABOVERES_combined_netcdf['GABOVERES_combined'].isel(time=n, NGFBFC=i).to_numpy()[mask], AGWBUR[AGWBUR['year'] == year][j].values)\n",
    "\n",
    "burnresLocc_netcdf = save_netcdf_ngfbfc(out_file_name=\"burnresLocc\", variabel=\"burnresLocc\", dims=dims_ngfbfc, input_data=burnresLocc, input_ngfbfc=GABOVERES_ngfbfc_ir_rf_list, coord=GABOVERES, time=pd.date_range(start=label_start_time_ori, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "burnresLocc_ngfbfc = [element.strip() for element in burnresLocc_netcdf.coords['NGFBFC'].data.astype('str').tolist()]\n",
    "eco2abLoc_ton_C_ha = ((burnresLocc_netcdf['burnresLocc'].isel(time=slice(start_year_analysis, end_year_analysis)) * CVKGDMKGC * Mg_to_tonne) / km2_to_ha)\n",
    "\n",
    "eco2abLoc_ton_C = np.zeros((analysis_period, len(burnresLocc_ngfbfc), lat, lon), dtype=std_dtype_float)\n",
    "for n in range(analysis_period):\n",
    "    for i in range(len(burnresLocc_ngfbfc)):\n",
    "        eco2abLoc_ton_C[n][i] = matrixMultiply(eco2abLoc_ton_C_ha.isel(time=n, NGFBFC=i), garea_ha_7020[n])\n",
    "\n",
    "eco2abLoc_ton_C_netcdf = save_netcdf_ngfbfc(out_file_name=\"eco2abLoc_ton_C\", variabel=\"eco2abLoc_ton_C\", dims=dims_ngfbfc, input_data=eco2abLoc_ton_C, input_ngfbfc=burnresLocc_ngfbfc, coord=GABOVERES, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "geCH4ab = eco2abLoc_ton_C_netcdf['eco2abLoc_ton_C'].to_numpy() * ratioCH4toC * CCH4toCH4\n",
    "geCH4ab_GtTon = (geCH4ab * ton_to_gigaton * interval)\n",
    "geCH4ab_GtTon = geCH4ab_GtTon.reshape((len(burnresLocc_ngfbfc), analysis_period, lat, lon))\n",
    "\n",
    "geCH4ab_GtTon_netcdf = save_netcdf_variabel(out_file_name=\"geCH4ab_crop_CH4\", variabel=burnresLocc_ngfbfc, input_data=geCH4ab_GtTon, coord=GABOVERES, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "geCH4ab_GtTon_netcdf = geCH4ab_GtTon_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "geCH4ab_GtTon_excel = netcdf_to_excel_peryear(out_file_name=\"geCH4ab_crop_CH4\", input_data=geCH4ab_GtTon_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=burnresLocc_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "\n",
    "geCH4ab_GtTon_excel = pd.merge(left=geCH4ab_GtTon_excel, right=country_code, left_on=\"country_name\", right_on=\"ISO Country\")\n",
    "geCH4ab_GtTon_excel = geCH4ab_GtTon_excel[['IMAGE Region Name', 'time', 'NGFBFC']]\n",
    "geCH4ab_GtTon_excel = geCH4ab_GtTon_excel.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "geCH4ab_GtTon_excel = geCH4ab_GtTon_excel.reset_index()\n",
    "\n",
    "geCH4ab_GtTon_excel.to_excel(\"/OUTPUT_DATA/geCH4ab_crop_CH4.xlsx\", index=False)\n",
    "\n",
    "geN2Oab = eco2abLoc_ton_C_netcdf['eco2abLoc_ton_C'].to_numpy() * ratioN2OtoC * CNtoN2O\n",
    "geN2Oab_GtTon = (geN2Oab * ton_to_gigaton * interval)\n",
    "geN2Oab_GtTon = geN2Oab_GtTon.reshape((len(burnresLocc_ngfbfc), analysis_period, lat, lon))\n",
    "\n",
    "GgeN2Oab_GtTon_netcdf = save_netcdf_variabel(out_file_name=\"geN2Oab_crop_N2O\", variabel=burnresLocc_ngfbfc, input_data=geN2Oab_GtTon, coord=GABOVERES, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "GgeN2Oab_GtTon_netcdf = GgeN2Oab_GtTon_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "GgeN2Oab_GtTon_excel = netcdf_to_excel_peryear(out_file_name=\"geN2Oab_crop_N2O\", input_data=GgeN2Oab_GtTon_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=burnresLocc_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "\n",
    "GgeN2Oab_GtTon_excel = pd.merge(left=GgeN2Oab_GtTon_excel, right=country_code, left_on=\"country_name\", right_on=\"ISO Country\")\n",
    "GgeN2Oab_GtTon_excel = GgeN2Oab_GtTon_excel[['IMAGE Region Name', 'time', 'NGFBFC']]\n",
    "GgeN2Oab_GtTon_excel = GgeN2Oab_GtTon_excel.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "GgeN2Oab_GtTon_excel = GgeN2Oab_GtTon_excel.reset_index()\n",
    "\n",
    "GgeN2Oab_GtTon_excel.to_excel(\"/OUTPUT_DATA/geN2Oab_crop_N2O.xlsx\", index=False)\n",
    "\n",
    "GABOVERES_netcdf = GABOVERES_combined_netcdf.isel(time=slice(start_year_analysis, end_year_analysis))\n",
    "prop_crops_GABOVERES = np.zeros((len(GABOVERES_ngfbfc_ir_rf_list), analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(GABOVERES_ngfbfc_ir_rf_list):\n",
    "    for n in range(analysis_period):\n",
    "        prop_crops_GABOVERES[i][n] = fractionDivision(GABOVERES_netcdf['GABOVERES_combined'].isel(NGFBFC=i).isel(time=n).to_numpy(), \n",
    "                                                            GABOVERES_netcdf['GABOVERES_combined'].isel(time=n).sum(dim='NGFBFC').to_numpy())\n",
    "        \n",
    "GEN2ORE = GEN2ORE.isel(time=slice(start_year_analysis, end_year_analysis))\n",
    "emission_GEN2ORE_ton_ha = GEN2ORE['GEN2ORE'] * Kg_to_tonne / km2_to_ha\n",
    "emission_ton = matrixMultiply(emission_GEN2ORE_ton_ha, garea_ha_7520)\n",
    "emission_GtTon = emission_ton * (N_to_N2O) * ton_to_gigaton * interval\n",
    "\n",
    "emission_GtTon_netcdf = save_netcdf_ngfbfc(out_file_name=\"GEN2ORE\", variabel=\"GEN2ORE\", dims=dims_ngfbfc, input_data=emission_GtTon, input_ngfbfc=burnresLocc_ngfbfc, coord=gfrac5min, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "GEN2ORE_crop = np.zeros((len(GABOVERES_ngfbfc_ir_rf_list), analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "for i, crop in enumerate(burnresLocc_ngfbfc):\n",
    "    for n in range(analysis_period):\n",
    "        GEN2ORE_crop[i][n] = matrixMultiply(emission_GtTon_netcdf['GEN2ORE'].isel(time=n).to_numpy(), prop_crops_GABOVERES[i][n])\n",
    "\n",
    "GEN2ORE_crop_netcdf = save_netcdf_variabel(out_file_name=\"GEN2ORE_crop_v2\", variabel=burnresLocc_ngfbfc, input_data=GEN2ORE_crop, coord=gfrac5min, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "GEN2ORE_crop_netcdf = GEN2ORE_crop_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "GEN2ORE_crop_excel = netcdf_to_excel_peryear(out_file_name=\"GEN2ORE_crop_v2\", input_data=GEN2ORE_crop_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=burnresLocc_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "\n",
    "GEN2ORE_crop_excel = pd.merge(left=GEN2ORE_crop_excel, right=country_code, left_on=\"country_name\", right_on=\"ISO Country\")\n",
    "GEN2ORE_crop_excel = GEN2ORE_crop_excel[['IMAGE Region Name', 'time', 'NGFBFC']]\n",
    "GEN2ORE_crop_excel = GEN2ORE_crop_excel.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "GEN2ORE_crop_excel = GEN2ORE_crop_excel.reset_index()\n",
    "\n",
    "GEN2ORE_crop_excel.to_excel(\"/OUTPUT_DATA/GEN2ORE_crop_v2.xlsx\", index=False)\n",
    "\n",
    "# S4.1B\n",
    "GPEATLAND = xr.open_dataset(\"/INPUT_DATA/GPEATLAND.NC\", engine=\"netcdf4\")\n",
    "GPEATLANDSFRAC = xr.open_dataset(\"/INPUT_DATA/GPEATLANDSFRAC.NC\", engine=\"netcdf4\")\n",
    "\n",
    "peatland_fraction_total_on_crop = np.zeros((account_period, lat, lon), dtype=std_dtype_float)\n",
    "for n in range(account_period):\n",
    "    if n < analysis_period:\n",
    "        peatland_fraction_total_on_crop[n+1] = np.where(\n",
    "            (GPEATLAND['GPEATLAND'].isel(time=n) == 1) & (GPEATLAND['GPEATLAND'].isel(time=n+1) == 2),\n",
    "            matrixMultiply(GPEATLANDSFRAC['GPEATLANDSFRAC'].isel(time=0).values, garea_ha_7020[n+1]),\n",
    "            0\n",
    "        )\n",
    "\n",
    "peatland_area_prop_crop = np.zeros((account_period, len_ngfbfc, lat, lon), dtype=std_dtype_float)\n",
    "for n in range(account_period):\n",
    "    for i in range(len_ngfbfc):\n",
    "        peatland_area_prop_crop[n][i] = matrixMultiply(gfrac_area_7020_netcdf['GFRAC_combined'].isel(time=n).isel(NGFBFC=i), peatland_fraction_total_on_crop[n])\n",
    "\n",
    "peatland_area_prop_crop_netcdf = save_netcdf_ngfbfc(out_file_name=\"peatland_area_prop_crops\", variabel=\"peatland_area_prop_crops\", dims=dims_ngfbfc, input_data=peatland_area_prop_crop, input_ngfbfc=gfrac_ngfbfc, coord=gfrac_combined_netcdf, time=pd.date_range(start=start_time, end=end_time, freq=frequensi))\n",
    "\n",
    "# S4.2B\n",
    "GNLCT = xr.open_dataset(\"/INPUT_DATA/GNLCT.NC\", engine=\"netcdf4\")\n",
    "\n",
    "sheet_list = ['CO2', 'CH4', 'N2O', 'DOC']\n",
    "peatland_columns = ['Boreal', 'Temperate', 'Tropical']\n",
    "boreal_range = range(7,12)\n",
    "temperate_range = range(12,16)\n",
    "tropical_range = range(16,21)\n",
    "\n",
    "ef_zeros = np.zeros((analysis_period, len_ngfbfc, lat, lon), dtype='float32')\n",
    "for sheet in sheet_list:\n",
    "    peatland_df = pd.read_excel(\"/INPUT_DATA/EF Peatland.xlsx\", sheet_name=sheet)\n",
    "    peatland_df[peatland_columns] = peatland_df[peatland_columns].replace(',', '.', regex=True).astype(float)\n",
    "\n",
    "    for n in range(analysis_period):\n",
    "        gnlct_values = GNLCT['GNLCT'].isel(time=n)\n",
    "        for i, ngfbfc in enumerate(peatland_df['NGFBFC'].to_list()):\n",
    "\n",
    "            if np.any(np.isin(gnlct_values, boreal_range)):\n",
    "                ef_zeros[n][i][np.isin(gnlct_values, boreal_range)] = peatland_df.loc[peatland_df['NGFBFC'] == ngfbfc, 'Boreal'].values[0]\n",
    "            \n",
    "            if np.any(np.isin(gnlct_values, temperate_range)):\n",
    "                ef_zeros[n][i][np.isin(gnlct_values, temperate_range)] = peatland_df.loc[peatland_df['NGFBFC'] == ngfbfc, 'Temperate'].values[0]\n",
    "            \n",
    "            if np.any(np.isin(gnlct_values, tropical_range)):\n",
    "                ef_zeros[n][i][np.isin(gnlct_values, tropical_range)] = peatland_df.loc[peatland_df['NGFBFC'] == ngfbfc, 'Tropical'].values[0]\n",
    "        \n",
    "    EF_netcdf = save_netcdf_ngfbfc(out_file_name=sheet, variabel=str(sheet), dims=dims_ngfbfc, input_data=ef_zeros, input_ngfbfc=gfrac_ngfbfc, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "\n",
    "EF_CO2 = xr.open_dataset(\"/OUTPUT_DATA/CO2.NC\", engine=\"netcdf4\")\n",
    "EF_CO2_eq = EF_CO2['CO2'] * tonne_to_tonne * C_to_CO2 \n",
    "\n",
    "EF_CH4 = xr.open_dataset(\"/OUTPUT_DATA/CH4.NC\", engine=\"netcdf4\")\n",
    "EF_CH4_eq = EF_CH4['CH4'] * Kg_to_tonne * CH4_to_CH4 \n",
    "\n",
    "EF_N2O = xr.open_dataset(\"/OUTPUT_DATA/N2O.NC\", engine=\"netcdf4\")\n",
    "EF_N2O_eq = EF_N2O['N2O'] * Kg_to_tonne * N_to_N2O \n",
    "\n",
    "EF_DOC = xr.open_dataset(\"/OUTPUT_DATA/DOC.NC\", engine=\"netcdf4\")\n",
    "EF_DOC_eq = EF_DOC['DOC'] * tonne_to_tonne * C_to_CO2 \n",
    "\n",
    "# S4.3B\n",
    "emission_peat_CO2 = np.zeros((len_ngfbfc, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "emission_peat_CH4 = np.zeros((len_ngfbfc, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "emission_peat_N2O = np.zeros((len_ngfbfc, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "emission_peat_DOC = np.zeros((len_ngfbfc, analysis_period, lat, lon), dtype=std_dtype_float)\n",
    "\n",
    "for i, crops in enumerate(gfrac_ngfbfc):\n",
    "    for n in range(analysis_period):\n",
    "        emission_peat_CO2[i][n] = matrixMultiply(EF_CO2_eq[n], peatland_area_prop_crop[i][n])\n",
    "        emission_peat_CH4[i][n] = matrixMultiply(EF_CH4_eq[n], peatland_area_prop_crop[i][n])\n",
    "        emission_peat_N2O[i][n] = matrixMultiply(EF_N2O_eq[n], peatland_area_prop_crop[i][n])\n",
    "        emission_peat_DOC[i][n] = matrixMultiply(EF_DOC_eq[n], peatland_area_prop_crop[i][n])\n",
    "                                    \n",
    "emission_peat_CO2_GtCO2eq = emission_peat_CO2 * CO2_to_CO2eq * ton_to_gigaton                       \n",
    "emission_peat_CH4_GtCO2eq = emission_peat_CH4 * CH4_to_CO2eq * ton_to_gigaton \n",
    "emission_peat_N2O_GtCO2eq = emission_peat_N2O * N2O_to_CO2eq * ton_to_gigaton \n",
    "emission_peat_DOC_GtCO2eq = emission_peat_DOC * CO2_to_CO2eq * ton_to_gigaton \n",
    "\n",
    "emission_peat_CO2_GtCO2eq_netcdf = save_netcdf_variabel(out_file_name=\"emission_peat_CO2_GtCO2eq\", variabel=gfrac_ngfbfc, input_data=emission_peat_CO2_GtCO2eq, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "emission_peat_CO2_GtCO2eq_netcdf = emission_peat_CO2_GtCO2eq_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "emission_peat_CO2_GtCO2eq_excel = netcdf_to_excel_peryear(out_file_name=\"emission_peat_CO2_GtCO2eq\", input_data=emission_peat_CO2_GtCO2eq_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=gfrac_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "emission_peat_CO2_GtCO2eq_excel.insert(3, \"emissions\", \"peat_CO2\")\n",
    "emission_peat_CO2_GtCO2eq_excel.columns[:, columns_year_analysis] = (emission_peat_CO2_GtCO2eq_excel.columns[columns_year_analysis].values / interval)\n",
    "emission_peat_CO2_GtCO2eq_excel.to_excel(\"/OUTPUT_DATA/emission_peat_CO2_GtCO2eq.xlsx\", index=False)\n",
    "\n",
    "emission_peat_CH4_GtCO2eq_netcdf = save_netcdf_variabel(out_file_name=\"emission_peat_CH4_GtCO2eq\", variabel=gfrac_ngfbfc, input_data=emission_peat_CH4_GtCO2eq, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "emission_peat_CH4_GtCO2eq_netcdf = emission_peat_CH4_GtCO2eq_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "emission_peat_CH4_GtCO2eq_excel = netcdf_to_excel_peryear(out_file_name=\"emission_peat_CH4_GtCO2eq\", input_data=emission_peat_CH4_GtCO2eq_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=gfrac_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "emission_peat_CH4_GtCO2eq_excel.insert(3, \"emissions\", \"peat_CH4\")\n",
    "emission_peat_CH4_GtCO2eq_excel.columns[:, columns_year_analysis] = (emission_peat_CH4_GtCO2eq_excel.columns[columns_year_analysis].values / interval)\n",
    "emission_peat_CH4_GtCO2eq_excel.to_excel(\"/OUTPUT_DATA/emission_peat_CH4_GtCO2eq.xlsx\", index=False)\n",
    "\n",
    "emission_peat_N2O_GtCO2eq_netcdf = save_netcdf_variabel(out_file_name=\"emission_peat_N2O_GtCO2eq\", variabel=gfrac_ngfbfc, input_data=emission_peat_N2O_GtCO2eq, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "emission_peat_N2O_GtCO2eq_netcdf = emission_peat_N2O_GtCO2eq_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "emission_peat_N2O_GtCO2eq_excel = netcdf_to_excel_peryear(out_file_name=\"emission_peat_N2O_GtCO2eq\", input_data=emission_peat_N2O_GtCO2eq_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=gfrac_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "emission_peat_N2O_GtCO2eq_excel.insert(3, \"emissions\", \"peat_N2O\")\n",
    "emission_peat_N2O_GtCO2eq_excel.columns[:, columns_year_analysis] = (emission_peat_N2O_GtCO2eq_excel.columns[columns_year_analysis].values / interval)\n",
    "emission_peat_N2O_GtCO2eq_excel.to_excel(\"/OUTPUT_DATA/emission_peat_N2O_GtCO2eq.xlsx\", index=False)\n",
    "\n",
    "emission_peat_DOC_GtCO2eq_netcdf = save_netcdf_variabel(out_file_name=\"emission_peat_DOC_GtCO2eq\", variabel=gfrac_ngfbfc, input_data=emission_peat_DOC_GtCO2eq, coord=gfrac_combined_netcdf, time=pd.date_range(start=label_start_time_analysis, end=label_end_time_analysis, freq=frequensi))\n",
    "emission_peat_DOC_GtCO2eq_netcdf = emission_peat_DOC_GtCO2eq_netcdf.assign_coords(country_name=country_coords[\"country\"])\n",
    "emission_peat_DOC_GtCO2eq_excel = netcdf_to_excel_peryear(out_file_name=\"emission_peat_DOC_GtCO2eq\", input_data=emission_peat_DOC_GtCO2eq_netcdf, year=analysis_period, columns_name=\"NGFBFC\", input_label=gfrac_ngfbfc, index_data=[\"country_name\"], column_data=['time'], agg=\"sum\")\n",
    "emission_peat_DOC_GtCO2eq_excel.insert(3, \"emissions\", \"peat_DOC\")\n",
    "emission_peat_DOC_GtCO2eq_excel.columns[:, columns_year_analysis] = (emission_peat_DOC_GtCO2eq_excel.columns[columns_year_analysis].values / interval)\n",
    "emission_peat_DOC_GtCO2eq_excel.to_excel(\"/OUTPUT_DATA/emission_peat_DOC_GtCO2eq.xlsx\", index=False)\n",
    "\n",
    "emission_CO2_LUC_Category_AM1_excel = emission_CO2_LUC_Category_AM1_excel.drop(columns=['Country'])\n",
    "emission_CO2_LUC_Category_AM1_excel = emission_CO2_LUC_Category_AM1_excel.rename(columns={\"LUC_Category\" : \"emissions\"})\n",
    "emission_CO2_LUC_Category_AM1_excel.columns[:, columns_year_analysis] = emission_CO2_LUC_Category_AM1_excel.columns[columns_year_analysis].values / interval\n",
    "emission_CO2_LUC_Category_AM1_excel_filtered = emission_CO2_LUC_Category_AM1_excel[emission_CO2_LUC_Category_AM1_excel['emissions'].isin(['Agricultural Transition Emission', 'LUC Crops Emission'])]\n",
    "emission_CO2_LUC_Category_AM1_excel_filtered.to_excel(\"/OUTPUT_DATA//LUC2_Category.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5\n",
    "# S5.A\n",
    "df_physical = pd.read_excel(\"/INPUT_DATA/Physical to Harvested Area GFRAC.xlsx\")\n",
    "\n",
    "time = list(range(start_time_year, end_time_year, interval)) \n",
    "\n",
    "df1_copy = df_physical.copy()\n",
    "df1_copy = df1_copy.rename(columns={\"t\" : \"time\"})\n",
    "df1_copy = df1_copy[~df1_copy['NFBFC'].str.contains(\"biofuel\")]\n",
    "df1_copy.loc[:, 'RF/IR'] = np.where(np.arange(4192) % 32 < 16, \"RF\", \"IR\")\n",
    "df1_copy = ngfbfc_processing(df1_copy)\n",
    "df1_copy[\"NGFBFC\"] = df1_copy['RF/IR'] + \" \" + df1_copy['NFBFC']\n",
    "df1_copy = df1_copy.drop(columns=[\"NFBFC\", \"RF/IR\"])\n",
    "df1_melt = df1_copy.melt(id_vars=['NGFBFC', 'time'], var_name='IMAGE Region Name', value_name='value')\n",
    "\n",
    "df2_copy = gfrac32_excel.copy()\n",
    "df2_copy = ngfbfc_processing(df2_copy)\n",
    "df2_merge = pd.merge(left=df2_copy, right=country_code, left_on=\"country\", right_on=\"ISO Country\")\n",
    "df2_pivot = pd.pivot_table(data=df2_merge, values=time, index=['IMAGE Region Name', 'NGFBFC'], fill_value=0, aggfunc='sum')\n",
    "df2_index = df2_pivot.reset_index()\n",
    "df2_melt = df2_index.melt(id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "\n",
    "df_copy = df2_melt.copy()\n",
    "for region, time, ngfbfc in zip(df_copy[\"IMAGE Region Name\"].to_list(), df_copy[\"time\"].to_list(), df_copy[\"NGFBFC\"].to_list()):\n",
    "    try:\n",
    "        data1 = df1_melt[(df1_melt['IMAGE Region Name'] == region) & (df1_melt['time'] == time) & (df1_melt['NGFBFC'] == ngfbfc)]['value'].to_numpy()\n",
    "        data2 = df2_melt[(df2_melt['IMAGE Region Name'] == region) & (df2_melt['time'] == time) & (df2_melt['NGFBFC'] == ngfbfc)]['value'].to_numpy()\n",
    "        if data1.size == 0:\n",
    "            data1 = [0]\n",
    "        if data2.size == 0: \n",
    "            data2 = [0]\n",
    "        mask = df_copy[(df_copy['IMAGE Region Name'] == region) & (df_copy['time'] == time) & (df_copy['NGFBFC'] == ngfbfc)].index\n",
    "        df_copy.loc[mask, 'value'] =  data1[0] * data2[0]\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e} for region {region}\")\n",
    "\n",
    "df_copy[\"NGFBFC\"] = df_copy[\"NGFBFC\"].apply(lambda x: x.replace('IR ', '').replace('RF ', ''))\n",
    "df_groupby = df_copy.groupby(['IMAGE Region Name', 'NGFBFC', 'time']).sum()\n",
    "df_index = df_groupby.reset_index()\n",
    "\n",
    "df_restructur = pd.pivot_table(data=df_index, columns=[\"time\"], index=[\"IMAGE Region Name\", \"NGFBFC\"], values=['value'])\n",
    "restructur_index = df_restructur.stack(level=0, future_stack=True)\n",
    "restructur_index = restructur_index.reset_index()\n",
    "restructur_index = restructur_index.drop(columns=['level_2'])\n",
    "\n",
    "restructur_index.to_csv(\"/OUTPUT_DATA/GFRAC_Area_Harvested_combined_kolom.csv\", index=False)\n",
    "\n",
    "# S5.B\n",
    "fao_stat_ori = pd.read_csv(\"/INPUT_DATA/Production_Crops_Livestock_E_All_Data_analyze.csv\")\n",
    "crop_class_ori = pd.read_excel(\"/INPUT_DATA/Crop Classification_latest.xlsx\", engine=\"openpyxl\", skiprows=1)\n",
    "\n",
    "crop_class_ori = crop_class_ori.drop('Unnamed: 0', axis=1)\n",
    "crop_class_ori.rename(columns={'FAO Crops': 'Item'}, inplace=True)\n",
    "\n",
    "fao_stat_ori = fao_stat_ori[~fao_stat_ori[\"Area\"].isin([\"Americas\", \"Asia\", \"Australia and New Zealand\", \"Africa\", \"Belgium-Luxembourg\", \"Central America\", \"Central Asia\", \"Caribbean\", \"Czechoslovakia\", \"Eastern Africa\", \"Eastern Asia\",\n",
    " \"Eastern Europe\", \"European Union (27)\",\"Land Locked Developing Countries\", \"Least Developed Countries\", \"Europe\", \"Low Income Food Deficit Countries\", \"Melanesia\", \"Middle Africa\", \n",
    "  \"Net Food Importing Developing Countries\", \"Northern Africa\", \"Northern America\", \"Northern Europe\", \"Oceania\", \"Polynesia\", \"Small Island Developing States\", \"Serbia and Montenegro\", \"China\",\n",
    "  \"South-eastern Asia\", \"Southern Africa\", \"Southern Asia\", \"Southern Europe\", \"Sudan (former)\", \"South America\", \"Western Africa\", \"Western Asia\", \"Western Europe\", \"World\", \"Yugoslav SFR\"])]\n",
    "\n",
    "fao_stat_production = fao_stat_ori[fao_stat_ori['Element'] == \"Production\"]\n",
    "fao_stat_production = fao_stat_production.fillna(0)\n",
    "fao_stat_production = fao_stat_production.merge(crop_class_ori, on='Item')\n",
    "\n",
    "fao_stat_prod = fao_stat_production.drop_duplicates(subset=['Area', 'Item', 'Year', 'Element', 'IMAGE Classification'])\n",
    "fao_stat_prod_columns = fao_stat_prod[['Area', 'Item', 'Year','IMAGE Classification', 'Value']]\n",
    "mask = (fao_stat_prod_columns['Area'] == \"Russian Federation\") & (fao_stat_prod_columns['Year'] <= 1991)\n",
    "ussr_mask = (fao_stat_prod_columns['Area'] == \"USSR\") & (fao_stat_prod_columns['Year'] <= 1991)\n",
    "\n",
    "ussr_values = fao_stat_prod_columns.loc[ussr_mask, ['Item', 'Year', 'IMAGE Classification', 'Value']].values\n",
    "fao_stat_prod_columns.loc[mask, ['Item', 'Year', 'IMAGE Classification', 'Value']] = ussr_values[:len(mask[mask])]\n",
    "fao_stat_prod_columns_update = fao_stat_prod_columns[~fao_stat_prod_columns[\"Area\"].isin([\"USSR\"])]\n",
    "fao_stat_prod_columns_drop = fao_stat_prod_columns_update.drop_duplicates(subset=['Area', 'Item', 'Year', 'IMAGE Classification', 'Value'])\n",
    "\n",
    "step1_copy = fao_stat_prod_columns_drop.copy()\n",
    "step1_copy['Value'] = step1_copy['Value'].fillna(0)\n",
    "step1_copy['Value'] = 0\n",
    "step1_copy['Value'] = fao_stat_prod_columns_drop.groupby(['Area', \"Year\", 'IMAGE Classification'])['Value'].transform('sum')\n",
    "\n",
    "step1_copy_drop = step1_copy.drop_duplicates(subset=['Area', 'Year', 'IMAGE Classification', 'Value'])\n",
    "step1_copy_columns = step1_copy_drop[['Area', 'Year', 'IMAGE Classification', 'Value']]\n",
    "\n",
    "eight_year_ranges = [(y, y+4) for y in range(1968, end_time_year, interval)]\n",
    "step2_copy = step1_copy_columns.copy()\n",
    "for year in eight_year_ranges:\n",
    "    mask = (step1_copy_columns['Year'] >= year[0]) & (step1_copy_columns['Year'] <= year[1]) #5years\n",
    "    step2_copy.loc[mask, 'Value'] = step1_copy_columns[mask].groupby(['Area', 'IMAGE Classification'])['Value'].transform('mean')\n",
    "\n",
    "step2_copy_drop = step2_copy.drop_duplicates(subset=['Area', 'Year', 'IMAGE Classification', 'Value'])\n",
    "\n",
    "eight_year_ranges = [(y, y+4) for y in range(1968, end_time_year, interval)]\n",
    "five_yearIncrements = range(start_time_year, end_time_year, interval)\n",
    "step3_copy = step2_copy_drop.copy()\n",
    "for year, five_year in zip(eight_year_ranges, five_yearIncrements):\n",
    "    year_idx = step2_copy_drop[(step2_copy_drop['Year'] >= year[0]) & (step2_copy_drop['Year'] <= year[1])]['Year'].index\n",
    "    step3_copy.loc[year_idx, 'Year'] = five_year\n",
    "\n",
    "step3_copy_drop = step3_copy.drop_duplicates(subset=['Area', 'Year', 'IMAGE Classification', 'Value'])\n",
    "\n",
    "fao_stat_copy = step3_copy_drop.copy()\n",
    "prubahan_nama = {\n",
    "    \"China, Hong Kong SAR\": \"Hong Kong\",\n",
    "    \"China, Macao SAR\": \"Macao\", \n",
    "    \"China, Taiwan Province of\": \"Taiwan,  Province of China\",\n",
    "    \"China, mainland\": \"China\",\n",
    "    \"Democratic People's Republic of Korea\": \"Korea (Democratic People's Republic of)\",\n",
    "    \"Democratic Republic of the Congo\": \"Congo, Democratic Republic of the\",\n",
    "    \"Micronesia\": \"Micronesia (Federated States of)\",\n",
    "    \"Micronesia (Federated States of) (Federated States of)\": \"Micronesia (Federated States of)\",\n",
    "    \"Netherlands (Kingdom of the)\": \"Netherlands\",\n",
    "    \"Republic of Korea\": \"Korea, Republic of\",\n",
    "    \"Republic of Moldova\": \"Moldova, Republic of\",\n",
    "    \"Palestine\" : \"Palestine, State of\",\n",
    "    \"Türkiye\": \"Turkey\",\n",
    "    \"United Republic of Tanzania\": \"Tanzania, United Republic of\",\n",
    "    \"Ethiopia PDR\" : \"Eritrea\"\n",
    "}\n",
    "keys_list = list(prubahan_nama.keys())\n",
    "values_list = list(prubahan_nama.values())\n",
    "\n",
    "for i in range(len(keys_list)):\n",
    "    fao_stat_copy['Area'] = fao_stat_copy['Area'].astype(str).str.replace(keys_list[i], values_list[i])\n",
    "\n",
    "fao_stat_copy.to_csv(\"/OUTPUT_DATA/REV_fao_stat_production_mov_average_v2.csv\", index=False)\n",
    "\n",
    "# S5b.1b\n",
    "faostat_prod_1a = fao_stat_copy.rename(columns={\"Value\": \"Fao Area Harvested\", \"IMAGE Classification\": \"NGFBFC\", \"Year\": \"time\"})\n",
    "faostat_prod_1a = pd.merge(left=faostat_prod_1a, right=country_code, left_on='Area', right_on='ISO Country')\n",
    "faostat_prod_1a = faostat_prod_1a[['IMAGE Region Name', 'time', 'NGFBFC', 'Fao Area Harvested']]\n",
    "faostat_prod_1a = faostat_prod_1a.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "faostat_prod_1a = faostat_prod_1a.reset_index()\n",
    "faostat_prod_1a.to_excel(\"/OUTPUT_DATA/REV_fao_stat_area_harvested_mov_average.xlsx\", index=False)\n",
    "\n",
    "# S5b.2b\n",
    "faostat_prod_2a = fao_stat_copy.rename(columns={\"Value\": \"FAO Production\", \"IMAGE Classification\": \"NGFBFC\", \"Year\": \"time\"})\n",
    "faostat_prod_2a = pd.merge(left=faostat_prod_2a, right=country_code, left_on='Area', right_on='ISO Country')\n",
    "faostat_prod_2a = faostat_prod_2a[['IMAGE Region Name', 'time', 'NGFBFC', 'FAO Production']]\n",
    "faostat_prod_2a = faostat_prod_2a.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "faostat_prod_2a = faostat_prod_2a.reset_index()\n",
    "faostat_prod_2a.to_excel(\"/OUTPUT_DATA/REV_fao_stat_production_mov_average_v2_REGION.xlsx\", index=False)\n",
    "\n",
    "# S5b.1c\n",
    "faostat_area_harvested = pd.merge(left=faostat_prod_1a, right=country_code, left_on='Area', right_on='ISO Country')\n",
    "faostat_area_harvested = faostat_area_harvested[['IMAGE Region Name', 'time', 'NGFBFC', 'Fao Area Harvested']]\n",
    "faostat_area_harvested = faostat_area_harvested.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "faostat_area_harvested = faostat_area_harvested.reset_index()\n",
    "faostat_area_harvested.to_excel(\"/OUTPUT_DATA/REV_fao_stat_area_harvested_mov_average_REGION.xlsx\", index=False)\n",
    "faostat_area_harvested = faostat_area_harvested.rename(columns={\"FAO Production\": \"Fao Area Harvested\"})\n",
    "\n",
    "gfrac32_concat_melt = gfrac32_excel.rename(columns={\"value\": \"GFRAC\"})\n",
    "gfrac32_concat_melt = gfrac32_concat_melt.copy()\n",
    "gfrac32_concat_melt.loc[:,'FAO'] = 0.0\n",
    "gfrac32_concat_melt['FAO'] = gfrac32_concat_melt.groupby(['NGFBFC', 'time', 'IMAGE Region Name'])['GFRAC'].transform(lambda x: faostat_area_harvested[(faostat_area_harvested['NGFBFC'] == x.name[0]) & (faostat_area_harvested['time'] == x.name[1]) & (faostat_area_harvested['IMAGE Region Name'] == x.name[2])]['Fao Area Harvested'].sum())\n",
    "gfrac32_concat_melt.loc[:, 'selisih'] = abs(gfrac32_concat_melt['GFRAC'] - gfrac32_concat_melt['FAO'])\n",
    "gfrac32_concat_melt.sort_values(by='selisih', ascending=False)\n",
    "gfrac32_concat_melt.to_excel(\"/OUTPUT_DATA/Komparasi_FAO_GFRAC.xlsx\", index=False)\n",
    "\n",
    "# S5b.2c\n",
    "faostat_production = pd.merge(left=faostat_prod_2a, right=country_code, left_on='Area', right_on='ISO Country')\n",
    "faostat_production = faostat_production[['IMAGE Region Name', 'time', 'NGFBFC', 'FAO Production']]\n",
    "faostat_production = faostat_production.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "faostat_production = faostat_production.reset_index()\n",
    "faostat_production.to_excel(\"/OUTPUT_DATA/REV_fao_stat_area_harvested_mov_average_v2_REGION.xlsx\", index=False)\n",
    "\n",
    "grapc_concat_melted = gfrac32_excel.rename(columns={\"GFRAC\": \"GRAPC\"})\n",
    "grapc_concat_melted = grapc_concat_melted.copy()\n",
    "grapc_concat_melted.loc[:,'FAO'] = 0.0\n",
    "grapc_concat_melted['FAO'] = grapc_concat_melted.groupby(['NGFBFC', 'time', 'IMAGE Region Name'])['GRAPC'].transform(lambda x: faostat_production[(faostat_production['NGFBFC'] == x.name[0]) & (faostat_production['time'] == x.name[1]) & (faostat_production['IMAGE Region Name'] == x.name[2])]['FAO Production'].sum())\n",
    "grapc_concat_melted.loc[:, 'selisih'] = abs(grapc_concat_melted['GRAPC'] - grapc_concat_melted['FAO'])\n",
    "grapc_concat_melted.sort_values(by='selisih', ascending=False)\n",
    "grapc_concat_melted.to_excel(\"/OUTPUT_DATA/Komparasi_FAO_GRAPC.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GECH4RI = pd.read_excel(\"/OUTPUT_DATA/GECH4RI_crop_CH4.xlsx\")\n",
    "GECO2AB_CH4 = pd.read_excel(\"/OUTPUT_DATA/geCH4ab_crop_CH4.xlsx\") \n",
    "GECO2AB_N2O = pd.read_excel(\"/OUTPUT_DATA/geN2Oab_crop_N2O.xlsx\")\n",
    "GEC2OLC = pd.read_excel(\"/OUTPUT_DATA/GEN2OLC_crop_N20.xlsx\")\n",
    "GEN2ORE = pd.read_excel(\"/OUTPUT_DATA/GEN2ORE_crop_v2.xlsx\")\n",
    "GFERTYN = pd.read_excel(\"/OUTPUT_DATA/GFERTILIZER_SYNTHETIC_crop_N20.xlsx\")\n",
    "GMANURE = pd.read_excel(\"/OUTPUT_DATA/GFERTILIZER_crop_N20.xlsx\")\n",
    "\n",
    "peat_CH4 = pd.read_excel(\"/OUTPUT_DATA/emission_peat_CH4_GtCO2eq.xlsx\")\n",
    "peat_CO2 = pd.read_excel(\"/OUTPUT_DATA/emission_peat_CO2_GtCO2eq.xlsx\")\n",
    "peat_DOC = pd.read_excel(\"/OUTPUT_DATA/emission_peat_DOC_GtCO2eq.xlsx\")\n",
    "peat_N2O = pd.read_excel(\"/OUTPUT_DATA/emission_peat_N2O_GtCO2eq.xlsx\")\n",
    "\n",
    "GECH4RI = ngfbfc_processing(GECH4RI)\n",
    "GECO2AB_CH4 = ngfbfc_processing(GECO2AB_CH4)\n",
    "GECO2AB_N2O = ngfbfc_processing(GECO2AB_N2O)\n",
    "GEC2OLC = ngfbfc_processing(GEC2OLC)\n",
    "GEN2ORE = ngfbfc_processing(GEN2ORE)\n",
    "GFERTYN = ngfbfc_processing(GFERTYN)\n",
    "GMANURE = ngfbfc_processing(GMANURE)\n",
    "LUC_agri = ngfbfc_processing(luc_crops_prop_crop_AM1_excel)\n",
    "agri_to_agri = ngfbfc_processing(agri_to_agri_prop_crop_AM1_excel)\n",
    "\n",
    "peat_CH4 = ngfbfc_processing(peat_CH4)\n",
    "peat_CO2 = ngfbfc_processing(peat_CO2)\n",
    "peat_DOC = ngfbfc_processing(peat_DOC)\n",
    "peat_N2O = ngfbfc_processing(peat_N2O)\n",
    "\n",
    "all_sources = pd.concat([LUC_agri, agri_to_agri, GEC2OLC, GECH4RI, GECO2AB_CH4, GECO2AB_N2O, GEN2ORE, GFERTYN, GMANURE, peat_CH4, peat_CO2, peat_DOC, peat_N2O], ignore_index=True)\n",
    "all_sources.columns[:, range(start_time_year+5, end_time_year, interval)] = all_sources.columns[range(start_time_year+5, end_time_year, interval)].values * 5\n",
    "\n",
    "all_sources_copy = all_sources.copy()\n",
    "all_sources_copy.rename(columns={'emissions': 'Process'}, inplace=True)\n",
    "all_sources_copy['Process'] = all_sources_copy['Process'].str.replace(\"peat_DOC\", 'peat_CO2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tahun = []\n",
    "for n in range(start_time_year+5, end_time_year, interval):\n",
    "    n_awal = n - interval\n",
    "    tahun.append(f'{str(n_awal)[2:]}-{str(n)[2:]}')\n",
    "\n",
    "all_sources_process = all_sources_copy.groupby(['Process']).sum()\n",
    "all_sources_process_reset = all_sources_process.reset_index()\n",
    "\n",
    "all_sources_process_drop = all_sources_process_reset.drop(columns=['IMAGE Region Name','NGFBFC'])\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('LUC_Agri', 'Natural Vegetation to Agriculture Emission')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('agri2agri', 'Agricultural Transition Emission')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('GEN2OLC', 'N2O Land Clearing')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('GECH4RI', 'CH4 Wetland Rice')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('agri_burn_CH4', 'CH4 Agriculture Waste Burning')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('agri_burn_N2O', 'N2O Agriculture Waste Burning')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('GEN2ORE', 'N2O Agriculture Residues')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('GFERTSYN', 'N2O Synthetic Fertilizer')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('GMANURE', 'N2O Manure Fertilizer')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('peat_CH4', 'CH4 Drained Peatland')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('peat_CO2', 'CO2 Drained Peatland')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('peat_CH4', 'CH4 Drained Peatland')\n",
    "all_sources_process_drop['Process'] = all_sources_process_drop['Process'].replace('peat_N2O', 'N2O Drained Peatland')\n",
    "\n",
    "new_columns_order_process = [6,5,1,9,10,11,3,4,7,8,2,0]\n",
    "all_sources_process_reordered = all_sources_process_drop.reindex(new_columns_order_process)\n",
    "all_sources_process_reordered = all_sources_process_reordered.reset_index()\n",
    "all_sources_process_reordered = all_sources_process_reordered.drop(columns = \"index\")\n",
    "all_sources_process_reordered_index = all_sources_process_reordered.set_index('Process')\n",
    "value_all_sources_process = all_sources_process_reordered_index.T.values\n",
    "\n",
    "panel_A = pd.DataFrame(value_all_sources_process, index=tahun, columns=columns1)\n",
    "ax1 = panel_A.plot(kind='bar', stacked=True, color=colors1, figsize=(14, 8), legend=False)\n",
    "\n",
    "plt.xlabel('Year', fontweight='bold', fontsize=15)\n",
    "plt.ylabel(r\"$\\bf{Carbon\\ Emissions\\ (Gt~CO_2 eq.)/\\ year}$\", fontsize=15)\n",
    "plt.xticks([r for r in range(len(tahun))], tahun, rotation=0)\n",
    "plt.axhline(0, color='black', linewidth=0.8)\n",
    "\n",
    "yticks = np.arange(0, 6, 1)\n",
    "plt.yticks(yticks)\n",
    "\n",
    "handles = []\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "labels.append('Average annual emission (Gt CO2/ year)')\n",
    "\n",
    "order1 = [11,10,9,8,7,6,5,4,3,2,1,0]\n",
    "ax1.legend([handles[idx] for idx in order1], [labels[idx] for idx in order1], title='Emissions Category', loc='upper left', bbox_to_anchor=(1.01, 1.0), ncol=1)\n",
    "plt.show()\n",
    "plt.savefig('/VIZ/Grafik_panelA.png')\n",
    "\n",
    "all_source_crops = all_sources_copy.groupby(['NGFBFC']).sum()\n",
    "all_source_crops_reset = all_source_crops.reset_index()\n",
    "all_source_crops_drop = all_source_crops_reset.drop(columns=['IMAGE Region Name','Process'])\n",
    "all_source_crops_drop['NGFBFC'] = all_source_crops_drop['NGFBFC'].replace('grass', 'pasture')\n",
    "all_source_crops_drop = ngfbfc_processing(all_source_crops_drop)\n",
    "\n",
    "all_source_crops_drop.set_index('NGFBFC', inplace=True)\n",
    "all_source_crops_reorder = all_source_crops_drop.reindex(list(colors.keys()))\n",
    "value_all_sources_crops = all_source_crops_reorder.T.values\n",
    "\n",
    "panel_B = pd.DataFrame(value_all_sources_crops, index=tahun, columns=list(colors.keys()))\n",
    "ax2 = panel_B.plot(kind='bar', stacked=True, color=list(colors.values()), figsize=(14, 8), legend=False)\n",
    "plt.xlabel('Year', fontweight='bold', fontsize=15)\n",
    "plt.ylabel(r\"$\\bf{Carbon\\ Emissions\\ (Gt~CO_2)}$\", fontsize=15)\n",
    "plt.xticks([r for r in range(len(tahun))], tahun, rotation=360)\n",
    "plt.axhline(0, color='black', linewidth=0.8)\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "labels.append('Average annual emission (Gt CO2/ year)')\n",
    "\n",
    "order2 = [16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0]\n",
    "ax2.legend([handles[idx] for idx in order2], [labels[idx] for idx in order2], title='Crop categories', loc='upper right', bbox_to_anchor=(1.23, 1.0), ncol=1)\n",
    "plt.show()\n",
    "plt.savefig('/VIZ/Grafik_panelB.png')\n",
    "\n",
    "all_sources_region = all_sources_copy.groupby(['IMAGE Region Name']).sum()\n",
    "all_sources_region_reset = all_sources_region.reset_index()\n",
    "all_sources_region_drop = all_sources_region_reset.drop(columns=['Process','NGFBFC'])\n",
    "all_sources_region_drop = region_processing(all_sources_region_drop)\n",
    "all_sources_region_drop = all_sources_region_drop.set_index(\"IMAGE Region Name\")\n",
    "all_source_region_reorder = all_sources_region_drop.reindex(list(palettes.keys()))\n",
    "value_all_sources_region = all_source_region_reorder.T.values\n",
    "\n",
    "panel_C = pd.DataFrame(value_all_sources_region, index=tahun, columns=list(palettes.keys()))\n",
    "ax3 = panel_C.plot(kind='bar', stacked=True, color=list(palettes.values()), figsize=(14, 8), legend=False)\n",
    "\n",
    "plt.xlabel('Year', fontweight='bold', fontsize=15)\n",
    "plt.ylabel(r\"$\\bf{GHG\\ Emissions\\ (Gt~CO_2-eq.)/\\ year}$\", fontsize=15)\n",
    "plt.xticks([r for r in range(len(tahun))], tahun, rotation=360)\n",
    "plt.axhline(0, color='black', linewidth=0.8)\n",
    "\n",
    "handles, labels = ax3.get_legend_handles_labels()\n",
    "order3 = [25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,0]\n",
    "ax3.legend([handles[idx] for idx in order3], [labels[idx] for idx in order3], title='IMAGE Region', loc='upper right', bbox_to_anchor=(1.22, 1.0), ncol=1)\n",
    "plt.show()\n",
    "plt.savefig('/VIZ/Grafik_panelC.png')\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(13, 18))\n",
    "axs[0] = panel_A.plot(kind='bar', stacked=True, color=colors1, ax=axs[0], legend=False)\n",
    "axs[0].set_ylabel(r\"$\\bf{GHG\\ Emissions\\ (Gt~CO_2-eq.)/\\ year}$\", fontsize=15)\n",
    "axs[0].set_xticks([r for r in range(len(tahun))])\n",
    "axs[0].set_xticklabels(tahun, rotation=0)\n",
    "axs[0].axhline(0, color='black', linewidth=0.8)\n",
    "\n",
    "axs[1] = panel_B.plot(kind='bar', stacked=True, color=list(colors.values()), ax=axs[1], legend=False)\n",
    "axs[1].set_ylabel(r\"$\\bf{GHG\\ Emissions\\ (Gt~CO_2-eq.)/\\ year}$\", fontsize=15)\n",
    "axs[1].set_xticks([r for r in range(len(tahun))])\n",
    "axs[1].set_xticklabels(tahun, rotation=360)\n",
    "axs[1].axhline(0, color='black', linewidth=0.8)\n",
    "\n",
    "axs[2] = panel_C.plot(kind='bar', stacked=True, color=list(palettes.values()), ax=axs[2], legend=False)\n",
    "axs[2].set_ylabel(r\"$\\bf{GHG\\ Emissions\\ (Gt~CO_2-eq.)/\\ year}$\", fontsize=15)\n",
    "axs[2].set_xticks([r for r in range(len(tahun))])\n",
    "axs[2].set_xticklabels(tahun, rotation=360)\n",
    "axs[2].axhline(0, color='black', linewidth=0.8)\n",
    "axs[2].set_xlabel('Year', fontweight='bold', fontsize=15)\n",
    "\n",
    "bbox_transform = fig.transFigure\n",
    "plt.rc('text', usetex=False)\n",
    "\n",
    "handles1, labels1 = axs[0].get_legend_handles_labels()\n",
    "axs[0].legend([handles1[idx] for idx in order1], [labels1[idx] for idx in order1] ,edgecolor='white',loc='upper left', bbox_to_anchor=(1.005, 0.95))\n",
    "\n",
    "handles2, labels2 = axs[1].get_legend_handles_labels()\n",
    "axs[1].legend([handles2[idx] for idx in order2], [labels2[idx] for idx in order2], edgecolor='white', loc='upper left', bbox_to_anchor=(1.005, 1), ncol=1)\n",
    "\n",
    "handles3, labels3 = axs[2].get_legend_handles_labels()\n",
    "axs[2].legend([handles3[idx] for idx in order3], [labels3[idx] for idx in order3],edgecolor='white', loc='upper left', bbox_to_anchor=(1.005, 1), ncol=1)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.001)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('/VIZ/Grafik_panelABC.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources_copy = all_sources[all_sources['NGFBFC'] != 'pasture']\n",
    "\n",
    "df_LUC = all_sources_copy[(all_sources_copy['emissions'] == 'LUC_Agri') | (all_sources_copy['emissions'] == 'agri2agri') | (all_sources_copy['emissions'] == 'GEN2OLC')]\n",
    "df_LUC = df_LUC.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "df_LUC = df_LUC.reset_index()\n",
    "df_LUC = df_LUC.drop(columns=['emissions'])\n",
    "df_LUC.columns[:, range(start_time_year+5, end_time_year, interval)] = (df_LUC.columns[range(start_time_year+5, end_time_year, interval)].values * 5)\n",
    "\n",
    "df_LUC_melt = df_LUC.melt(id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "df_LUC_melt.loc[:, 'emissions'] = \"LUC\"\n",
    "\n",
    "df_AGRI = all_sources_copy[~(all_sources_copy['emissions'] == 'LUC_Agri') | ~(all_sources_copy['emissions'] == 'agri2agri') | ~(all_sources_copy['emissions'] == 'GEN2OLC')]\n",
    "df_AGRI = df_AGRI.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "df_AGRI = df_AGRI.reset_index()\n",
    "df_AGRI = df_AGRI.drop(columns=['emissions'])\n",
    "df_AGRI.columns[:, range(start_time_year+5, end_time_year, interval)] = (df_AGRI.columns[range(start_time_year+5, end_time_year, interval)].values * 5)\n",
    "\n",
    "df_AGRI_melt = df_AGRI.melt(id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "df_AGRI_melt.loc[:, 'emissions'] = \"AGRI\"\n",
    "\n",
    "data_2kategori = pd.concat([df_LUC_melt, df_AGRI_melt], ignore_index=True)\n",
    "data_2kategori_drop = data_2kategori.drop(columns=['emissions'])\n",
    "data_2kategori = data_2kategori_drop.groupby(columns).sum()\n",
    "data_2kategori = data_2kategori.reset_index()\n",
    "\n",
    "region_code_map = country_code.set_index('IMAGE Region Name')['IMAGE Region Code'].to_dict()\n",
    "data_2kategori['IMAGE Region Name'] = data_2kategori['IMAGE Region Name'].map(region_code_map)\n",
    "\n",
    "for time in range(start_time_year+5, end_time_year, interval):\n",
    "    data_2kategori = data_2kategori[data_2kategori['time'] == time]\n",
    "\n",
    "    df_top3 = get_top_n(data_2kategori, 'NGFBFC', 'value', 3)\n",
    "    total_top3 = df_top3.groupby('NGFBFC')['value'].sum()\n",
    "    total_top3 = total_top3.reset_index()\n",
    "\n",
    "    total_per_NGFBFC = data_2kategori.groupby('NGFBFC')['value'].sum()\n",
    "    total_per_NGFBFC = total_per_NGFBFC.reset_index()\n",
    "    df_others_sum = total_per_NGFBFC.merge(total_top3, on='NGFBFC', how='left', suffixes=('', '_top3'))\n",
    "    df_others_sum['value'] = df_others_sum['value'] - df_others_sum['value_top3'].fillna(0)\n",
    "    df_others_sum = df_others_sum[df_others_sum['value'] > 0] \n",
    "    df_others_sum['IMAGE Region Name'] = \"others\"\n",
    "\n",
    "    df_combined = pd.concat([df_top3, df_others_sum[['NGFBFC', 'value', 'IMAGE Region Name']]], ignore_index=True)\n",
    "    df_combined = df_combined[df_combined['NGFBFC'] != 'pasture']\n",
    "\n",
    "    df_combined['color_order'] = df_combined['NGFBFC'].map(lambda x: list(colors.keys()).index(x) if x in colors else len(colors))\n",
    "    df_combined = df_combined.sort_values('color_order').drop('color_order', axis=1)\n",
    "\n",
    "    ring1_data = df_combined.groupby('NGFBFC')['value'].sum()\n",
    "    ring1_labels = [i for i in colors.keys() if i != 'pasture']\n",
    "    ring1_data = ring1_data.reindex(ring1_labels)\n",
    "    ring1_colors = [colors[label] for label in ring1_labels]\n",
    "\n",
    "    ring1_percent = ring1_data / ring1_data.sum() * 100\n",
    "\n",
    "    ring2_data = df_combined.groupby(['NGFBFC', 'IMAGE Region Name'])['value'].sum()\n",
    "\n",
    "    NGFBFCs_list = list(colors.keys())\n",
    "    final_data = []\n",
    "\n",
    "    for NGFBFC_name in NGFBFCs_list:\n",
    "        if NGFBFC_name in ring2_data.index.get_level_values(0):\n",
    "            NGFBFC_data = ring2_data.xs(NGFBFC_name)\n",
    "            angle = get_angular_position(NGFBFC_name, NGFBFCs_list)\n",
    "            \n",
    "            others_value = NGFBFC_data['others'] if 'others' in NGFBFC_data.index else None\n",
    "            non_others = NGFBFC_data[NGFBFC_data.index != 'others'].sort_values(ascending=False)\n",
    "            \n",
    "            if 300 <= angle or angle <= 70:\n",
    "                non_others = NGFBFC_data[NGFBFC_data.index != 'others'].sort_values(ascending=True)\n",
    "                if others_value is not None:\n",
    "                    regions = ['others'] + non_others.index.tolist()\n",
    "                    values = [others_value] + non_others.values.tolist()\n",
    "                else:\n",
    "                    regions = non_others.index.tolist()\n",
    "                    values = non_others.values.tolist()\n",
    "            else:\n",
    "                if others_value is not None:\n",
    "                    regions = non_others.index.tolist() + ['others']\n",
    "                    values = non_others.values.tolist() + [others_value]\n",
    "                else:\n",
    "                    regions = non_others.index.tolist()\n",
    "                    values = non_others.values.tolist()\n",
    "            \n",
    "            for region, value in zip(regions, values):\n",
    "                final_data.append(((NGFBFC_name, region), value))\n",
    "\n",
    "    ring2_data = pd.Series(dict(final_data))\n",
    "    ring2_labels = ring2_data.index.get_level_values(1)\n",
    "\n",
    "    ring2_colors = []\n",
    "    for NGFBFC_name in colors.keys():\n",
    "        if NGFBFC_name in ring2_data.index.get_level_values(0):\n",
    "            NGFBFC_data = ring2_data.xs(NGFBFC_name)\n",
    "            ring2_colors.extend([colors[NGFBFC_name]] * len(NGFBFC_data))\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = gridspec.GridSpec(2, 2, figure=fig, hspace=0.2, wspace=0.2, width_ratios=[7,3], height_ratios=[7,3])\n",
    "    ax = fig.add_subplot(gs[:, 0], aspect=\"equal\")\n",
    "\n",
    "    plt.title(f\"{time}\")\n",
    "\n",
    "    inner_pie, _ = ax.pie(ring1_data, radius=1.2, colors=ring1_colors, wedgeprops=dict(width=1, edgecolor='#808080'), startangle=90)\n",
    "    outer_pie, _ = ax.pie(ring2_data, radius=1.5, colors=ring2_colors, wedgeprops=dict(width=0.7, edgecolor='#808080'), startangle=90)\n",
    "\n",
    "    for i, (label, percent) in enumerate(zip(ring1_labels, ring1_percent)):\n",
    "        ang = (inner_pie[i].theta2 + inner_pie[i].theta1) / 2\n",
    "        x = 0.5 * np.cos(np.deg2rad(ang))\n",
    "        y = 0.5 * np.sin(np.deg2rad(ang))\n",
    "        rotation = ang + 180 if 90 <= ang <= 270 else ang\n",
    "        ax.text(x, y, f'{percent:.1f}%', ha='center', va='center', rotation=rotation, \n",
    "                color='black', fontsize=14, fontweight='bold',\n",
    "                path_effects=[path_effects.Stroke(linewidth=3, foreground='white'), \n",
    "                            path_effects.Normal()])\n",
    "\n",
    "    for i, label in enumerate(ring2_labels):\n",
    "        ang = (outer_pie[i].theta2 + outer_pie[i].theta1) / 2\n",
    "        x = 1.2 * np.cos(np.deg2rad(ang))\n",
    "        y = 1.2 * np.sin(np.deg2rad(ang))\n",
    "        rotation = ang + 180 if 90 <= ang <= 270 else ang\n",
    "        ax.text(x, y, f'{label}', ha='center', va='center', rotation=rotation,\n",
    "                color='black', fontsize=12, fontweight='bold',\n",
    "                path_effects=[path_effects.Stroke(linewidth=4, foreground='white'),\n",
    "                            path_effects.Normal()])\n",
    "\n",
    "    legend_handles = [plt.Rectangle((0, 0), 1, 1, edgecolor='#808080', facecolor=color) for color in dict(reversed(colors.items())).values()]\n",
    "    \n",
    "    legend_ax = fig.add_subplot(gs[0, 1])\n",
    "    legend_ax.axis('off') \n",
    "    legend_ax.legend(handles=legend_handles,\n",
    "            labels=[label for label in dict(reversed(colors.items())).keys()],\n",
    "            title=\"Crop Categories\", title_fontsize=14,\n",
    "            bbox_to_anchor=(0,0.1), loc=\"lower left\", fontsize=12)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.savefig(f'/VIZ/PieChart_multiyear_{time}.png')\n",
    "\n",
    "df_AGRI_melt = df_AGRI.melt(id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "df_AGRI_melt = df_AGRI_melt.drop(columns=['time'])\n",
    "df_AGRI_groupby = df_AGRI_melt.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "df_AGRI_index = df_AGRI_groupby.reset_index()\n",
    "df_AGRI_index.loc[:, 'emissions'] = \"AGRI\"\n",
    "\n",
    "df_LUC_melt = df_LUC.melt(id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "df_LUC_melt = df_LUC_melt.drop(columns=['time'])\n",
    "df_LUC_groupby = df_LUC_melt.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "df_LUC_index = df_LUC_groupby.reset_index()\n",
    "df_LUC_index.loc[:, 'emissions'] = \"LUC\"\n",
    "\n",
    "data_2kategori = pd.concat([df_AGRI_index, df_LUC_index], ignore_index=True)\n",
    "data_2kategori_drop = data_2kategori.drop(columns=['emissions'])\n",
    "data_2kategori_sum = data_2kategori_drop.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "data_2kategori_sum = data_2kategori_sum.reset_index()\n",
    "\n",
    "region_code_map = country_code.set_index('IMAGE Region Name')['IMAGE Region Code'].to_dict()\n",
    "data_2kategori_sum['IMAGE Region Name'] = data_2kategori_sum['IMAGE Region Name'].map(region_code_map)\n",
    "total_per_NGFBFC = data_2kategori_sum.groupby('NGFBFC')['value'].sum()\n",
    "total_per_NGFBFC = total_per_NGFBFC.reset_index()\n",
    "\n",
    "df_top3 = get_top_n(data_2kategori_sum, 'NGFBFC', 'value', 3)\n",
    "total_top3 = df_top3.groupby('NGFBFC')['value'].sum()\n",
    "total_top3 = total_top3.reset_index()\n",
    "\n",
    "df_others_sum = total_per_NGFBFC.merge(total_top3, on='NGFBFC', how='left', suffixes=('', '_top3'))\n",
    "df_others_sum['value'] = df_others_sum['value'] - df_others_sum['value_top3'].fillna(0)\n",
    "df_others_sum = df_others_sum[df_others_sum['value'] > 0]  \n",
    "df_others_sum['IMAGE Region Name'] = \"others\"\n",
    "\n",
    "df_combined = pd.concat([df_top3, df_others_sum[['NGFBFC', 'value', 'IMAGE Region Name']]], ignore_index=True)\n",
    "df_combined = df_combined[df_combined['NGFBFC'] != 'grass']\n",
    "\n",
    "df_combined['color_order'] = df_combined['NGFBFC'].map(lambda x: list(colors.keys()).index(x))\n",
    "df_combined = df_combined.sort_values('color_order').drop('color_order', axis=1)\n",
    "\n",
    "ring1_data = df_combined.groupby('NGFBFC')['value'].sum()\n",
    "ring1_labels = [i for i in colors.keys() if i != 'pasture']\n",
    "ring1_data = ring1_data.reindex(ring1_labels)\n",
    "ring1_colors = [colors[label] for label in ring1_labels]\n",
    "\n",
    "ring1_percent = ring1_data / ring1_data.sum() * 100\n",
    "ring2_data = df_combined.groupby(['NGFBFC', 'IMAGE Region Name'])['value'].sum()\n",
    "\n",
    "NGFBFCs_list = list(colors.keys())\n",
    "final_data = []\n",
    "for NGFBFC_name in NGFBFCs_list:\n",
    "    if NGFBFC_name in ring2_data.index.get_level_values(0):\n",
    "        NGFBFC_data = ring2_data.xs(NGFBFC_name)\n",
    "        angle = get_angular_position(NGFBFC_name, NGFBFCs_list)\n",
    "        \n",
    "        others_value = NGFBFC_data['others'] if 'others' in NGFBFC_data.index else None\n",
    "        non_others = NGFBFC_data[NGFBFC_data.index != 'others'].sort_values(ascending=False)\n",
    "        \n",
    "        if 300 <= angle or angle <= 70:\n",
    "            non_others = NGFBFC_data[NGFBFC_data.index != 'others'].sort_values(ascending=True)\n",
    "            if others_value is not None:\n",
    "                regions = ['others'] + non_others.index.tolist()\n",
    "                values = [others_value] + non_others.values.tolist()\n",
    "            else:\n",
    "                regions = non_others.index.tolist()\n",
    "                values = non_others.values.tolist()\n",
    "        else:\n",
    "            if others_value is not None:\n",
    "                regions = non_others.index.tolist() + ['others']\n",
    "                values = non_others.values.tolist() + [others_value]\n",
    "            else:\n",
    "                regions = non_others.index.tolist()\n",
    "                values = non_others.values.tolist()\n",
    "        \n",
    "        for region, value in zip(regions, values):\n",
    "            final_data.append(((NGFBFC_name, region), value))\n",
    "\n",
    "ring2_data = pd.Series(dict(final_data))\n",
    "ring2_labels = ring2_data.index.get_level_values(1)\n",
    "\n",
    "ring2_colors = []\n",
    "for NGFBFC_name in colors.keys():\n",
    "    if NGFBFC_name != 'pasture':\n",
    "        if NGFBFC_name in ring2_data.index.get_level_values(0):\n",
    "            NGFBFC_data = ring2_data.xs(NGFBFC_name)\n",
    "            ring2_colors.extend([colors[NGFBFC_name]] * len(NGFBFC_data))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = gridspec.GridSpec(2, 2, figure=fig, hspace=0.2, wspace=0.2, width_ratios=[7,3], height_ratios=[7,3])\n",
    "ax = fig.add_subplot(gs[:, 0], aspect=\"equal\")\n",
    "\n",
    "inner_pie, _ = ax.pie(ring1_data, radius=1.2, colors=ring1_colors, wedgeprops=dict(width=1, edgecolor='#808080'), startangle=90)\n",
    "outer_pie, _ = ax.pie(ring2_data, radius=1.5, colors=ring2_colors, wedgeprops=dict(width=0.7, edgecolor='#808080'), startangle=90)\n",
    "\n",
    "for i, (label, percent) in enumerate(zip(ring1_labels, ring1_percent)):\n",
    "    ang = (inner_pie[i].theta2 + inner_pie[i].theta1) / 2\n",
    "    x = 0.5 * np.cos(np.deg2rad(ang))\n",
    "    y = 0.5 * np.sin(np.deg2rad(ang))\n",
    "    rotation = ang + 180 if 90 <= ang <= 270 else ang\n",
    "    ax.text(x, y, f'{percent:.1f}%', ha='center', va='center', rotation=rotation, \n",
    "            color='black', fontsize=14, fontweight='bold',\n",
    "            path_effects=[path_effects.Stroke(linewidth=3, foreground='white'), \n",
    "                        path_effects.Normal()])\n",
    "\n",
    "for i, label in enumerate(ring2_labels):\n",
    "    ang = (outer_pie[i].theta2 + outer_pie[i].theta1) / 2\n",
    "    x = 1.2 * np.cos(np.deg2rad(ang))\n",
    "    y = 1.2 * np.sin(np.deg2rad(ang))\n",
    "    rotation = ang + 180 if 90 <= ang <= 270 else ang\n",
    "    ax.text(x, y, f'{label}', ha='center', va='center', rotation=rotation,\n",
    "            color='black', fontsize=12, fontweight='bold',\n",
    "            path_effects=[path_effects.Stroke(linewidth=4, foreground='white'),\n",
    "                        path_effects.Normal()])\n",
    "        \n",
    "legend_handles = [plt.Rectangle((0, 0), 1, 1, edgecolor='#808080', facecolor=color) for color in dict(reversed(colors.items())).values()]\n",
    "plt.legend(handles=legend_handles,\n",
    "           labels=[label for label in dict(reversed(colors.items())).keys()],\n",
    "           title=\"Crop Categories\",title_fontsize=14,\n",
    "           bbox_to_anchor=(1.1, 1), loc=\"upper left\", fontsize=12)\n",
    "plt.show()\n",
    "plt.savefig(f'/VIZ/PieChart_akumulasi_{start_time_year+5}-{end_time_year}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources_group = all_sources_copy.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "all_sources_group = all_sources_group.reset_index()\n",
    "all_sources_group = region_processing(all_sources_group)\n",
    "all_sources_group = ngfbfc_processing(all_sources_group)\n",
    "all_sources_group = all_sources_group[all_sources_group['NGFBFC'] != 'pasture']\n",
    "\n",
    "all_sources_group_copy = all_sources_group.copy()\n",
    "all_sources_group_copy.loc[:, range(start_time_year+5, end_time_year, interval)] = all_sources_group_copy[range(start_time_year+5, end_time_year, interval)].values * 1e3\n",
    "all_sources_group_copy['IMAGE Realtion'] =  all_sources_group_copy['NGFBFC'] + \" - \"  + all_sources_group_copy['IMAGE Region Name']\n",
    "all_sources_group_copy = all_sources_group_copy[list(range(start_time_year+5, end_time_year, interval)) + ['IMAGE Realtion']]\n",
    "\n",
    "df_crops = all_sources_group_copy.melt(id_vars=['IMAGE Realtion'], var_name='Time', value_name='value')\n",
    "df_crops = df_crops[df_crops['IMAGE Realtion'] != 'wheat - Rest of South Asia']\n",
    "\n",
    "results_crops = {}\n",
    "df_crops_sort = df_crops.sort_values(by=['value'], ascending=[True])\n",
    "for time in df_crops_sort['Time'].unique():\n",
    "    filtered_data = df_crops_sort[df_crops_sort['Time'] == time]\n",
    "    sorted_data = filtered_data.sort_values(by='value', ascending=False)\n",
    "    top_5_data = sorted_data.head(3)\n",
    "    if time not in results_crops:\n",
    "        results_crops[time] = {}\n",
    "    results_crops[time] = top_5_data\n",
    "\n",
    "time_map = {}\n",
    "for n in range(start_time_year+5, end_time_year, interval):\n",
    "    n_awal = n - interval\n",
    "    time_map[n] = f'{str(n_awal)[2:]}-{str(n)[2:]}'\n",
    "\n",
    "df_crops_concat = pd.concat([pd.concat(results_crops.values())])\n",
    "df_crops_concat_copy = df_crops_concat.copy()\n",
    "df_crops_concat_copy['Time'] = df_crops_concat_copy['Time'].map(time_map)\n",
    "df_crops_concat_copy_sorted = df_crops_concat_copy.sort_values(by=['Time', 'value'], ascending=[False, False])\n",
    "\n",
    "plt.figure(figsize=(25, 6), dpi=300)\n",
    "loc = plticker.MultipleLocator(base=1)\n",
    "ax2 = plt.subplot(131)\n",
    "ax2.set_ylabel(r\"$\\bf{GHG\\ Emissions\\ (Mt~CO_2-eq)/\\ year}$\", fontsize=10)\n",
    "ax2.set_xlabel('Years',fontweight='bold', fontsize=10)\n",
    "\n",
    "sns.scatterplot(x=\"Time\", y=\"value\", color='#DDDDDD', sizes=(100, 300), alpha=.3, data=df_crops)\n",
    "sns.scatterplot(x=\"Time\", y=\"value\", hue='IMAGE Realtion',alpha=.8, palette=palette, style='IMAGE Realtion', markers=markers, s=60, \n",
    "                data=df_crops_concat_copy_sorted.sort_values(by=['IMAGE Realtion'], ascending=[True]), hue_order=legend_order)\n",
    "\n",
    "ax2.legend(loc='lower left', bbox_to_anchor= (1.01, 0.45), ncol=1, prop={'size': 8})\n",
    "ax2.xaxis.set_major_locator(loc)\n",
    "ax2.set_ylim(ymin=0)\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(f'/VIZ/scatterplot_{start_time_year+5}-{end_time_year}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['IMAGE Region Name', 'NGFBFC'] + [x for x in range(start_time_year+5, end_time_year, interval)]\n",
    "\n",
    "df_all_sources_copy = all_sources.copy()\n",
    "df_all_sources_copy = ngfbfc_processing(df_all_sources_copy)\n",
    "df_all_sources_copy = df_all_sources_copy[~df_all_sources_copy['NGFBFC'].str.contains(\"pasture\")]\n",
    "\n",
    "df_all_sources_copy = df_all_sources_copy[columns]\n",
    "df_all_sources_copy = df_all_sources_copy.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "df_all_sources_copy = df_all_sources_copy.reset_index()\n",
    "df_all_sources_melt = df_all_sources_copy.melt(id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "df_all_sources_melt['value'] = df_all_sources_melt['value'] * 1e9\n",
    "\n",
    "df_GFRACcombined_copy = gfrac_area_7020_excel.copy()\n",
    "df_GFRACcombined_copy = ngfbfc_processing(df_GFRACcombined_copy)\n",
    "df_GFRACcombined_copy = df_GFRACcombined_copy[~df_GFRACcombined_copy['NGFBFC'].str.contains(\"grass\")]\n",
    "\n",
    "df_GFRACcombined_copy = pd.merge(left=country_code, right=df_GFRACcombined_copy, how=\"left\", left_on=\"ISO Country\", right_on=\"country\")\n",
    "df_GFRACcombined_copy = df_GFRACcombined_copy[columns]\n",
    "df_GFRACcombined_copy = df_GFRACcombined_copy[~(df_GFRACcombined_copy['IMAGE Region Name'] == \"N|A\")]\n",
    "df_GFRACcombined_copy = df_GFRACcombined_copy.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "df_GFRACcombined_copy = df_GFRACcombined_copy.reset_index()\n",
    "df_GFRACcombined_melt = pd.melt(df_GFRACcombined_copy, id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "\n",
    "CF_emisi_total_GFRAC_area = df_all_sources_melt.copy()\n",
    "CF_emisi_total_GFRAC_area = CF_emisi_total_GFRAC_area.drop(columns=['value'])\n",
    "\n",
    "IMAGERegionName\t= CF_emisi_total_GFRAC_area[\"IMAGE Region Name\"].to_list()\n",
    "time = CF_emisi_total_GFRAC_area[\"time\"].to_list()\n",
    "ngfbfc = CF_emisi_total_GFRAC_area[\"NGFBFC\"].to_list()\n",
    "for region, time, ngfbfc in zip(IMAGERegionName, time, ngfbfc):\n",
    "    try:\n",
    "        data1 = df_all_sources_melt[(df_all_sources_melt['IMAGE Region Name'] == region) & (df_all_sources_melt['time'] == time) & (df_all_sources_melt['NGFBFC'] == ngfbfc)]['value'].to_numpy()\n",
    "        data2 = df_GFRACcombined_melt[(df_GFRACcombined_melt['IMAGE Region Name'] == region) & (df_GFRACcombined_melt['time'] == time) & (df_GFRACcombined_melt['NGFBFC'] == ngfbfc)]['value'].to_numpy()\n",
    "        if data1.size == 0:\n",
    "            data1 = [0]\n",
    "        if data2.size == 0: \n",
    "            data2 = [0]\n",
    "        mask = df_all_sources_melt[(df_all_sources_melt['IMAGE Region Name'] == region) & (df_all_sources_melt['time'] == time) & (df_all_sources_melt['NGFBFC'] == ngfbfc)].index\n",
    "        CF_emisi_total_GFRAC_area.loc[mask, 'CF'] = data1[0] / data2[0]\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e} for region {region}\")\n",
    "\n",
    "CF_emisi_total_GFRAC_area['CF'] = CF_emisi_total_GFRAC_area['CF'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "df_GFRAC_Area_copy = restructur_index.copy()\n",
    "df_GFRAC_Area_copy = df_GFRAC_Area_copy[df_GFRAC_Area_copy['time'] >= start_time_year+5]\n",
    "df_GFRAC_Area_copy = ngfbfc_processing(df_GFRAC_Area_copy)\n",
    "df_GFRAC_Area_selected = df_GFRAC_Area_copy[~df_GFRAC_Area_copy['NGFBFC'].str.contains(\"grass\")]\n",
    "\n",
    "CF_emisi_total_AH = df_all_sources_melt.copy()\n",
    "CF_emisi_total_AH = CF_emisi_total_AH.drop(columns=['value'])\n",
    "\n",
    "IMAGERegionName = CF_emisi_total_AH[\"IMAGE Region Name\"].to_list()\n",
    "time = CF_emisi_total_AH[\"time\"].to_list()\n",
    "ngfbfc = CF_emisi_total_AH[\"NGFBFC\"].to_list()\n",
    "for region, time, ngfbfc in zip(IMAGERegionName, time, ngfbfc):\n",
    "    try:\n",
    "        data1 = df_all_sources_melt[(df_all_sources_melt['IMAGE Region Name'] == region) & (df_all_sources_melt['time'] == time) & (df_all_sources_melt['NGFBFC'] == ngfbfc)]['value'].to_numpy()\n",
    "        data2 = df_GFRAC_Area_selected[(df_GFRAC_Area_selected['IMAGE Region Name'] == region) & (df_GFRAC_Area_selected['time'] == time) & (df_GFRAC_Area_selected['NGFBFC'] == ngfbfc)]['value'].to_numpy()\n",
    "        if data1.size == 0:\n",
    "            data1 = [0]\n",
    "        if data2.size == 0: \n",
    "            data2 = [0]\n",
    "        mask = df_all_sources_melt[(df_all_sources_melt['IMAGE Region Name'] == region) & (df_all_sources_melt['time'] == time) & (df_all_sources_melt['NGFBFC'] == ngfbfc)].index\n",
    "        CF_emisi_total_AH.loc[mask, 'CF'] = data1[0] / data2[0]\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e} for region {region}\")\n",
    "\n",
    "CF_emisi_total_AH['CF'] = CF_emisi_total_AH['CF'].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "df1 = CF_emisi_total_AH.copy()\n",
    "df2 = df_GFRAC_Area_selected.copy()\n",
    "\n",
    "df1.loc[df1['CF'] > 50, 'CF'] = 0\n",
    "df1 = ngfbfc_processing(df1)\n",
    "df2 = ngfbfc_processing(df2)\n",
    "\n",
    "data1 = np.zeros((len(list(range(start_time_year+5, end_time_year, interval))), len(df1['NGFBFC'].unique()), len(df2['IMAGE Region Name'].unique())), dtype='float32')\n",
    "average_AreaHarvested_RegionCrops = np.zeros((len(list(range(start_time_year+5, end_time_year, interval))), len(df1['NGFBFC'].unique()), len(df2['IMAGE Region Name'].unique())), dtype='float32')\n",
    "result_average = np.zeros((len(df1['NGFBFC'].unique()), len(list(range(start_time_year+5, end_time_year, interval)))), dtype='float32')\n",
    "for n, time in enumerate(range(start_time_year+5, end_time_year, interval)):\n",
    "    for i, ngfbfc in enumerate(df1['NGFBFC'].unique()):\n",
    "        for j, image_region in enumerate(df2['IMAGE Region Name'].unique()):\n",
    "            ngfbfc_areaharves = df2[(df2['time'] == time) & (df2['IMAGE Region Name'] == image_region) & (df2['NGFBFC'] == ngfbfc)]['value'].replace([np.inf, -np.inf], np.nan).values\n",
    "            average_AreaHarvested_RegionCrops[n][i][j] = np.nan_to_num(ngfbfc_areaharves)\n",
    "\n",
    "for n, time in enumerate(range(start_time_year+5, end_time_year, interval)):\n",
    "    for i, ngfbfc in enumerate(df1['NGFBFC'].unique()):\n",
    "        carbon_footprint = df1[(df1['time'] == time) & (df1['NGFBFC'] == ngfbfc)]['CF'].replace([np.inf, -np.inf], np.nan).values\n",
    "        data1[n][i] = np.nan_to_num(carbon_footprint)\n",
    "\n",
    "for i, ngfbfc in enumerate(df1['NGFBFC'].unique()):    \n",
    "    for n, time in enumerate(range(start_time_year+5, end_time_year, interval)):\n",
    "        result_average[i][n] = np.average(data1[n][i], weights=average_AreaHarvested_RegionCrops[n][i])\n",
    "\n",
    "df_avg = pd.DataFrame(result_average, index=[df2['NGFBFC'].unique()], columns=list(range(start_time_year+5, end_time_year, interval)))\n",
    "df_avg = df_avg.reset_index()\n",
    "df_avg = df_avg.rename(columns={\"level_0\" : 'NGFBFC'})\n",
    "df_avg_melt = pd.melt(\n",
    "    df_avg, \n",
    "    id_vars=[\"NGFBFC\"],  \n",
    "    var_name=\"time\",     \n",
    "    value_name=\"value\"  \n",
    ")\n",
    "df_avg = df_avg_melt.sort_values(by=['value', 'NGFBFC'], ascending=[False, False])\n",
    "\n",
    "results = {}\n",
    "for category in df_avg['NGFBFC'].unique():\n",
    "    for time in range(start_time_year+5, end_time_year, interval):\n",
    "        filtered_data = df_avg[(df_avg['NGFBFC'] == category) & (df_avg['time'] == time)]\n",
    "        sorted_data = filtered_data.sort_values(by='value', ascending=False)\n",
    "        top_5_data = sorted_data.head(3)\n",
    "        if time not in results:\n",
    "            results[time] = {}\n",
    "        results[time][category] = top_5_data\n",
    "\n",
    "df_avg = pd.concat([pd.concat(results[year].values()) for year in results.keys()])\n",
    "df_avg = df_avg.sort_values(by=['time', 'value'], ascending=[True, False])\n",
    "df_avg = ngfbfc_processing(df_avg)\n",
    "\n",
    "produk_diulang = np.array([item for item in df_avg[df_avg['time'] == 1980]['NGFBFC'].to_list() for _ in range(1)])\n",
    "\n",
    "df_footprint_region = region_processing(df1)\n",
    "df_footprint_region_table = pd.pivot_table(data=df_footprint_region, index=['NGFBFC', 'time'], columns=['IMAGE Region Name'])\n",
    "df_footprint_region_index = df_footprint_region_table.stack(level=0, future_stack=True)\n",
    "df_footprint_region_index = df_footprint_region_index.reset_index()\n",
    "df_footprint_region_index_drop = df_footprint_region_index.drop(columns=['level_2'])\n",
    "df_footprint_region_index_drop.index = df_footprint_region_index_drop.columns['NGFBFC'].values\n",
    "\n",
    "average1_melt = df_footprint_region_index_drop.melt(id_vars=['NGFBFC', 'time'], value_name='value') \n",
    "average1_melt = average1_melt[~((average1_melt['IMAGE Region Name'] == \"Canada\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['IMAGE Region Name'] == \"Central America\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"tropical cereals\") & (average1_melt['IMAGE Region Name'] == \"Japan\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"South Africa\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"Rest of Southern Africa\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"USA\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"non food, luxury, spices\") & (average1_melt['IMAGE Region Name'] == \"Russia region\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"soybeans\") & (average1_melt['IMAGE Region Name'] == \"Southeast Asia\"))]\n",
    "\n",
    "average1_melt.index = average1_melt.columns[:,'NGFBFC'].values\n",
    "average1_filtered = average1_melt[average1_melt['value'] < 20]\n",
    "average1_new = average1_filtered.sort_values(by=['value', 'NGFBFC'], ascending=[True, True])\n",
    "\n",
    "results = {}\n",
    "for country in average1_new['IMAGE Region Name'].unique():\n",
    "    for category in average1_new['NGFBFC'].unique():\n",
    "        for time in range(start_time_year+5, end_time_year, interval):\n",
    "            filtered_data = average1_new[(average1_new['NGFBFC'] == category) & (average1_new['time'] == time)]\n",
    "            sorted_data = filtered_data.sort_values(by='value', ascending=False)\n",
    "            top_5_data = sorted_data.head(3)\n",
    "            if time not in results:\n",
    "                results[time] = {}\n",
    "            results[time][category] = top_5_data\n",
    "\n",
    "df_footprint_df = pd.concat([pd.concat(results[year].values()) for year in results.keys()])\n",
    "df_footprint_df_filtered = df_footprint_df[df_footprint_df['value'] < 20]\n",
    "\n",
    "for time in range(start_time_year+5, end_time_year, interval):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_xlabel('Crop Footprint based on total area ($ton~CO_2/~hectare$)')\n",
    "    ax.set_ylabel('Crop Categories')\n",
    "\n",
    "    plt.title(f\"{time}\")\n",
    "    \n",
    "    produk_diulang = np.array([item for item in df_avg[df_avg['time'] == time]['NGFBFC'].to_list() for _ in range(1)])\n",
    "\n",
    "    sns.scatterplot(x=\"value\", y=\"NGFBFC\", color='#686D76', sizes=(100, 300), alpha=.3, data=average1_filtered[average1_filtered['time'] == time].loc[produk_diulang])\n",
    "    sns.scatterplot(x=\"value\", y=\"NGFBFC\", hue='IMAGE Region Name', sizes=(100, 300), alpha=.8, palette=palettes, data=df_footprint_df_filtered[df_footprint_df_filtered['time'] == time])\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "    ax.plot(df_avg[df_avg['time'] == time].sort_values(by='value', ascending=False)['value'].to_numpy(), df_avg[df_avg['time'] == time].sort_values(by='value', ascending=False)['NGFBFC'].to_numpy(), \"D\", color='red', label='Weighted Average')\n",
    "    \n",
    "    legend_handles, legend_labels = ax.get_legend_handles_labels()\n",
    "    weighted_average_index = legend_labels.index('Weighted Average')\n",
    "    weighted_average_handle = legend_handles.pop(weighted_average_index)\n",
    "    weighted_average_label = legend_labels.pop(weighted_average_index)\n",
    "    \n",
    "    legend_handles.append(weighted_average_handle)\n",
    "    legend_labels.append(weighted_average_label)\n",
    "\n",
    "    ax.legend(handles=legend_handles, labels=legend_labels, bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "    \n",
    "    plt.show()\n",
    "    plt.savefig(f'/VIZ/CF_multiyears_{time}.png')\n",
    "\n",
    "df1 = CF_emisi_total_AH.copy()\n",
    "df2 = df_GFRAC_Area_selected.copy()\n",
    "\n",
    "df1.loc[df1['CF'] > 50, 'CF'] = 0\n",
    "df1 = ngfbfc_processing(df1)\n",
    "df2 = ngfbfc_processing(df2)\n",
    "\n",
    "data1 = np.zeros((len(df1['NGFBFC'].unique()), len(df2['IMAGE Region Name'].unique())), dtype='float32')\n",
    "average_AreaHarvested_RegionCrops = np.zeros((len(df1['NGFBFC'].unique()), len(df2['IMAGE Region Name'].unique())), dtype='float32')\n",
    "result_average = np.zeros((len(df1['NGFBFC'].unique())), dtype='float32')\n",
    "\n",
    "for i, ngfbfc in enumerate(df1['NGFBFC'].unique()):\n",
    "    for n, image_region in enumerate(df2['IMAGE Region Name'].unique()):\n",
    "        ngfbfc_areaharves = df2[(df2['IMAGE Region Name'] == image_region) & (df2['NGFBFC'] == ngfbfc) & (df2['value'] > 0)]['value'].replace([np.inf, -np.inf], np.nan).mean()\n",
    "        average_AreaHarvested_RegionCrops[i][n] = np.nan_to_num(ngfbfc_areaharves)\n",
    "\n",
    "for i, ngfbfc in enumerate(df1['NGFBFC'].unique()):\n",
    "    carbon_footprint = df1[df1['NGFBFC'] == ngfbfc]['CF'].replace([np.inf, -np.inf], np.nan).mean()\n",
    "    data1[i] = np.nan_to_num(carbon_footprint)\n",
    "\n",
    "for x in range(len(df1['NGFBFC'].unique())):\n",
    "    result_average[x] = np.average(data1[x], weights=average_AreaHarvested_RegionCrops[x])\n",
    "\n",
    "df_avg = pd.DataFrame(result_average, index=df2['NGFBFC'].unique(), columns=['value'])\n",
    "df_avg = df_avg.reset_index()\n",
    "df_avg = df_avg.rename(columns={\"index\":'NGFBFC'})\n",
    "df_avg = df_avg.sort_values(by=['value'], ascending=[False])\n",
    "\n",
    "produk_diulang = np.array([item for item in df_avg['NGFBFC'].to_list() for _ in range(1)])\n",
    "\n",
    "df_footprint_region = region_processing(df1)\n",
    "df_footprint_region_table = pd.pivot_table(data=df_footprint_region, index=['NGFBFC', 'time'], columns=['IMAGE Region Name'])\n",
    "df_footprint_region_index = df_footprint_region_table.stack(level=0, future_stack=True)\n",
    "df_footprint_region_index = df_footprint_region_index.reset_index()\n",
    "df_footprint_region_index_drop = df_footprint_region_index.drop(columns=['level_2'])\n",
    "df_footprint_region_index_drop = df_footprint_region_index_drop.drop(columns=['time'])\n",
    "df_footprint_region_index_drop.index = df_footprint_region_index_drop.loc[:, 'NGFBFC'].values\n",
    "\n",
    "average1_melt = df_footprint_region_index_drop.melt(id_vars=['NGFBFC'], value_name='value') \n",
    "average1_melt = average1_melt[~((average1_melt['IMAGE Region Name'] == \"Canada\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['IMAGE Region Name'] == \"Central America\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"tropical cereals\") & (average1_melt['IMAGE Region Name'] == \"Japan\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"South Africa\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"Rest of Southern Africa\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"USA\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"non food, luxury, spices\") & (average1_melt['IMAGE Region Name'] == \"Russia region\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"soybeans\") & (average1_melt['IMAGE Region Name'] == \"Southeast Asia\"))]\n",
    "\n",
    "average = average1_melt.groupby(['IMAGE Region Name', 'NGFBFC'])['value'].mean().to_frame('Mean')\n",
    "average1 = average.reset_index()\n",
    "average1.index = average1.columns['NGFBFC'].values\n",
    "average1_filtered = average1[average1['Mean'] < 20]\n",
    "average1_new = average1_filtered.sort_values(by=['Mean', 'NGFBFC'], ascending=[True, True])\n",
    "\n",
    "results = {}\n",
    "for country in average1_new['IMAGE Region Name'].unique():\n",
    "    for category in average1_new['NGFBFC'].unique():\n",
    "        filtered_data = average1_new[average1_new['NGFBFC'] == category]\n",
    "        sorted_data = filtered_data.sort_values(by='Mean', ascending=False)\n",
    "        top_5_data = sorted_data.head(3)\n",
    "        results[category] = top_5_data\n",
    "\n",
    "df_footprint_df = pd.concat([pd.concat(results.values())])\n",
    "df_footprint_df_filtered = df_footprint_df[df_footprint_df['Mean'] < 20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_xlabel('Crop Footprint based on total area ($ton~CO_2/~hectare$)')\n",
    "ax.set_ylabel('Crop Categories')\n",
    "\n",
    "sns.scatterplot(x=\"Mean\", y=\"NGFBFC\", color='#686D76', sizes=(100, 300), alpha=.3, data=average1_filtered.loc[produk_diulang])\n",
    "sns.scatterplot(x=\"Mean\", y=\"NGFBFC\", hue='IMAGE Region Name', sizes=(100, 300), alpha=.8, palette=palettes, data=df_footprint_df_filtered)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "ax.plot(df_avg['value'].to_numpy(), df_avg['NGFBFC'].to_numpy(), \"D\", color='red', label='Weighted Average')\n",
    "\n",
    "legend_handles, legend_labels = ax.get_legend_handles_labels()\n",
    "weighted_average_index = legend_labels.index('Weighted Average')\n",
    "weighted_average_handle = legend_handles.pop(weighted_average_index)\n",
    "weighted_average_label = legend_labels.pop(weighted_average_index)\n",
    "\n",
    "legend_handles.append(weighted_average_handle)\n",
    "legend_labels.append(weighted_average_label)\n",
    "\n",
    "ax.legend(handles=legend_handles, labels=legend_labels, bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(f'/VIZ/CF_average_{start_time_year+5}-{end_time_year}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emisi_total_copy = all_sources.copy()\n",
    "emisi_total_copy = ngfbfc_processing(emisi_total_copy)\n",
    "emisi_total_copy = emisi_total_copy[emisi_total_copy['NGFBFC'] != \"pasture\"]\n",
    "emisi_total_copy = emisi_total_copy.groupby(['IMAGE Region Name', 'NGFBFC']).sum()\n",
    "emisi_total_copy = emisi_total_copy.reset_index()\n",
    "emisi_total_copy = emisi_total_copy.drop(columns=['emissions'])\n",
    "\n",
    "emisi_total_melted = pd.melt(emisi_total_copy, id_vars=['IMAGE Region Name', 'NGFBFC'], var_name='time', value_name='value')\n",
    "emisi_total_melted = emisi_total_melted.groupby(['IMAGE Region Name', 'time', 'NGFBFC']).sum()\n",
    "emisi_total_melted = emisi_total_melted.reset_index()\n",
    "emisi_total_melted['value'] = emisi_total_melted['value'] * 1E9\n",
    "\n",
    "fao_prod_copy = faostat_prod_2a.copy()\n",
    "fao_prod_copy = ngfbfc_processing(fao_prod_copy)\n",
    "fao_prod_copy = fao_prod_copy[fao_prod_copy['time'] >= start_time_year+5]\n",
    "\n",
    "df_intensity_region = fao_prod_copy.copy()\n",
    "for region, time, ngfbfc in zip(df_intensity_region[\"IMAGE Region Name\"].to_list(), df_intensity_region[\"time\"].to_list(), df_intensity_region[\"NGFBFC\"].to_list()):\n",
    "    try:\n",
    "        data1 = fao_prod_copy[(fao_prod_copy['IMAGE Region Name'] == region) & (fao_prod_copy['time'] == time) & (fao_prod_copy['NGFBFC'] == ngfbfc)]['FAO Production'].to_numpy()\n",
    "        data2 = emisi_total_melted[(emisi_total_melted['IMAGE Region Name'] == region) & (emisi_total_melted['time'] == time) & (emisi_total_melted['NGFBFC'] == ngfbfc)]['value'].to_numpy()\n",
    "        if data1.size == 0:\n",
    "            data1 = [0]\n",
    "        if data2.size == 0: \n",
    "            data2 = [0]\n",
    "        mask = df_intensity_region[(df_intensity_region['IMAGE Region Name'] == region) & (df_intensity_region['time'] == time) & (df_intensity_region['NGFBFC'] == ngfbfc)].index\n",
    "        df_intensity_region.loc[mask, 'Carbon Intensity'] =  data2[0] / data1[0]\n",
    "    \n",
    "    except (KeyError, ZeroDivisionError) as e:\n",
    "        print(f\"Error: {e} for region {region}\")\n",
    "\n",
    "df_intensity_region = df_intensity_region.drop(columns=['FAO Production'])\n",
    "df_intensity_region['Carbon Intensity'] = df_intensity_region['Carbon Intensity'].replace([np.inf, -np.inf], np.nan)\n",
    "df_intensity_region['Carbon Intensity'] = df_intensity_region['Carbon Intensity'].fillna(0)\n",
    "\n",
    "df1_copy = df_intensity_region.copy()\n",
    "df2_copy = faostat_prod_2a.copy()\n",
    "\n",
    "df1_copy.loc[df1_copy['Carbon Intensity'] > 50, 'Carbon Intensity'] = 0\n",
    "df1_copy = ngfbfc_processing(df1_copy)\n",
    "df2_copy = ngfbfc_processing(df2_copy)\n",
    "\n",
    "df_ittertols = df_footprint_region.drop(columns=['CF'])\n",
    "df_itertools_copy1 = df_ittertols.copy()\n",
    "df_itertools_copy1[\"Carbon Intensity\"] = 0.0\n",
    "df1_copy = df_itertools_copy1.merge(df1_copy , how='left', left_on=['IMAGE Region Name', 'time', 'NGFBFC'], right_on=['IMAGE Region Name', 'time', 'NGFBFC'])\n",
    "df1_copy = df1_copy.drop(columns=['Carbon Intensity_x']).rename(columns={\"Carbon Intensity_y\": \"Carbon Intensity\"})\n",
    "\n",
    "df_itertools_copy2 = df_ittertols.copy()\n",
    "df_itertools_copy2[\"FAO Production\"] = 0.0\n",
    "df2_copy = df_itertools_copy2.merge(df2_copy , how='left', left_on=['IMAGE Region Name', 'time', 'NGFBFC'], right_on=['IMAGE Region Name', 'time', 'NGFBFC'])\n",
    "df2_copy = df2_copy.drop(columns=['FAO Production_x']).rename(columns={\"FAO Production_y\": \"FAO Production\"})\n",
    "\n",
    "data1 = np.zeros((len(df1_copy['time'].unique()), len(df1_copy['NGFBFC'].unique()), len(df1_copy['IMAGE Region Name'].unique())), dtype='float32')\n",
    "average_AreaHarvested_RegionCrops = np.zeros((len(df1_copy['time'].unique()), len(df1_copy['NGFBFC'].unique()), len(df1_copy['IMAGE Region Name'].unique())), dtype='float32')\n",
    "result_average = np.zeros((len(df1_copy['NGFBFC'].unique()), len(df1_copy['time'].unique())), dtype='float32')\n",
    "for n, time in enumerate(range(start_time_year+5, end_time_year, interval)):\n",
    "    for i, ngfbfc in enumerate(df1_copy['NGFBFC'].unique()):\n",
    "        for j, image_region in enumerate(df2_copy['IMAGE Region Name'].unique()):\n",
    "            ngfbfc_areaharves = df2_copy[(df2_copy['time'] == time) & (df2_copy['IMAGE Region Name'] == image_region) & (df2_copy['NGFBFC'] == ngfbfc)]['FAO Production'].replace([np.inf, -np.inf], np.nan).values\n",
    "            average_AreaHarvested_RegionCrops[n][i][j] = np.nan_to_num(ngfbfc_areaharves)\n",
    "\n",
    "for n, time in enumerate(range(start_time_year+5, end_time_year, interval)):\n",
    "    for i, ngfbfc in enumerate(df1_copy['NGFBFC'].unique()):\n",
    "        carbon_footprint = df1_copy[(df1_copy['time'] == time) & (df1_copy['NGFBFC'] == ngfbfc)]['Carbon Intensity'].replace([np.inf, -np.inf], np.nan).values\n",
    "        data1[n][i] = np.nan_to_num(carbon_footprint)\n",
    "\n",
    "for i, ngfbfc in enumerate(df1_copy['NGFBFC'].unique()):   \n",
    "    for n, time in enumerate(range(start_time_year+5, end_time_year, interval)):\n",
    "        result_average[i][n] = np.average(data1[n][i], weights=average_AreaHarvested_RegionCrops[n][i])\n",
    "\n",
    "df_avg = pd.DataFrame(result_average, index=[df2_copy['NGFBFC'].unique()], columns=list(range(start_time_year+5, end_time_year, interval)))\n",
    "df_avg = df_avg.reset_index()\n",
    "df_avg = df_avg.rename(columns={\"level_0\":'NGFBFC'})\n",
    "df_avg_melt = pd.melt(\n",
    "    df_avg, \n",
    "    id_vars=[\"NGFBFC\"], \n",
    "    var_name=\"time\",     \n",
    "    value_name=\"value\"   \n",
    ")\n",
    "df_avg = df_avg_melt.sort_values(by=['value', 'NGFBFC'], ascending=[False, False])\n",
    "\n",
    "results = {}\n",
    "for category in df_avg['NGFBFC'].unique():\n",
    "    for time in range(start_time_year+5, end_time_year, interval):\n",
    "        filtered_data = df_avg[(df_avg['NGFBFC'] == category) & (df_avg['time'] == time)]\n",
    "        sorted_data = filtered_data.sort_values(by='value', ascending=False)\n",
    "        top_5_data = sorted_data.head(3)\n",
    "        if time not in results:\n",
    "            results[time] = {}\n",
    "        results[time][category] = top_5_data\n",
    "\n",
    "df_avg = pd.concat([pd.concat(results[year].values()) for year in results.keys()])\n",
    "df_avg = df_avg.sort_values(by=['time', 'value'], ascending=[True, False])\n",
    "\n",
    "df_footprint_region = region_processing(df1_copy)\n",
    "df_footprint_region_table = pd.pivot_table(data=df_footprint_region, index=['NGFBFC', 'time'], columns=['IMAGE Region Name'])\n",
    "df_footprint_region_index = df_footprint_region_table.stack(level=0, future_stack=True)\n",
    "df_footprint_region_index = df_footprint_region_index.reset_index()\n",
    "df_footprint_region_index_drop = df_footprint_region_index.drop(columns=['level_2'])\n",
    "df_footprint_region_index_drop.index = df_footprint_region_index_drop.columns['NGFBFC'].values\n",
    "  \n",
    "average1_melt = df_footprint_region_index_drop.melt(id_vars=['NGFBFC', 'time'], value_name='value') \n",
    "average1_melt = average1_melt[~((average1_melt['IMAGE Region Name'] == \"Canada\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['IMAGE Region Name'] == \"Central America\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"tropical cereals\") & (average1_melt['IMAGE Region Name'] == \"Japan\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"South Africa\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"Rest of Southern Africa\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"palm oil\") & (average1_melt['IMAGE Region Name'] == \"USA\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"non food, luxury, spices\") & (average1_melt['IMAGE Region Name'] == \"Russia region\"))]\n",
    "average1_melt = average1_melt[~((average1_melt['NGFBFC'] == \"soybeans\") & (average1_melt['IMAGE Region Name'] == \"Southeast Asia\"))]\n",
    "\n",
    "average1_melt.index = average1_melt.columns['NGFBFC'].values\n",
    "average1_melt = average1_melt[average1_melt['value'] < 20]\n",
    "average1_melt = average1_melt.sort_values(by=['value', 'NGFBFC'], ascending=[True, True])\n",
    "\n",
    "results = {}\n",
    "for country in average1_melt['IMAGE Region Name'].unique():\n",
    "    for category in average1_melt['NGFBFC'].unique():\n",
    "        for time in range(start_time_year+5, end_time_year, interval):\n",
    "            filtered_data = average1_melt[(average1_melt['NGFBFC'] == category) & (average1_melt['time'] == time)]\n",
    "            sorted_data = filtered_data.sort_values(by='value', ascending=False)\n",
    "            top_5_data = sorted_data.head(3)\n",
    "            if time not in results:\n",
    "                results[time] = {}\n",
    "            results[time][category] = top_5_data\n",
    "\n",
    "df_footprint_df = pd.concat([pd.concat(results[year].values()) for year in results.keys()])\n",
    "df_footprint_df_filtered = df_footprint_df[df_footprint_df['value'] < 20]\n",
    "\n",
    "for time in range(start_time_year+5, end_time_year, interval):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_xlabel('Crop Footprint based on total area ($ton~CO_2/~hectare$)')\n",
    "    ax.set_ylabel('Crop Categories')\n",
    "\n",
    "    plt.title(f\"{time}\")\n",
    "    \n",
    "    produk_diulang = np.array([item for item in df_avg[df_avg['time'] == time]['NGFBFC'].to_list() for _ in range(1)])\n",
    "\n",
    "    sns.scatterplot(x=\"value\", y=\"NGFBFC\", color='#686D76', sizes=(100, 300), alpha=.3, data=average1_filtered[average1_filtered['time'] == time].loc[produk_diulang])\n",
    "    sns.scatterplot(x=\"value\", y=\"NGFBFC\", hue='IMAGE Region Name', sizes=(100, 300), alpha=.8, palette=palettes, data=df_footprint_df_filtered[df_footprint_df_filtered['time'] == time])\n",
    "\n",
    "    ax.legend(bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "    ax.plot(df_avg[df_avg['time'] == time].sort_values(by='value', ascending=False)['value'].to_numpy(), df_avg[df_avg['time'] == time].sort_values(by='value', ascending=False)['NGFBFC'].to_numpy(), \"D\", color='red', label='Weighted Average')\n",
    "    \n",
    "    legend_handles, legend_labels = ax.get_legend_handles_labels()\n",
    "    weighted_average_index = legend_labels.index('Weighted Average')\n",
    "    weighted_average_handle = legend_handles.pop(weighted_average_index)\n",
    "    weighted_average_label = legend_labels.pop(weighted_average_index)\n",
    "    \n",
    "    legend_handles.append(weighted_average_handle)\n",
    "    legend_labels.append(weighted_average_label)\n",
    "\n",
    "    ax.legend(handles=legend_handles, labels=legend_labels, bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(5))\n",
    "\n",
    "    plt.show()\n",
    "    plt.savefig(f'/VIZ/CI_multiyears_{time}.png')\n",
    "\n",
    "df1_copy = df_intensity_region.copy()\n",
    "df2_copy = faostat_prod_2a.copy()\n",
    "\n",
    "df1_copy.loc[df1_copy['Carbon Intensity'] > 50, 'Carbon Intensity'] = 0\n",
    "df1_copy= ngfbfc_processing(df1_copy)\n",
    "df2_copy = ngfbfc_processing(df2_copy)\n",
    "\n",
    "df2_copy = df2_copy[~((df2_copy['time'] <= 1990) & (df2_copy['IMAGE Region Name'] == \"Russia\"))]\n",
    "df2_copy = df2_copy[df2_copy['time'] >= start_time_year+5]\n",
    "\n",
    "data1 = np.zeros((len(df1_copy['NGFBFC'].unique()), len(df2_copy['IMAGE Region Name'].unique())), dtype='float32')\n",
    "average_AreaHarvested_RegionCrops = np.zeros((len(df1_copy['NGFBFC'].unique()), len(df2_copy['IMAGE Region Name'].unique())), dtype='float32')\n",
    "result_average = np.zeros((len(df1_copy['NGFBFC'].unique())), dtype='float32')\n",
    "for i, ngfbfc in enumerate(df1_copy['NGFBFC'].unique()):\n",
    "    for n, image_region in enumerate(df2_copy['IMAGE Region Name'].unique()):\n",
    "        ngfbfc_areaharves = df2_copy[(df2_copy['IMAGE Region Name'] == image_region) & (df2_copy['NGFBFC'] == ngfbfc) & (df2_copy['FAO Production'] > 0)]['FAO Production'].replace([np.inf, -np.inf], np.nan).mean()\n",
    "        average_AreaHarvested_RegionCrops[i][n] = np.nan_to_num(ngfbfc_areaharves)\n",
    "\n",
    "for i, ngfbfc in enumerate(df1_copy['NGFBFC'].unique()):\n",
    "    carbon_footprint = df1_copy[df1_copy['NGFBFC'] == ngfbfc]['Carbon Intensity'].replace([np.inf, -np.inf], np.nan).mean()\n",
    "    data1[i] = np.nan_to_num(carbon_footprint)\n",
    "\n",
    "for i, ngfbfc in enumerate(df1_copy['NGFBFC'].unique()):   \n",
    "    result_average[i] = np.average(data1[i], weights=average_AreaHarvested_RegionCrops[i])\n",
    "    \n",
    "df_avg = pd.DataFrame(result_average, index=df2_copy['NGFBFC'].unique())\n",
    "df_avg = df_avg.reset_index()\n",
    "df_avg = df_avg.rename(columns={\"index\":'NGFBFC', 0:\"value\"})\n",
    "df_avg = df_avg.sort_values(by=['value'], ascending=[False])\n",
    "\n",
    "df_footprint_region = region_processing(df1_copy)\n",
    "df_footprint_region = df_footprint_region[~((df_footprint_region['time'] <= 1990) & (df_footprint_region['IMAGE Region Name'] == \"Russia\"))] \n",
    "\n",
    "df_footprint_region_table = pd.pivot_table(data=df_footprint_region, index=['NGFBFC', 'time'], columns=['IMAGE Region Name'])\n",
    "df_footprint_region_index = df_footprint_region_table.stack(level=0, future_stack=True)\n",
    "df_footprint_region_index = df_footprint_region_index.reset_index()\n",
    "df_footprint_region_index = df_footprint_region_index.drop(columns=['level_2'])\n",
    "df_footprint_region_index.index = df_footprint_region_index['NGFBFC'].values\n",
    "\n",
    "produk_diulang = np.array([item for item in df_avg['NGFBFC'].to_list() for _ in range(1)])\n",
    "df_footprint_region_index = df_footprint_region_index.loc[produk_diulang]\n",
    "df_footprint_region_index = df_footprint_region_index.drop(columns=['time'])\n",
    "\n",
    "average_melt = df_footprint_region_index.melt(id_vars=['NGFBFC'], value_name='value') \n",
    "average_melt['value'] = average_melt['value'].fillna(0)\n",
    "\n",
    "average_melt = average_melt.groupby(['IMAGE Region Name', 'NGFBFC'])['value'].apply(custom_mean).to_frame('Mean').reset_index()\n",
    "average_melt.index = average_melt['NGFBFC'].values\n",
    "average_melt = average_melt[average_melt['Mean'] < 25]\n",
    "\n",
    "average1_new = average.sort_values(by=['Mean', 'NGFBFC'], ascending=[True, True])\n",
    "average1_new = average1_new[~((average1_new['IMAGE Region Name'] == \"Canada\"))]\n",
    "average1_new = average1_new[~((average1_new['IMAGE Region Name'] == \"Central America\"))]\n",
    "average1_new = average1_new[~((average1_new['IMAGE Region Name'] == \"Japan\"))]\n",
    "average1_new = average1_new[~((average1_new['IMAGE Region Name'] == \"Central Europe\"))]\n",
    "average1_new = average1_new[~((average1_new['NGFBFC'] == \"palm oil\") & (average1_new['IMAGE Region Name'] == \"South Africa\"))]\n",
    "average1_new = average1_new[~((average1_new['NGFBFC'] == \"palm oil\") & (average1_new['IMAGE Region Name'] == \"Rest of Southern Africa\"))]\n",
    "average1_new = average1_new[~((average1_new['NGFBFC'] == \"palm oil\") & (average1_new['IMAGE Region Name'] == \"USA\"))]\n",
    "average1_new = average1_new[~((average1_new['NGFBFC'] == \"non food, luxury, spices\") & (average1_new['IMAGE Region Name'] == \"Russia region\"))]\n",
    "average1_new = average1_new[~((average1_new['NGFBFC'] == \"soybeans\") & (average1_new['IMAGE Region Name'] == \"Southeast Asia\"))]\n",
    "average1_new = average1_new[~((average1_new['NGFBFC'] == \"soybeans\") & (average1_new['IMAGE Region Name'] == \"Indonesia region\"))]\n",
    "average1_new = average1_new[~((average1_new['NGFBFC'] == \"plant based fibres\") & (average1_new['IMAGE Region Name'] == \"Ukraine region\"))]\n",
    "\n",
    "results = {}\n",
    "for country in average1_new['IMAGE Region Name'].unique():\n",
    "    for category in average1_new['NGFBFC'].unique():\n",
    "        filtered_data = average1_new[average1_new['NGFBFC'] == category]\n",
    "        sorted_data = filtered_data.sort_values(by='Mean', ascending=False)\n",
    "        top_5_data = sorted_data.head(3)\n",
    "        results[category] = top_5_data\n",
    "\n",
    "df_footprint_df = pd.concat([pd.concat(results.values())])\n",
    "df_footprint_df = df_footprint_df[df_footprint_df['Mean'] < 25]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_xlabel('Crop Emission Intensity ($ton~CO_2-eq/~tonne~crop$)')\n",
    "ax.set_ylabel('Crop Categories')\n",
    "\n",
    "sns.scatterplot(x=\"Mean\", y=\"NGFBFC\", color='#686D76', sizes=(100, 300), alpha=.3, data=average1_new.loc[produk_diulang])\n",
    "sns.scatterplot(x=\"Mean\", y=\"NGFBFC\", hue='IMAGE Region Name', sizes=(100, 300), alpha=.8, palette=palettes, data=df_footprint_df)\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "ax.plot(df_avg['value'].to_numpy(), df_avg['NGFBFC'].to_numpy(), \"D\", color='red', label='Weighted Average')\n",
    "\n",
    "legend_handles, legend_labels = ax.get_legend_handles_labels()\n",
    "weighted_average_index = legend_labels.index('Weighted Average')\n",
    "weighted_average_handle = legend_handles.pop(weighted_average_index)\n",
    "weighted_average_label = legend_labels.pop(weighted_average_index)\n",
    "\n",
    "legend_handles.append(weighted_average_handle)\n",
    "legend_labels.append(weighted_average_label)\n",
    "\n",
    "ax.legend(handles=legend_handles, labels=legend_labels, bbox_to_anchor=(1.01, 1), ncol=1, loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(f'/VIZ/CI_average_{start_time_year+5}-{end_time_year}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_to_multiply = [int(year) for year in range(start_time_year, end_time_year+1, 5)]\n",
    "\n",
    "df_LUC = all_sources[(all_sources['emissions'] == 'LUC_Agri') | (all_sources['emissions'] == 'agri2agri') | (all_sources['emissions'] == 'GEN2OLC')]\n",
    "df_LUC = df_LUC.groupby(['IMAGE Region Name', 'type']).sum()\n",
    "df_LUC = df_LUC.reset_index()\n",
    "df_LUC = df_LUC.drop(columns=['emissions'])\n",
    "df_LUC.loc[:, columns_to_multiply] = df_LUC.loc[:, columns_to_multiply] * 5\n",
    "df_LUC_melt = df_LUC.melt(id_vars=['IMAGE Region Name', 'type'], var_name='time', value_name='value')\n",
    "df_LUC_melt_droptime = df_LUC_melt.drop(columns=['time'])\n",
    "df_LUC_melt_droptime = df_LUC_melt_droptime.groupby(['IMAGE Region Name', 'type']).sum()\n",
    "df_LUC_index = df_LUC_melt_droptime.reset_index()\n",
    "df_LUC_index.loc[:, 'emissions'] = \"LUC\"\n",
    "\n",
    "df_AGRI = all_sources[~(all_sources['emissions'] == 'LUC_Agri') | ~(all_sources['emissions'] == 'agri2agri') | ~(all_sources['emissions'] == 'GEN2OLC')]\n",
    "df_AGRI = df_AGRI.groupby(['IMAGE Region Name', 'type']).sum()\n",
    "df_AGRI = df_AGRI.reset_index()\n",
    "df_AGRI = df_AGRI.drop(columns=['emissions'])\n",
    "df_AGRI.loc[:, columns_to_multiply] = df_AGRI.loc[:, columns_to_multiply] * 5\n",
    "df_AGRI_melt = df_AGRI.melt(id_vars=['IMAGE Region Name', 'type'], var_name='time', value_name='value')\n",
    "df_agrim_melt_droptime = df_AGRI_melt.drop(columns=['time'])\n",
    "df_agrim_melt_droptime = df_agrim_melt_droptime.groupby(['IMAGE Region Name', 'type']).sum()\n",
    "df_agrim_index = df_agrim_melt_droptime.reset_index()\n",
    "df_agrim_index.loc[:, 'emissions'] = \"AGRI\"\n",
    "\n",
    "data_2kategori = pd.concat([df_agrim_index, df_LUC_index], ignore_index=True)\n",
    "data_2kategori_drop = data_2kategori.drop(columns=['emissions'])\n",
    "data_2kategori_sum = data_2kategori_drop.groupby(['IMAGE Region Name', 'type']).sum()\n",
    "data_2kategori_sum_index = data_2kategori_sum.reset_index()\n",
    "data_2kategori_sum_index['type'] = data_2kategori_sum_index['type'].replace('grass', 'pasture').replace('oil & palm fruit', 'palm oil')\n",
    "data_2kategori_sum_index['type'] = data_2kategori_sum_index['type'].replace('other temperate cereals', 'temperate cereals')\n",
    "data_2kategori_sum_index['IMAGE Map'] = data_2kategori_sum_index['IMAGE Region Name']\n",
    "data_2kategori_sum_index = region_processing(data_2kategori_sum_index)\n",
    "data_2kategori_sum_index['IMAGE Classification Region'] = data_2kategori_sum_index['IMAGE Region Name'] + \"-\" + data_2kategori_sum_index['type']\n",
    "data_2kategori_sum_index = data_2kategori_sum_index[data_2kategori_sum_index['IMAGE Classification Region'] != 'indonesia region-temperate cereals'] #drop karena tidak ada produksi di FAO\n",
    "\n",
    "df_top3 = get_top_n(data_2kategori_sum_index, 'type', 'value', 2)\n",
    "\n",
    "region_code_map = country_code.set_index('IMAGE Region Name')['IMAGE Region Code'].to_dict()\n",
    "df_top3['IMAGE Map'] = df_top3['IMAGE Map'].map(region_code_map)\n",
    "df_top3 = df_top3[df_top3['type'] != 'pasture']\n",
    "df_top3 = df_top3.drop(columns=['IMAGE Region Name'])\n",
    "\n",
    "columns2 = ['plant based fibres', 'other non-food & luxury & spices', 'vegetables & fruits', 'palm oil',\n",
    "            'sugar crops', 'tropical roots & tubers', 'temperate roots & tubers', 'tropical oil crops',\n",
    "            'temperate oil crops', 'soybeans', 'pulses', 'temperate cereals', 'tropical cereals', 'maize', 'rice',\n",
    "            'wheat', 'pasture']\n",
    "\n",
    "colors2 = ['#4D869C', '#7AB2B2', '#CDE8E5', '#FC4100', '#FFC55A', '#8E3E63', '#D2649A', '#03AED2', \n",
    "'#68D2E8', '#5F6F52', '#A9B388', '#FC819E', '#F7418F', '#FFF455', '#FFEFEF', '#F7C566', '#ACE1AF']\n",
    "\n",
    "color_mapping = dict(zip(columns2, colors2))\n",
    "def get_color(plant_type):\n",
    "    return color_mapping.get(plant_type, 'unknown')\n",
    "\n",
    "df_top3['color'] = df_top3['type'].apply(get_color)\n",
    "df_pallete = df_top3.copy()\n",
    "\n",
    "yield_raw = faostat_prod_2a.copy()\n",
    "for region, time, ngfbfc in zip(yield_raw[\"IMAGE Region Name\"].to_list(), yield_raw[\"time\"].to_list(), yield_raw[\"NGFBFC\"].to_list()):\n",
    "    try:\n",
    "        data1 = faostat_area_harvested[(faostat_area_harvested['IMAGE Region Name'] == region) & (faostat_area_harvested['time'] == time) & (faostat_area_harvested['NGFBFC'] == ngfbfc)]['Fao Area Harvested'].to_numpy()\n",
    "        data2 = faostat_prod_2a[(faostat_prod_2a['IMAGE Region Name'] == region) & (faostat_prod_2a['time'] == time) & (faostat_prod_2a['NGFBFC'] == ngfbfc)]['FAO Production'].to_numpy()\n",
    "        if data1.size == 0:\n",
    "            data1 = [0]\n",
    "        if data2.size == 0: \n",
    "            data2 = [0]\n",
    "        mask = yield_raw[(yield_raw['IMAGE Region Name'] == region) & (yield_raw['time'] == time) & (yield_raw['NGFBFC'] == ngfbfc)].index\n",
    "        yield_raw.loc[mask, 'value'] =  data2[0] / data1[0]\n",
    "\n",
    "    except (KeyError, ZeroDivisionError) as e:\n",
    "        print(f\"Error: {e} for region {region}\")\n",
    "\n",
    "yield_raw_1 = yield_raw.copy()\n",
    "yield_raw_1 = yield_raw_1.drop(columns=['FAO Production'])\n",
    "yield_raw_1 = yield_raw_1[yield_raw_1['time'] > start_time_year]\n",
    "\n",
    "yield_raw_1['NGFBFC'] = yield_raw_1['NGFBFC'].str.lower()\n",
    "yield_raw_1['NGFBFC'] = yield_raw_1['NGFBFC'].str.replace(\"tropical roots and tubers\", \"tropical roots & tubers\")\n",
    "yield_raw_1['NGFBFC'] = yield_raw_1['NGFBFC'].str.replace(\"vegetables or fruits\", \"vegetables & fruits\")\n",
    "yield_raw_1['NGFBFC'] = yield_raw_1['NGFBFC'].str.replace(\"other temperate cereals\", \"temperate cereals\")\n",
    "yield_raw_1['NGFBFC'] = yield_raw_1['NGFBFC'].str.replace(\"temperate roots and tubers\", \"temperate roots & tubers\")\n",
    "yield_raw_1['NGFBFC'] = yield_raw_1['NGFBFC'].str.replace(\"plant-based fibers\", \"plant based fibres\")\n",
    "yield_raw_1['NGFBFC'] = yield_raw_1['NGFBFC'].str.replace(\"oil & palm fruit\", \"palm oil\")\n",
    "\n",
    "yield_raw_1 = region_processing(yield_raw_1)\n",
    "\n",
    "yield_raw_copy = yield_raw_1.copy()\n",
    "yield_raw_copy['IMAGE Classification Region'] = yield_raw_copy['IMAGE Region Name'] + \"-\" + yield_raw_copy['NGFBFC']\n",
    "yield_raw_copy.rename(columns={'time': 'Year'}, inplace=True)\n",
    "yield_raw_copy = yield_raw_copy.drop(columns=['IMAGE Region Name', 'NGFBFC'])\n",
    "yield_raw_copy['value'] = yield_raw_copy['value'].fillna(0.0)\n",
    "yield_FAO = yield_raw_copy[['Year', 'IMAGE Classification Region', 'value']]\n",
    "yield_FAO  = yield_FAO[yield_FAO['IMAGE Classification Region'].isin(df_pallete['IMAGE Classification Region'])]\n",
    "\n",
    "yield_FAO_average = yield_FAO.groupby(['IMAGE Classification Region'])['value'].apply(custom_mean).to_frame('value')\n",
    "yield_FAO_average = yield_FAO_average.reset_index()\n",
    "yield_FAO_average = yield_FAO_average[['IMAGE Classification Region', 'value']]\n",
    "df2_array_selected = yield_FAO_average['value'].to_numpy()\n",
    "\n",
    "carbon_footprint.rename(columns={'NGFBFC': 'type'}, inplace=True)\n",
    "carbon_footprint['type'] = carbon_footprint['type'].str.replace(\"non food, luxury, spices\", \"other non-food & luxury & spices\").replace(\"oil, palm fruit\", \"palm oil\")\n",
    "carbon_footprint = carbon_footprint[~carbon_footprint['type'].str.contains(\"pasture\")]\n",
    "carbon_footprint['IMAGE Region Name'] = carbon_footprint['IMAGE Region Name'].str.lower()\n",
    "carbon_footprint['IMAGE Classification Region'] = carbon_footprint['IMAGE Region Name'] + \"-\" + carbon_footprint['type']\n",
    "carbon_footprint_group = carbon_footprint.groupby([\"IMAGE Classification Region\"]).sum()\n",
    "carbon_footprint_group = carbon_footprint_group.reset_index()\n",
    "carbon_footprint_group.rename(columns={'Mean': 'average'}, inplace=True)\n",
    "\n",
    "carbon_footprint_group['average'] = carbon_footprint_group['average'].fillna(0)\n",
    "carbon_footprint_group = carbon_footprint_group[['IMAGE Classification Region', 'average']]\n",
    "carbon_footprint_array = carbon_footprint_group['average'].to_numpy()\n",
    "carbon_footprint_group_sorted = carbon_footprint_group.sort_values(by='average', ascending=False)\n",
    "carbon_footprint_  = carbon_footprint_group[carbon_footprint_group['IMAGE Classification Region'].isin(df_pallete['IMAGE Classification Region'])]\n",
    "carbon_footprint_array_selected = carbon_footprint_['average'].to_numpy()\n",
    "carbon_footprint_ = pd.merge(left=carbon_footprint_, right=df_pallete, left_on=\"IMAGE Classification Region\", right_on=\"IMAGE Classification Region\", how=\"left\")\n",
    "\n",
    "crops = [x for x in carbon_footprint_group['IMAGE Classification Region'].unique()]\n",
    "\n",
    "combinations = list(itertools.product(columns_to_multiply, crops))\n",
    "df_new = pd.DataFrame(combinations, columns=['Year', 'IMAGE Classification Region'])\n",
    "df_new[\"value\"] = 0.0\n",
    "df_new_copy2 = df_new.copy()\n",
    "df_new_copy2 = df_new_copy2.merge(yield_FAO, how='left', left_on=['Year', 'IMAGE Classification Region'], right_on=['Year', 'IMAGE Classification Region'])\n",
    "df_new_copy2['value'] = df_new_copy2['value_y'].fillna(0.0)\n",
    "df_new_copy2 = df_new_copy2.drop(columns=['value_y', 'value_x'])\n",
    "df_new_copy2 = pd.pivot_table(data=df_new_copy2, columns=\"Year\", index=[\"IMAGE Classification Region\"], values=\"value\").reset_index()\n",
    "df_new_copy2['average'] = df_new_copy2.iloc[:, 1:].mean(axis=1)\n",
    "df_new_copy2['average'] = df_new_copy2['average'].fillna(0)\n",
    "df_new_copy2 = df_new_copy2[['IMAGE Classification Region', 'average']]\n",
    "df_2_sort = df_new_copy2.sort_values(by='average', ascending=False)\n",
    "df2_array = df_new_copy2['average'].to_numpy()\n",
    "df2_isin = df_new_copy2[df_new_copy2['IMAGE Classification Region'].isin(df_pallete['IMAGE Classification Region'])]\n",
    "df2_array_selected = df2_isin['average'].to_numpy()\n",
    "\n",
    "df2_colour = pd.merge(left=df2_isin, right=df_pallete, left_on=\"IMAGE Classification Region\", right_on=\"IMAGE Classification Region\", how=\"right\")\n",
    "df2_colour = df2_colour.sort_values(by='IMAGE Classification Region', ascending=True)\n",
    "\n",
    "production_raw = faostat_prod_2a.copy()\n",
    "production_raw = region_processing(production_raw)\n",
    "production_raw['NGFBFC'] = production_raw['NGFBFC'].str.lower()\n",
    "production_raw['NGFBFC'] = production_raw['NGFBFC'].str.replace('oil & palm fruit', 'palm oil')\n",
    "production_raw['NGFBFC'] = production_raw['NGFBFC'].str.replace('other non-food & luxury & spices', 'other non-food & luxury & spices')\n",
    "production_raw['NGFBFC'] = production_raw['NGFBFC'].str.replace('other temperate cereals', 'temperate cereals')\n",
    "production_raw['IMAGE Classification Region'] = production_raw['IMAGE Region Name'] + \"-\" + production_raw['NGFBFC']\n",
    "production_raw = production_raw.drop(columns=['IMAGE Region Name', 'NGFBFC'])\n",
    "\n",
    "production_copy = production_raw.copy()\n",
    "production_copy = production_copy.groupby(['IMAGE Classification Region'])['FAO Production'].apply(custom_mean).to_frame('average')\n",
    "production_copy = production_copy.reset_index()\n",
    "\n",
    "df_norm = production_copy.copy()\n",
    "df_norm = df_norm[['IMAGE Classification Region', 'average']]\n",
    "df_norm_selected = df_norm[df_norm['IMAGE Classification Region'].isin(df_pallete['IMAGE Classification Region'])]\n",
    "df_norm_selected_test = df_norm_selected['average'].to_numpy()/1e7\n",
    "\n",
    "df_agrim_melt_multiyear = df_AGRI_melt[((df_AGRI_melt['time'] > 1990))]\n",
    "df_agrim_melt_multiyear = df_agrim_melt_multiyear.drop(columns=['time'])\n",
    "df_agrim_groupby_multiyear = df_agrim_melt_multiyear.groupby(['IMAGE Region Name', 'type']).sum()\n",
    "df_agrim_index_multiyear = df_agrim_groupby_multiyear.reset_index()\n",
    "df_agrim_index_multiyear.loc[:, 'emissions'] = \"AGRI\"\n",
    "\n",
    "df_LUC_melt_multiyear = df_LUC_melt[((df_LUC_melt['time'] > 1990))]\n",
    "df_LUC_melt_multiyear = df_LUC_melt_multiyear.drop(columns=['time'])\n",
    "df_LUC_groupby_multiyear = df_LUC_melt_multiyear.groupby(['IMAGE Region Name', 'type']).sum()\n",
    "df_LUC_index_multiyear = df_LUC_groupby_multiyear.reset_index()\n",
    "df_LUC_index_multiyear.loc[:, 'emissions'] = \"LUC\"\n",
    "\n",
    "data_2kategori = pd.concat([df_agrim_index_multiyear, df_LUC_index_multiyear], ignore_index=True)\n",
    "\n",
    "five_top_data_multiyear = data_2kategori[\n",
    "    (data_2kategori['IMAGE Region Name'] == \"Brazil\") & (data_2kategori['type'] == \"soybeans\") \n",
    "  | (data_2kategori['IMAGE Region Name'] == \"Indonesia\") & (data_2kategori['type'] == \"oil & palm fruit\") \n",
    "  | (data_2kategori['IMAGE Region Name'] == \"SE. Asia\") & (data_2kategori['type'] == \"rice\") \n",
    "  | (data_2kategori['IMAGE Region Name'] == \"W. Africa\") & (data_2kategori['type'] == \"tropical cereals\") \n",
    "                                      \n",
    "]\n",
    "total_emissions = five_top_data_multiyear.groupby(['IMAGE Region Name', 'type'])['value'].sum()\n",
    "total_emissions = total_emissions.reset_index()\n",
    "total_emissions.columns = ['IMAGE Region Name', 'type', 'total_akumulatif']\n",
    "five_top_data_multiyear = five_top_data_multiyear.merge(total_emissions, on=['IMAGE Region Name', 'type'])\n",
    "five_top_data_multiyear['percentage'] = (five_top_data_multiyear['value'] / five_top_data_multiyear['total_akumulatif']) * 100\n",
    "pivot_df = five_top_data_multiyear.pivot_table(index=['IMAGE Region Name', 'type'], columns='emissions', values='percentage', fill_value=0)\n",
    "bar_width = 0.6 \n",
    "\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = gridspec.GridSpec(3, 3, figure=fig, hspace=0.001, wspace=0.01, width_ratios=[7,0.5,2.5], height_ratios=[5,2,3])\n",
    "\n",
    "countour_plot = fig.add_subplot(gs[:, :1])\n",
    "\n",
    "crop_footprint = carbon_footprint_array\n",
    "crop_footprint_selected = carbon_footprint_array_selected\n",
    "\n",
    "yields = df2_array.flatten()\n",
    "yields_selected = df2_array_selected.flatten()\n",
    "\n",
    "land_effeciency = 1 / yields\n",
    "land_effeciency_selected = 1 / yields_selected\n",
    "\n",
    "n_points = 100\n",
    "carbon_footprint_contour = np.linspace(0, np.max(crop_footprint_selected) + 1, n_points)\n",
    "df2_contour = np.linspace(0, np.max(land_effeciency_selected) + 0.1, n_points)\n",
    "\n",
    "X, Y = np.meshgrid(carbon_footprint_contour, df2_contour)\n",
    "Z = X * Y \n",
    "\n",
    "class_ranges = [0.1, 0.2, 0.5, 1, 2, 4, 6, 8, 11, 17, 30, 40]\n",
    "\n",
    "base_cmap = plt.cm.Greys\n",
    "colors = base_cmap(np.linspace(0.0, 0.6, base_cmap.N))  # Slice to avoid pure white or black\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_greys\", colors)\n",
    "\n",
    "norm = BoundaryNorm(class_ranges, ncolors=custom_cmap.N, clip=True)\n",
    "\n",
    "contour = countour_plot.contourf(X, Y, Z, levels=class_ranges, cmap=custom_cmap, norm=norm, edgecolors='Black')\n",
    "\n",
    "countour_plot.set_xlabel('Crop Footprint (tCO₂-eq/ ha)')\n",
    "countour_plot.set_ylabel('Land intensity for crop production (ha/ton)')\n",
    "countour_plot.axis('on')\n",
    "\n",
    "for x, data in enumerate(zip(df2_colour['IMAGE Classification Region'].to_list(), df2_colour['color'].to_list(), df2_colour['IMAGE Map'].to_list())):\n",
    "    sizes = df_norm_selected_test[x] * 60\n",
    "    countour_plot.scatter(crop_footprint_selected[x], land_effeciency_selected[x], color=data[1], edgecolors='grey', label=data[0], s=sizes)\n",
    "    \n",
    "    text = countour_plot.text(crop_footprint_selected[x], land_effeciency_selected[x] + 0.02, data[2], fontsize=8, color='black')\n",
    "    text.set_path_effects([path_effects.withStroke(linewidth=2, foreground=\"white\")])\n",
    "\n",
    "legend_ax = fig.add_subplot(gs[0, 2])\n",
    "legend_ax.axis('off') \n",
    "colors = ['#4D869C', '#7AB2B2', '#CDE8E5', '#FC4100', '#FFC55A', '#8E3E63', '#D2649A', '#03AED2', \n",
    "           '#68D2E8', '#5F6F52', '#A9B388', '#FC819E', '#F7418F', '#FFF455', '#FFEFEF', '#F7C566']\n",
    "\n",
    "legend_handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markeredgecolor='grey',markersize=10) for color in colors]\n",
    "columns2 = ['plant based fibres','non food, luxury, spices','vegetables & fruits','palm oil',\n",
    "            'sugar crops','tropical roots & tubers','temperate roots & tubers','tropical oil crops',\n",
    "            'temperate oil crops','soybeans','pulses','temperate cereals','tropical cereals','maize','rice', 'wheat']\n",
    "\n",
    "legend_ax.legend(legend_handles, columns2, loc='lower left', bbox_to_anchor=(-0.10,0.1), ncol=1)\n",
    "\n",
    "size_ax = fig.add_subplot(gs[1,2]) \n",
    "size_labels = ['5 Mton', ' 67 Mton','      370 Mton']\n",
    "size_values = [30, 404.84181766, 2248.3112172]\n",
    "for size, label in zip(size_values, size_labels):\n",
    "    size_ax.scatter([], [], s=size, facecolor='white', edgecolor='grey', linewidth=1.5, label=label)  # Empty scatter for legend\n",
    "size_ax.legend(loc='lower left', bbox_to_anchor=(-0.15,0.5), ncol=3, handletextpad=0, labelspacing=0, frameon=False)\n",
    "size_ax.axis('off') \n",
    "\n",
    "ax_barchart = fig.add_subplot(gs[2, 2])\n",
    "custom_labels = [\n",
    "    \"BRA\\nSoybeans\",\n",
    "    \"INDO\\nPalm Oil\",\n",
    "    \"SEA\\nRice\",\n",
    "    \"WAF\\nTropCereals\"]\n",
    "\n",
    "pivot_df.plot(kind='bar', stacked=True, ax=ax_barchart, color=['green', 'blue',], legend=False, width=0.4)\n",
    "\n",
    "ax_barchart.yaxis.set_major_locator(plticker.MultipleLocator(25))\n",
    "ax_barchart.set_xticks(range(len(custom_labels)))\n",
    "ax_barchart.set_xticklabels(custom_labels, rotation=0)\n",
    "ax_barchart.set_ylabel('(%)', fontsize=10)\n",
    "ax_barchart.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax_barchart.tick_params(axis='y', labelsize=10)\n",
    "ax_barchart.set_xlabel(\"\")\n",
    "\n",
    "bar_legend = ax_barchart.legend( ['MGMT', 'LUC'],\n",
    "    bbox_to_anchor=(0.5, 1),  # Centered below the plot\n",
    "    loc='lower center', \n",
    "    ncol=2,  # Two columns\n",
    "    title_fontsize=12,\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(f'/VIZ/Scatterplot_trade-off_{start_time_year+5}-{end_time_year}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
